{
  
    
        "post0": {
            "title": "Data Handling in PyTorch Geometric - Part 1",
            "content": "import numpy as np import torch import torch_geometric.datasets as datasets import torch_geometric.data as data import torch_geometric.transforms as transforms import torch_geometric.loader as loader import networkx as nx from torch_geometric.utils.convert import to_networkx . Data Manipulation . node_features = torch.rand((100, 16), dtype=torch.float) . print(node_features.shape) . torch.Size([100, 16]) . rows = np.random.choice(100, 500) cols = np.random.choice(100, 500) edges = torch.tensor([rows, cols]) . print(rows.shape) print(cols.shape) print(edges.shape) . (500,) (500,) torch.Size([2, 500]) . edges_attr = np.random.choice(3, 500) # one of three values 0, 1, 2 . ys = torch.rand((100)).round().long() # target class for each node . Creating the graph information in PyG Data Object . graph = data.Data(x = node_features, edge_index=edges, edge_attr=edges_attr, y=ys) . graph . Data(x=[100, 16], edge_index=[2, 500], edge_attr=[500], y=[100]) . type(graph) . torch_geometric.data.data.Data . for prop in graph: print(prop) . (&#39;x&#39;, tensor([[0.3260, 0.5614, 0.7219, ..., 0.8333, 0.2684, 0.6991], [0.2552, 0.7965, 0.5601, ..., 0.2872, 0.7215, 0.5561], [0.4680, 0.9911, 0.2609, ..., 0.7926, 0.7183, 0.5728], ..., [0.8130, 0.6181, 0.0477, ..., 0.4111, 0.1915, 0.2908], [0.5820, 0.0549, 0.5638, ..., 0.9298, 0.0790, 0.3821], [0.8570, 0.0329, 0.2215, ..., 0.7657, 0.5044, 0.0548]])) (&#39;edge_index&#39;, tensor([[22, 46, 57, 33, 51, 36, 73, 53, 98, 44, 19, 1, 43, 18, 75, 40, 28, 29, 81, 16, 81, 77, 19, 28, 26, 56, 14, 65, 56, 23, 29, 32, 87, 62, 8, 82, 17, 67, 27, 56, 39, 4, 34, 77, 45, 96, 28, 46, 32, 12, 15, 32, 8, 59, 93, 49, 24, 50, 62, 95, 17, 16, 95, 61, 77, 2, 75, 32, 33, 19, 96, 49, 33, 74, 61, 65, 13, 8, 0, 71, 29, 78, 24, 10, 35, 66, 49, 6, 38, 93, 6, 54, 99, 41, 29, 59, 18, 62, 24, 48, 87, 77, 58, 60, 62, 37, 36, 31, 7, 39, 12, 43, 26, 50, 37, 53, 98, 99, 58, 12, 7, 89, 78, 26, 81, 25, 13, 79, 28, 21, 4, 57, 63, 0, 25, 17, 64, 59, 59, 96, 9, 98, 78, 5, 10, 17, 63, 45, 68, 54, 67, 3, 47, 19, 49, 35, 24, 22, 29, 28, 39, 76, 63, 29, 35, 92, 97, 62, 96, 79, 78, 84, 41, 39, 28, 3, 53, 46, 88, 79, 39, 77, 94, 10, 10, 33, 63, 4, 73, 35, 10, 68, 99, 72, 58, 96, 10, 34, 42, 62, 62, 7, 86, 39, 27, 42, 32, 91, 52, 52, 71, 36, 10, 93, 20, 6, 65, 39, 33, 46, 23, 92, 84, 57, 29, 27, 29, 84, 94, 32, 76, 68, 32, 56, 64, 12, 49, 48, 63, 92, 71, 25, 0, 15, 93, 0, 4, 60, 86, 68, 32, 0, 13, 83, 8, 29, 37, 7, 49, 17, 37, 57, 40, 27, 26, 74, 74, 21, 90, 88, 53, 40, 39, 36, 5, 5, 3, 82, 44, 19, 69, 76, 0, 58, 33, 26, 60, 52, 27, 26, 18, 82, 40, 9, 18, 51, 4, 47, 53, 46, 59, 25, 55, 68, 75, 72, 24, 22, 15, 92, 73, 12, 18, 15, 73, 67, 12, 16, 55, 13, 45, 64, 80, 33, 17, 62, 1, 43, 29, 16, 51, 44, 14, 37, 71, 17, 55, 58, 93, 94, 21, 54, 61, 81, 96, 34, 50, 97, 81, 77, 44, 64, 82, 26, 16, 25, 31, 66, 11, 74, 24, 12, 50, 88, 69, 98, 26, 59, 35, 77, 68, 37, 79, 9, 50, 41, 76, 17, 86, 36, 96, 72, 92, 31, 73, 32, 64, 37, 69, 2, 45, 14, 51, 19, 72, 65, 51, 79, 11, 89, 61, 88, 85, 58, 4, 9, 93, 89, 78, 3, 15, 58, 16, 25, 32, 99, 82, 33, 3, 22, 29, 40, 24, 81, 38, 56, 2, 72, 20, 9, 10, 58, 51, 1, 46, 41, 62, 32, 14, 74, 56, 94, 27, 5, 69, 2, 30, 35, 59, 15, 30, 72, 20, 5, 86, 28, 15, 26, 62, 57, 37, 6, 94, 84, 92, 2, 4, 63, 53, 42, 62, 6, 71, 87, 17, 6, 84, 10, 27, 59, 87, 4, 6, 23, 23, 57, 39, 20, 31, 97, 86, 52, 36, 26, 80, 77, 92, 54, 94, 29], [81, 22, 82, 30, 24, 54, 37, 31, 26, 45, 35, 26, 93, 28, 2, 42, 71, 40, 73, 96, 90, 18, 44, 36, 39, 92, 73, 18, 38, 2, 91, 16, 43, 49, 39, 23, 18, 3, 78, 91, 40, 73, 6, 47, 85, 46, 36, 67, 73, 60, 72, 18, 21, 15, 15, 46, 3, 48, 82, 2, 54, 41, 9, 32, 71, 80, 60, 80, 45, 80, 35, 76, 41, 59, 3, 97, 46, 84, 58, 31, 16, 52, 84, 85, 66, 6, 32, 83, 52, 81, 86, 36, 58, 11, 48, 27, 52, 92, 73, 38, 4, 85, 9, 55, 20, 73, 44, 37, 58, 86, 4, 39, 77, 61, 91, 41, 85, 75, 74, 88, 84, 28, 14, 8, 90, 96, 61, 18, 24, 16, 19, 1, 86, 35, 74, 65, 63, 17, 32, 62, 23, 67, 31, 8, 93, 62, 62, 76, 0, 20, 18, 69, 29, 94, 25, 6, 42, 46, 46, 32, 7, 80, 13, 38, 67, 29, 11, 7, 57, 28, 62, 91, 17, 15, 88, 69, 55, 8, 19, 18, 67, 90, 28, 58, 86, 13, 64, 51, 47, 61, 31, 57, 60, 69, 64, 39, 91, 3, 57, 15, 27, 31, 15, 39, 16, 34, 11, 91, 86, 88, 23, 26, 45, 88, 41, 89, 76, 3, 84, 26, 42, 29, 23, 55, 94, 55, 18, 2, 40, 13, 0, 54, 89, 88, 25, 71, 49, 50, 28, 68, 36, 74, 68, 66, 51, 56, 85, 58, 61, 20, 11, 19, 48, 19, 86, 56, 27, 44, 65, 82, 57, 60, 68, 2, 54, 9, 51, 97, 70, 21, 95, 91, 50, 61, 47, 46, 94, 92, 24, 34, 50, 24, 58, 72, 34, 30, 16, 96, 95, 56, 34, 93, 25, 26, 44, 26, 96, 14, 15, 48, 46, 30, 97, 89, 31, 99, 58, 18, 45, 49, 80, 5, 4, 7, 88, 46, 17, 33, 4, 72, 94, 30, 22, 64, 66, 95, 88, 44, 19, 63, 68, 12, 49, 67, 82, 49, 38, 91, 53, 34, 87, 19, 35, 19, 40, 46, 4, 34, 5, 78, 0, 47, 98, 5, 77, 29, 15, 88, 17, 15, 15, 8, 61, 59, 31, 44, 71, 57, 12, 47, 13, 28, 61, 13, 96, 93, 76, 62, 57, 7, 10, 93, 45, 94, 8, 90, 74, 33, 66, 67, 52, 76, 28, 88, 95, 72, 90, 69, 17, 63, 87, 83, 6, 14, 94, 67, 64, 85, 6, 3, 76, 25, 59, 93, 64, 19, 53, 42, 98, 66, 96, 83, 18, 64, 55, 58, 73, 15, 35, 52, 67, 37, 10, 52, 83, 20, 58, 93, 1, 74, 85, 16, 79, 59, 65, 41, 91, 78, 54, 48, 3, 83, 41, 0, 39, 20, 40, 32, 7, 37, 57, 22, 35, 70, 13, 71, 41, 41, 63, 11, 89, 26, 56, 57, 95, 72, 28, 34, 38, 25, 5, 65, 38, 7, 94, 35, 38, 65, 25, 12, 56, 70, 49, 98, 56, 39, 99, 98, 28, 35]])) (&#39;edge_attr&#39;, array([0, 1, 1, 0, 1, 2, 1, 0, 1, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 2, 1, 2, 1, 2, 1, 0, 2, 2, 1, 0, 1, 2, 1, 0, 2, 1, 0, 2, 0, 1, 0, 0, 1, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 2, 0, 1, 2, 1, 1, 0, 2, 0, 0, 1, 2, 0, 0, 2, 0, 2, 2, 2, 0, 2, 2, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 0, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 1, 0, 1, 2, 0, 1, 2, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 0, 2, 0, 1, 1, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 2, 2, 2, 0, 1, 1, 2, 0, 0, 1, 1, 0, 2, 0, 1, 1, 0, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0, 2, 0, 0, 1, 2, 2, 0, 0, 2, 2, 2, 1, 1, 1, 2, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 1, 0, 2, 0, 2, 1, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 1, 0, 1, 0, 2, 1, 1, 0, 1, 1, 2, 2, 2, 0, 2, 0, 0, 0, 1, 2, 0, 0, 2, 2, 0, 0, 1, 0, 2, 1, 2, 2, 2, 0, 1, 2, 1, 1, 1, 2, 1, 0, 2, 2, 1, 2, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 2, 0, 1, 2, 1, 1, 2, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 2, 2, 1, 0, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 0, 0, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 0, 1, 2, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 2, 2, 2, 2, 1, 0, 2, 1, 1, 2, 2, 2, 0, 0, 2, 1, 0, 2, 1, 2, 2, 2, 0, 2, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 0, 0, 0, 0, 2, 2, 0, 1, 1, 1, 2, 0, 0, 2, 1, 2, 0, 1, 1, 2, 1, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1, 2, 1, 2, 2, 1, 0, 2, 0, 1, 1, 2, 2, 0, 2, 0, 1, 0, 1, 0, 1, 2, 1, 1, 0, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 2, 1, 2, 0, 2, 1, 0, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 2, 1, 1])) (&#39;y&#39;, tensor([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0])) . vis = to_networkx(graph) node_labels = graph.y.numpy() import matplotlib.pyplot as plt plt.figure(1, figsize=(15, 13)) nx.draw(vis, cmap=plt.get_cmap(&#39;Set3&#39;), node_color= node_labels, node_size=70, linewidths=6) plt.show() . Batch . with the Batch we can represent graphs as single disconnected graph . graph2 = graph . batch = data.Batch().from_data_list([graph, graph2]) . print(&quot;Number of graphs:&quot;, batch.num_graphs) print(&quot;Graph at index 1:&quot;, batch[1]) print(&quot;Retrieve the list of graphs: n&quot;, len(batch.to_data_list())) . Number of graphs: 2 Graph at index 1: Data(x=[100, 16], edge_index=[2, 500], edge_attr=[500], y=[100]) Retrieve the list of graphs: 2 . Cluster . . . Sampler . for each convolitonal layer, sample a maximum of nodes from each neighbourhood (as in GraphSAGE) . sampler = data.NeighborSampler(graph.edge_index, sizes=[3,10], batch_size=4, shuffle=False) #sizes is the nodes ion the levels . /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/torch_geometric/deprecation.py:13: UserWarning: &#39;data.NeighborSampler&#39; is deprecated, use &#39;loader.NeighborSampler&#39; instead warnings.warn(out) . for s in sampler: print(s) break # first batch of neighbors . (4, tensor([ 0, 1, 2, 3, 68, 5, 44, 57, 14, 84, 27, 23, 30, 24, 39, 76, 95, 75, 67, 61, 34, 92, 51, 40, 87, 81, 12, 26, 98, 18, 7, 19, 36, 43, 96, 86, 37, 42, 59, 78, 47, 58, 33, 8, 62, 82, 9, 71, 64, 25, 28, 77]), [EdgeIndex(edge_index=tensor([[ 4, 5, 6, 15, 7, 8, 9, 10, 11, 16, 17, 3, 12, 13, 14, 18, 19, 20, 0, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 4, 24, 34, 35, 36, 36, 37, 38, 39, 40, 41, 13, 30, 42, 43, 36, 38, 44, 9, 45, 46, 47, 27, 42, 48, 49, 6, 15, 22, 50, 14, 27, 33, 34, 35, 43, 51], [ 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 9, 9, 9, 9, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14]]), e_id=tensor([148, 453, 350, 230, 131, 438, 227, 263, 29, 59, 14, 409, 450, 56, 217, 37, 74, 197, 242, 239, 330, 262, 480, 348, 311, 353, 365, 294, 257, 22, 106, 327, 191, 473, 168, 378, 260, 460, 198, 367, 122, 297, 403, 82, 120, 218, 77, 256, 95, 200, 222, 35, 140, 210, 285, 3, 321, 301, 278, 281, 4, 128, 203, 24, 111, 195, 454, 34, 495]), size=(52, 15)), EdgeIndex(edge_index=tensor([[ 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], [ 0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 3]]), e_id=tensor([148, 453, 350, 131, 438, 227, 263, 29, 450, 56, 217]), size=(15, 4))]) . print(&quot;Batch Size:&quot;, s[0]) print(&quot;Number of unique nodes involved in the sampling:&quot;, len(s[1])) print(&quot;Number of neighbors sampled:&quot;, len(s[2][0].edge_index[0]), len(s[2][1].edge_index[0])) . Batch Size: 4 Number of unique nodes involved in the sampling: 52 Number of neighbors sampled: 69 11 . Datasets . datasets.__all__ . [&#39;KarateClub&#39;, &#39;TUDataset&#39;, &#39;GNNBenchmarkDataset&#39;, &#39;Planetoid&#39;, &#39;FakeDataset&#39;, &#39;FakeHeteroDataset&#39;, &#39;NELL&#39;, &#39;CitationFull&#39;, &#39;CoraFull&#39;, &#39;Coauthor&#39;, &#39;Amazon&#39;, &#39;PPI&#39;, &#39;Reddit&#39;, &#39;Reddit2&#39;, &#39;Flickr&#39;, &#39;Yelp&#39;, &#39;AmazonProducts&#39;, &#39;QM7b&#39;, &#39;QM9&#39;, &#39;MD17&#39;, &#39;ZINC&#39;, &#39;MoleculeNet&#39;, &#39;Entities&#39;, &#39;RelLinkPredDataset&#39;, &#39;GEDDataset&#39;, &#39;AttributedGraphDataset&#39;, &#39;MNISTSuperpixels&#39;, &#39;FAUST&#39;, &#39;DynamicFAUST&#39;, &#39;ShapeNet&#39;, &#39;ModelNet&#39;, &#39;CoMA&#39;, &#39;SHREC2016&#39;, &#39;TOSCA&#39;, &#39;PCPNetDataset&#39;, &#39;S3DIS&#39;, &#39;GeometricShapes&#39;, &#39;BitcoinOTC&#39;, &#39;ICEWS18&#39;, &#39;GDELT&#39;, &#39;DBP15K&#39;, &#39;WILLOWObjectClass&#39;, &#39;PascalVOCKeypoints&#39;, &#39;PascalPF&#39;, &#39;SNAPDataset&#39;, &#39;SuiteSparseMatrixCollection&#39;, &#39;TrackMLParticleTrackingDataset&#39;, &#39;AMiner&#39;, &#39;WordNet18&#39;, &#39;WordNet18RR&#39;, &#39;WikiCS&#39;, &#39;WebKB&#39;, &#39;WikipediaNetwork&#39;, &#39;Actor&#39;, &#39;OGB_MAG&#39;, &#39;DBLP&#39;, &#39;MovieLens&#39;, &#39;IMDB&#39;, &#39;LastFM&#39;, &#39;HGBDataset&#39;, &#39;JODIEDataset&#39;, &#39;MixHopSyntheticDataset&#39;, &#39;UPFD&#39;, &#39;GitHub&#39;, &#39;FacebookPagePage&#39;, &#39;LastFMAsia&#39;, &#39;DeezerEurope&#39;, &#39;GemsecDeezer&#39;, &#39;Twitch&#39;, &#39;Airports&#39;, &#39;BAShapes&#39;, &#39;MalNetTiny&#39;, &#39;OMDB&#39;, &#39;PolBlogs&#39;, &#39;EmailEUCore&#39;, &#39;StochasticBlockModelDataset&#39;, &#39;RandomPartitionGraphDataset&#39;, &#39;LINKXDataset&#39;] . name = &#39;Cora&#39; transform = transforms.Compose([ transforms.RandomNodeSplit(&#39;train_rest&#39;, num_val=500, num_test=500), transforms.TargetIndegree() ]) cora = datasets.Planetoid(&#39;./data&#39;, name, pre_transform=transforms.NormalizeFeatures(), transform=transform) # pre_transform applied only when the dataset is downloading # once dataeset is downloaded the transforms will be applies # if dataset is already downloaded the running cell again will retrive dataset from the local it self . Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index Processing... Done! . aids = datasets.TUDataset(root=&#39;./data&#39;, name=&quot;AIDS&quot;) . Downloading https://www.chrsmrrs.com/graphkerneldatasets/AIDS.zip Extracting data/AIDS/AIDS.zip Processing... Done! . Cora and AIDS Datasets . print(&quot;AIDS info:&quot;) print(&quot;# of graphs:&quot;, len(aids)) print(&quot;# Classes {graphs}&quot;, aids.num_classes) print(&quot;# Edge features&quot;, aids.num_edge_features) print(&quot;# Edge labels&quot;, aids.num_edge_labels) print(&quot;# Node features&quot;, aids.num_node_features) . AIDS info: # of graphs: 2000 # Classes {graphs} 2 # Edge features 3 # Edge labels 3 # Node features 38 . print(&quot;Cora info:&quot;) print(&quot;# of graphs:&quot;, len(cora)) print(&quot;# Classes {graphs}&quot;, cora.num_classes) print(&quot;# Edge features&quot;, cora.num_edge_features) print(&quot;# Node features&quot;, cora.num_node_features) . Cora info: # of graphs: 1 # Classes {graphs} 7 # Edge features 1 # Node features 1433 . cora does not have attribute num_edge_labels . aids.data # implies one single data object . Data(x=[31385, 38], edge_index=[2, 64780], edge_attr=[64780, 3], y=[2000]) . aids[0] #info of a specific graph . Data(edge_index=[2, 106], x=[47, 38], edge_attr=[106, 3], y=[1]) . cora.data . Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708]) . cora[0] . Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_attr=[10556, 1]) . cora_loader = loader.DataLoader(cora) . for l in cora_loader: print(l) break . DataBatch(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_attr=[10556, 1], batch=[2708], ptr=[2]) .",
            "url": "https://mr-siddy.github.io/ML-blog/pytorch%20geometric/2022/03/11/pygone.html",
            "relUrl": "/pytorch%20geometric/2022/03/11/pygone.html",
            "date": " • Mar 11, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Iot In Healthcare",
            "content": "IoT in Healthcare . Author : Siddhant Saxena ( Manipal University Jaipur, siddhantsaxenaphy@gmail.com) . In healthcare IoT can be referenced as Internet of Medical Things, which is just a subset of Iot devices and deals specially with patient data, these devices can be worn like a fitbit that an individual wears and fitbit passively monitors the activities of that individual. Another class of devices that are Ambient such as sensors that exist in hospital beds or a monitor room and they either tell medical readings, vital signs or report on a patient’s behaviour. . Applications of IOT in Medical Sciences . Patient Monitoring Research and Life Sciences Smart Hospitals . Remote care | Integrate IoT and other data for research | Streamline hospital processes with automation | . Chronic Disease Management | Clinical trials | Augment Care teams | . Tele-health | Lab Data Analytics | Improve workflow safety and efficiency | . Challenges building Internet of Medical Things (IoMT) Solution . Latency in arriving data . Data generated by sensor is transmitted to a server for further examination, but due to several issues like slow internet connection can cause latency in arriving data . Out of order data . Data order is very important to monitor constant health, the device that is worn by individuals is dependent on internet connectivity of the internet and it can send recent data first and older data later but device and system have to make sure that data sent to server is in chronological order. . Balancing Latency and load . When there is a wearable device using some kind of gateway for internet connection like a smartphone we can have data that’s being collected for hours and once internet connectivity is established then data will be send and transmitted so we should be able to handle that burst of data then make sense of it appropriately . Application of IoT in Healthcare : . Remote Heart Rate monitoring using IoT device and Artificial Intelligence . Introduction . People suffering from heart related problems need constant monitoring, and often doctors suggest they have regular check-ups, but when there are a large number of patients connected to a hospital, it is very difficult to keep monitoring different people simultaneously. Here proposed methodology is based on the remote care application of IoT which uses sensors, raspberry pi and Artificial intelligence system to monitor large numbers of patients remotely and in an efficient manner. . Remote ECG and Heart Rate Monitoring IoT Device . The following are the components required to build a patient monitoring system. . Raspberry Pi . | Pulse Sensor . | ADS1115 ADC module . | Jumper wire . | Power supply (AC/DC) . | . Circuit Diagram to Connect Raspberry Pi to Sensors : . . Figure 1: IoT Device Setup . Configuration of Heart Rate Monitoring system . Signal pin of pulse sensor -&gt; A0 of ADC Module . | Vcc pin of pulse sensor -&gt; 3.3V of Raspberry . | GND pin of pulse sensor -&gt; GND of Pi . | Tx of RPI-&gt; Rx of RPI . | GND of ADC module -&gt; GND of RPI . | VCC of ADC Module -&gt; +5v Of RPI . | SCL and SDA of ADC module -&gt; SCL and SDA of RPI . | . Interface ADC module via 12C communication for getting analog output of pulse sensor. After getting raw analog output from pulse sensor, difference between upper peak and lower peak points can be used to convert them into BPM and then send raw analog output and BPM to serial port which is read from processing IDE to generate graphs.This ECG data captured from the sensor can be transmitted by raspberry pi to any server that is used by hospitals to monitor the patient’s health conditions. But still to track the health condition of a large number of patients is very difficult, this can be solved using artificial intelligence. . Raspberry Pi ECG Server with Integrated Artificial Intelligence . Raspberry pi can be used as a server which captures ecg data and simultaneously feeds it into an LSTM Autoencoder (RNN) to flag any type of anomaly in ECG normal data. This model is trained on ECG 5000 Publicly available dataset, which is then capable of classifying the ecg signal in 5 types of heartbeat classes. . Normal (N) . | R-on-T Premature Ventricular Contraction (R-on-T PVC) . | Premature Ventricular Contraction (PVC) . | Supra-ventricular Premature or Ectopic Beat (SP or EB) . | Unclassified Beat (UB). . | . If any type of heartbeat other than Normal occurs in any device, the raspberry pi server will automatically send information to the hospital to get instant support in case of emergency. . Complete architecture of IoMT device . . Figure 2: Remote IoT Device for Heart Rate Monitoring System . In figure 2, This is device architecture for an individual patient generates flags for 5 different types of heart diseases, and those of high risk can be easily segregated by hospitals for emergency situations. .",
            "url": "https://mr-siddy.github.io/ML-blog/2022/03/11/IoT-in-Healthcare.html",
            "relUrl": "/2022/03/11/IoT-in-Healthcare.html",
            "date": " • Mar 11, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fundamentals of Medical Image Processing for Deep Learning",
            "content": "import numpy as np import pandas as pd import scipy.ndimage from skimage import measure, morphology from mpl_toolkits.mplot3d.art3d import Poly3DCollection from sklearn.cluster import KMeans import shutil import cv2 import pydicom import matplotlib.pyplot as plt from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator) import seaborn as sns from IPython.display import HTML import gdcm import os . def set_options(): pd.set_option(&#39;display.max_columns&#39;, 100) pd.set_option(&#39;display.max_colwidth&#39;, None) pd.set_option(&#39;display.max_rows&#39;, 1000) . set_options() . Loading the Data . TRAIN_PATH = &#39;osic-pulmonary-fibrosis-progression/train.csv&#39; TRAIN_IMG_PATH = &#39;osic-pulmonary-fibrosis-progression/train&#39; TEST_PATH = &#39;osic-pulmonary-fibrosis-progression/test.csv&#39; TEST_IMG_PATH = &#39;osic-pulmonary-fibrosis-progression/test&#39; SUBMISSION_PATH = &#39;osic-pulmonary-fibrosis-progression/sample_submission.csv&#39; . &#39;&#39;&#39; Load CSV data&#39;&#39;&#39; train = pd.read_csv(TRAIN_PATH) test = pd.read_csv(TEST_PATH) . train[train.duplicated([&#39;Patient&#39;, &#39;Weeks&#39;], keep = False)] . Patient Weeks FVC Percent Age Sex SmokingStatus . 166 ID00048637202185016727717 | 9 | 1375 | 60.059404 | 70 | Female | Never smoked | . 167 ID00048637202185016727717 | 9 | 1477 | 64.514720 | 70 | Female | Never smoked | . 226 ID00068637202190879923934 | 11 | 2794 | 82.633385 | 73 | Male | Ex-smoker | . 227 ID00068637202190879923934 | 11 | 2827 | 83.609369 | 73 | Male | Ex-smoker | . 306 ID00089637202204675567570 | 7 | 2478 | 57.967624 | 63 | Male | Never smoked | . 307 ID00089637202204675567570 | 7 | 2539 | 59.394592 | 63 | Male | Never smoked | . 465 ID00125637202218590429387 | 8 | 2349 | 53.757781 | 65 | Male | Never smoked | . 466 ID00125637202218590429387 | 8 | 2584 | 59.135848 | 65 | Male | Never smoked | . 750 ID00199637202248141386743 | 5 | 2672 | 64.728682 | 62 | Male | Ex-smoker | . 751 ID00199637202248141386743 | 5 | 2683 | 64.995155 | 62 | Male | Ex-smoker | . 920 ID00240637202264138860065 | 5 | 2991 | 78.421605 | 63 | Male | Ex-smoker | . 921 ID00240637202264138860065 | 5 | 3132 | 82.118511 | 63 | Male | Ex-smoker | . 1521 ID00421637202311550012437 | 70 | 2628 | 78.720345 | 68 | Male | Ex-smoker | . 1522 ID00421637202311550012437 | 70 | 2719 | 81.446202 | 68 | Male | Ex-smoker | . train = train.drop_duplicates() . train.head(10) . Patient Weeks FVC Percent Age Sex SmokingStatus . 0 ID00007637202177411956430 | -4 | 2315 | 58.253649 | 79 | Male | Ex-smoker | . 1 ID00007637202177411956430 | 5 | 2214 | 55.712129 | 79 | Male | Ex-smoker | . 2 ID00007637202177411956430 | 7 | 2061 | 51.862104 | 79 | Male | Ex-smoker | . 3 ID00007637202177411956430 | 9 | 2144 | 53.950679 | 79 | Male | Ex-smoker | . 4 ID00007637202177411956430 | 11 | 2069 | 52.063412 | 79 | Male | Ex-smoker | . 5 ID00007637202177411956430 | 17 | 2101 | 52.868646 | 79 | Male | Ex-smoker | . 6 ID00007637202177411956430 | 29 | 2000 | 50.327126 | 79 | Male | Ex-smoker | . 7 ID00007637202177411956430 | 41 | 2064 | 51.937594 | 79 | Male | Ex-smoker | . 8 ID00007637202177411956430 | 57 | 2057 | 51.761449 | 79 | Male | Ex-smoker | . 9 ID00009637202177434476278 | 8 | 3660 | 85.282878 | 69 | Male | Ex-smoker | . HTML(&#39;&lt;iframe width=&quot;600&quot; height=&quot;400&quot; src=&quot;https://www.youtube.com/embed/KZld-5W99cI&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen&gt;&lt;/iframe&gt;&#39;) . /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead warnings.warn(&#34;Consider using IPython.display.IFrame instead&#34;) . # In this dataset the ImagePosition is not available so we&#39;ll sort the slices on Instance Number def load_slices(path): filenames = os.listdir(path) slices = [pydicom.dcmread(f&#39;{path}/{file}&#39;) for file in filenames] slices.sort(key = lambda x: int(x.InstanceNumber), reverse=True) return slices . scans = load_slices(f&#39;{TRAIN_IMG_PATH}/ID00007637202177411956430&#39;) print(len(scans)) # here is the first slice of dicom scans[0] . 30 . Dataset.file_meta - (0002, 0000) File Meta Information Group Length UL: 200 (0002, 0001) File Meta Information Version OB: b&#39; x00 x01&#39; (0002, 0002) Media Storage SOP Class UID UI: CT Image Storage (0002, 0003) Media Storage SOP Instance UID UI: 2.25.95516132172461492040664114239048418896 (0002, 0010) Transfer Syntax UID UI: Explicit VR Little Endian (0002, 0012) Implementation Class UID UI: 1.2.276.0.7230010.3.0.3.6.1 (0002, 0013) Implementation Version Name SH: &#39;OSIRIX_361&#39; (0002, 0016) Source Application Entity Title AE: &#39;ANONYMOUS&#39; - (0008, 0005) Specific Character Set CS: &#39;ISO_IR 100&#39; (0008, 0008) Image Type CS: [&#39;ORIGINAL&#39;, &#39;PRIMARY&#39;, &#39;AXIAL&#39;] (0008, 0018) SOP Instance UID UI: 2.25.95516132172461492040664114239048418896 (0008, 0060) Modality CS: &#39;CT&#39; (0008, 0070) Manufacturer LO: &#39;GE MEDICAL SYSTEMS&#39; (0008, 1090) Manufacturer&#39;s Model Name LO: &#39;LightSpeed VCT&#39; (0010, 0010) Patient&#39;s Name PN: &#39;ID00007637202177411956430&#39; (0010, 0020) Patient ID LO: &#39;ID00007637202177411956430&#39; (0010, 0040) Patient&#39;s Sex CS: &#39;&#39; (0012, 0063) De-identification Method LO: &#39;Table;&#39; (0018, 0015) Body Part Examined CS: &#39;Chest&#39; (0018, 0050) Slice Thickness DS: &#39;1.25&#39; (0018, 0060) KVP DS: &#39;120.0&#39; (0018, 1110) Distance Source to Detector DS: &#39;949.075012&#39; (0018, 1111) Distance Source to Patient DS: &#39;541.0&#39; (0018, 1120) Gantry/Detector Tilt DS: &#39;0.0&#39; (0018, 1130) Table Height DS: &#39;130.0&#39; (0018, 1140) Rotation Direction CS: &#39;CW&#39; (0018, 1151) X-Ray Tube Current IS: &#39;79&#39; (0018, 1170) Generator Power IS: &#39;9600&#39; (0018, 1190) Focal Spot(s) DS: &#39;0.7&#39; (0018, 1210) Convolution Kernel SH: &#39;BONE&#39; (0018, 5100) Patient Position CS: &#39;FFS&#39; (0020, 000d) Study Instance UID UI: 2.25.80896671862726099888461805953012988790 (0020, 000e) Series Instance UID UI: 2.25.51769600465874599901723496946193454321 (0020, 0010) Study ID SH: &#39;&#39; (0020, 0013) Instance Number IS: &#39;30&#39; (0020, 0032) Image Position (Patient) DS: [-158.700, -153.500, -359.750] (0020, 0037) Image Orientation (Patient) DS: [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000] (0020, 0052) Frame of Reference UID UI: 2.25.64058019325784235774105718339367403144 (0020, 1040) Position Reference Indicator LO: &#39;SN&#39; (0020, 1041) Slice Location DS: &#39;-359.75&#39; (0028, 0002) Samples per Pixel US: 1 (0028, 0004) Photometric Interpretation CS: &#39;MONOCHROME2&#39; (0028, 0010) Rows US: 512 (0028, 0011) Columns US: 512 (0028, 0030) Pixel Spacing DS: [0.652344, 0.652344] (0028, 0100) Bits Allocated US: 16 (0028, 0101) Bits Stored US: 16 (0028, 0102) High Bit US: 15 (0028, 0103) Pixel Representation US: 1 (0028, 0120) Pixel Padding Value SS: -2000 (0028, 1050) Window Center DS: &#39;-500.0&#39; (0028, 1051) Window Width DS: &#39;-1500.0&#39; (0028, 1052) Rescale Intercept DS: &#39;-1024.0&#39; (0028, 1053) Rescale Slope DS: &#39;1.0&#39; (0028, 1054) Rescale Type LO: &#39;HU&#39; (7fe0, 0010) Pixel Data OW: Array of 524288 elements . Some Meta Data Which is useful for processing . Slice Thickness: it is distance b/w two slices, further useful for getting the volume of the image | Image Orientation (patient) and Slice Location comes in use when the Slice Thickness is not given in the dataset so, slice thickness = difference b/w slice location of any two slices | Pixel Spacing is vimp metadata, it gives pixel size x and y coordinates | window center and the window window width are vimp as they give region of interest | Conversion in Hounsfeild Units . It basically gives the density of the tissue, so to convert the slices in the HU domain we take every slice and do, slice * Rescalse Slope + Rescale Intercept which is just a linear transformation . def get_pixels_hu(slices): image = np.stack([s.pixel_array for s in slices]) image = image.astype(np.int16) # Set outside-of-scan pixels to 0 # The intercept is usually -1024, so air is approximately 0 image[image &lt;= -1000] = 0 # convert to HU for slice_number in range(len(slices)): intercept = slices[slice_number].RescaleIntercept slope = slices[slice_number].RescaleSlope if slope != 1: image[slice_number] = slope * image[slice_number].astype(np.float64) image[slice_number] = image[slice_number].astype(np.int16) image[slice_number] += np.int16(intercept) return np.array(image, dtype=np.int16) . Windowing . windowing is the seletion of range of range of greyscale in the image that we need, basically it gives the region of interest using parameters like window width and window level(center) . window width - greyscale which can be displayed on the image, we do not want the black color bcoz that is the air, we do not want that density to show, so we adjust these greyscale range so that we can just get only the lung portion of that. . window center or level - center of that particular range of that window width . in our case WW of 100 HU could mean the grayscale only ranges from 0HU to +100 HU, with a WL of +50 HU. For Lungs window width is 1500 and window level is -600, so grayscale ranges from 150HU to -1350HU. More about windowing can be read here. How to get window width and level is explained briefly in this article. . def apply_window(hu_image, center, width): hu_image = hu_image.copy() min_value = center - width // 2 max_value = center + width // 2 hu_image[hu_image &lt; min_value] = min_value hu_image[hu_image &gt; max_value] = max_value return hu_image . Histogram Analysis . Lets plot histogram for image pixels after converting to HU and raw pixel values. After converting to HU we can see there is lot of air(-1000) in the scan. Some fat and muscle is also seen. . train.loc[0][&#39;Patient&#39;] . &#39;ID00007637202177411956430&#39; . fig, ax = plt.subplots(1, 2, figsize= (20, 5)) example = train.loc[0][&#39;Patient&#39;] scans = load_slices(f&#39;{TRAIN_IMG_PATH}/{example}&#39;) rescaled_images = get_pixels_hu(scans) images = [scan.pixel_array for scan in scans] for i in range(10): sns.histplot(images[i].flatten(), ax=ax[0]) sns.histplot(rescaled_images[i].flatten(), ax=ax[1]) ax[0].set_title(&quot;Raw pixel array distributions for 10 examples&quot;) ax[1].set_title(&quot;HU unit distributions for 10 examples&quot;) plt.show() . Storing Metadata in Dataframe . def get_dicom_raw(dicom): return ({attr:getattr(dicom, attr) for attr in dir(dicom) if attr[0].isupper() and attr not in [&#39;PixelData&#39;]}) . %%time # Get dicom metadata # Image features like lung volume are implementation from a detailed discussion &quot;Domain expert&#39;s insight&quot; by Dr. Konya. # https://www.kaggle.com/c/osic-pulmonary-fibrosis-progression/discussion/165727 def get_dicom_metadata(df): patients = df.Patient.unique() dicom_metadata = [] for patient in patients: path = f&#39;{TRAIN_IMG_PATH}/{patient}&#39; img_list = os.listdir(path) for img in img_list: image = pydicom.dcmread(f&#39;{path}/{img}&#39;) record = get_dicom_raw(image) raw = image.pixel_array pixelspacing_r, pixelspacing_c = image.PixelSpacing[0], image.PixelSpacing[1] row_distance = pixelspacing_r * image.Rows col_distance = pixelspacing_c * image.Columns record.update({&#39;raw_min&#39;:raw.min(), &#39;raw_max&#39;:raw.max(), &#39;raw_mean&#39;:raw.mean(), &#39;raw_std&#39;:raw.std(), &#39;raw_diff&#39;:raw.max()-raw.min(), &#39;pixel_spacing_area&#39;:pixelspacing_r * pixelspacing_c, &#39;img_area&#39;:image.Rows * image.Columns, &#39;pixel_row_distance&#39;:row_distance, &#39;pixel_col_distance&#39;:col_distance, &#39;slice_area_cm2&#39;:(0.1 * row_distance) * (0.1 * col_distance), &#39;slice_vol_cm3&#39;:(0.1 * image.SliceThickness) * (0.1 * row_distance) * (0.1 * col_distance), &#39;patient_img_path&#39;:f&#39;{path}/{img}&#39;}) dicom_metadata.append(record) metadata_df = pd.DataFrame(dicom_metadata) metadata_df.to_pickle(&#39;metadata_df.pkl&#39;) return metadata_df . CPU times: user 6 µs, sys: 1e+03 ns, total: 7 µs Wall time: 9.3 µs . metadata_df = get_dicom_metadata(train.copy()) metadata_df.head() . &lt;timed exec&gt;:22: RuntimeWarning: overflow encountered in short_scalars . BitsAllocated BitsStored BodyPartExamined Columns ConvolutionKernel DeidentificationMethod DistanceSourceToDetector DistanceSourceToPatient FocalSpots FrameOfReferenceUID GantryDetectorTilt GeneratorPower HighBit ImageOrientationPatient ImagePositionPatient ImageType InstanceNumber KVP Manufacturer ManufacturerModelName Modality PatientID PatientName PatientPosition PatientSex PhotometricInterpretation PixelPaddingValue PixelRepresentation PixelSpacing PositionReferenceIndicator RescaleIntercept RescaleSlope RescaleType RotationDirection Rows SOPInstanceUID SamplesPerPixel SeriesInstanceUID SliceLocation SliceThickness SpecificCharacterSet StudyID StudyInstanceUID TableHeight WindowCenter WindowWidth XRayTubeCurrent raw_min raw_max raw_mean raw_std raw_diff pixel_spacing_area img_area pixel_row_distance pixel_col_distance slice_area_cm2 slice_vol_cm3 patient_img_path LargestImagePixelValue SmallestImagePixelValue WindowCenterWidthExplanation PatientOrientation RevolutionTime SingleCollimationWidth SpiralPitchFactor TableFeedPerRotation TableSpeed TotalCollimationWidth SpacingBetweenSlices SpatialResolution . 0 16 | 16 | Chest | 512 | BONE | Table; | 949.075012 | 541.0 | 0.7 | 2.25.64058019325784235774105718339367403144 | 0.0 | 9600.0 | 15 | [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000] | [-158.700, -153.500, -69.750] | [ORIGINAL, PRIMARY, AXIAL] | 1 | 120.0 | GE MEDICAL SYSTEMS | LightSpeed VCT | CT | ID00007637202177411956430 | (I, D, 0, 0, 0, 0, 7, 6, 3, 7, 2, 0, 2, 1, 7, 7, 4, 1, 1, 9, 5, 6, 4, 3, 0) | FFS | | MONOCHROME2 | -2000.0 | 1 | [0.652344, 0.652344] | SN | -1024.0 | 1.0 | HU | CW | 512 | 2.25.12297650151329871895440507938349160734 | 1 | 2.25.51769600465874599901723496946193454321 | -69.75 | 1.25 | ISO_IR 100 | | 2.25.80896671862726099888461805953012988790 | 130.0 | -500.0 | -1500.0 | 79.0 | -2000 | 2842 | -1.454884 | 1137.488858 | 4842 | 0.425553 | 262144 | 334.000128 | 334.000128 | 1115.560855 | 139.445107 | osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/1.dcm | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1 16 | 16 | Chest | 512 | BONE | Table; | 949.075012 | 541.0 | 0.7 | 2.25.64058019325784235774105718339367403144 | 0.0 | 9600.0 | 15 | [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000] | [-158.700, -153.500, -159.750] | [ORIGINAL, PRIMARY, AXIAL] | 10 | 120.0 | GE MEDICAL SYSTEMS | LightSpeed VCT | CT | ID00007637202177411956430 | (I, D, 0, 0, 0, 0, 7, 6, 3, 7, 2, 0, 2, 1, 7, 7, 4, 1, 1, 9, 5, 6, 4, 3, 0) | FFS | | MONOCHROME2 | -2000.0 | 1 | [0.652344, 0.652344] | SN | -1024.0 | 1.0 | HU | CW | 512 | 2.25.37611372879908126511187998276199853341 | 1 | 2.25.51769600465874599901723496946193454321 | -159.75 | 1.25 | ISO_IR 100 | | 2.25.80896671862726099888461805953012988790 | 130.0 | -500.0 | -1500.0 | 79.0 | -2000 | 2918 | 19.038597 | 1138.876560 | 4918 | 0.425553 | 262144 | 334.000128 | 334.000128 | 1115.560855 | 139.445107 | osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/10.dcm | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2 16 | 16 | Chest | 512 | BONE | Table; | 949.075012 | 541.0 | 0.7 | 2.25.64058019325784235774105718339367403144 | 0.0 | 9600.0 | 15 | [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000] | [-158.700, -153.500, -169.750] | [ORIGINAL, PRIMARY, AXIAL] | 11 | 120.0 | GE MEDICAL SYSTEMS | LightSpeed VCT | CT | ID00007637202177411956430 | (I, D, 0, 0, 0, 0, 7, 6, 3, 7, 2, 0, 2, 1, 7, 7, 4, 1, 1, 9, 5, 6, 4, 3, 0) | FFS | | MONOCHROME2 | -2000.0 | 1 | [0.652344, 0.652344] | SN | -1024.0 | 1.0 | HU | CW | 512 | 2.25.85307440096263309601052352542310417307 | 1 | 2.25.51769600465874599901723496946193454321 | -169.75 | 1.25 | ISO_IR 100 | | 2.25.80896671862726099888461805953012988790 | 130.0 | -500.0 | -1500.0 | 79.0 | -2000 | 2976 | 27.237549 | 1146.816206 | 4976 | 0.425553 | 262144 | 334.000128 | 334.000128 | 1115.560855 | 139.445107 | osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/11.dcm | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 3 16 | 16 | Chest | 512 | BONE | Table; | 949.075012 | 541.0 | 0.7 | 2.25.64058019325784235774105718339367403144 | 0.0 | 9600.0 | 15 | [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000] | [-158.700, -153.500, -179.750] | [ORIGINAL, PRIMARY, AXIAL] | 12 | 120.0 | GE MEDICAL SYSTEMS | LightSpeed VCT | CT | ID00007637202177411956430 | (I, D, 0, 0, 0, 0, 7, 6, 3, 7, 2, 0, 2, 1, 7, 7, 4, 1, 1, 9, 5, 6, 4, 3, 0) | FFS | | MONOCHROME2 | -2000.0 | 1 | [0.652344, 0.652344] | SN | -1024.0 | 1.0 | HU | CW | 512 | 2.25.46123781426224593247761081441512910006 | 1 | 2.25.51769600465874599901723496946193454321 | -179.75 | 1.25 | ISO_IR 100 | | 2.25.80896671862726099888461805953012988790 | 130.0 | -500.0 | -1500.0 | 79.0 | -2000 | 2862 | 31.026043 | 1142.850763 | 4862 | 0.425553 | 262144 | 334.000128 | 334.000128 | 1115.560855 | 139.445107 | osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/12.dcm | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 4 16 | 16 | Chest | 512 | BONE | Table; | 949.075012 | 541.0 | 0.7 | 2.25.64058019325784235774105718339367403144 | 0.0 | 9600.0 | 15 | [1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000] | [-158.700, -153.500, -189.750] | [ORIGINAL, PRIMARY, AXIAL] | 13 | 120.0 | GE MEDICAL SYSTEMS | LightSpeed VCT | CT | ID00007637202177411956430 | (I, D, 0, 0, 0, 0, 7, 6, 3, 7, 2, 0, 2, 1, 7, 7, 4, 1, 1, 9, 5, 6, 4, 3, 0) | FFS | | MONOCHROME2 | -2000.0 | 1 | [0.652344, 0.652344] | SN | -1024.0 | 1.0 | HU | CW | 512 | 2.25.116080798158038264329904205296840554047 | 1 | 2.25.51769600465874599901723496946193454321 | -189.75 | 1.25 | ISO_IR 100 | | 2.25.80896671862726099888461805953012988790 | 130.0 | -500.0 | -1500.0 | 79.0 | -2000 | 2815 | 34.862141 | 1146.865109 | 4815 | 0.425553 | 262144 | 334.000128 | 334.000128 | 1115.560855 | 139.445107 | osic-pulmonary-fibrosis-progression/train/ID00007637202177411956430/13.dcm | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . Voxel Size and Volume . Voxel is 3D pixel having, pixel spacing = distance travelled by a pixel in x and y co-ordinates slice thickness as z coordinate . plt.tight_layout() fig, ax = plt.subplots(2, 2, figsize=(20,10)) sns.histplot(metadata_df.pixel_row_distance, ax = ax[0,0], color=&#39;green&#39;) sns.histplot(metadata_df.pixel_col_distance, ax = ax[0,1], color=&#39;blue&#39;) sns.histplot(metadata_df.slice_area_cm2, ax=ax[1,0], color=&#39;pink&#39;) sns.histplot(metadata_df.slice_vol_cm3, ax=ax[1, 1], color=&#39;magenta&#39;) ax[0,0].set_title(&quot;Pixel Rows Distace&quot;) ax[0,0].set_xlabel(&quot;Pixel Rows&quot;) ax[0,1].set_title(&quot;Pixel Column Distance&quot;) ax[0,1].set_xlabel(&quot;Pixel Columns&quot;) ax[1,0].set_title(&quot;CT-slice area in $cm^{2}$&quot;) ax[1,0].set_xlabel(&quot;Area in $cm^{2}$&quot;) ax[1,1].set_title(&quot;CT-slice volume in $cm^{3}$&quot;) ax[1,1].set_xlabel(&quot;Volume in $cm^{3}$&quot;) plt.show(ax[0,0]) . &lt;Figure size 640x480 with 0 Axes&gt; . highest_vol_patients = list(metadata_df[metadata_df.slice_vol_cm3 == max(metadata_df.slice_vol_cm3)][&#39;PatientID&#39;]) lowest_vol_patients = list(metadata_df[metadata_df.slice_vol_cm3 == min(metadata_df.slice_vol_cm3)][&#39;PatientID&#39;]) #load scans max_vol_scans = load_slices(f&quot;{TRAIN_IMG_PATH}/{highest_vol_patients[0]}&quot;) min_vol_scans = load_slices(f&quot;{TRAIN_IMG_PATH}/{lowest_vol_patients[0]}&quot;) #convert to HU max_vol_hu_imgs = get_pixels_hu(max_vol_scans) min_vol_hu_imgs = get_pixels_hu(min_vol_scans) #Apply Windowing # we can try with different window width and levels max_vol_window_img = apply_window(max_vol_hu_imgs[20], -600, 1200) min_vol_window_img = apply_window(min_vol_hu_imgs[18], -600, 1200) fig, ax = plt.subplots(1, 2, figsize=(20, 10)) ax[0].imshow(max_vol_window_img, cmap=&#39;YlGnBu&#39;) ax[0].set_title(&quot;CT with large volume&quot;) ax[1].imshow(min_vol_window_img, cmap=&#39;YlGnBu&#39;) ax[1].set_title(&quot;CT with min volume&quot;) plt.show(ax[0], ax[1]) . Resampling . metadata_df.SliceThickness.unique() #so when slice thickness is different then the voxel size of two images is also very much different . array([1.25 , 2. , 1. , 7. , 0.8 , 0.5 , 0.625 , 2.5 , 3. , 0.9 , 5. , 0.835938, 0.75 , 1.5 , 8. , 6.5 ]) . patient1 = train.Patient.unique()[0] patient2 = train.Patient.unique()[5] scans1 = load_slices(f&quot;{TRAIN_IMG_PATH}/{patient1}&quot;) scans2 = load_slices(f&quot;{TRAIN_IMG_PATH}/{patient2}&quot;) print(f&quot;{scans1[0].SliceThickness}, {scans1[0].PixelSpacing}&quot;) print(f&quot;{scans2[0].SliceThickness}, {scans2[0].PixelSpacing}&quot;) . 1.250000, [0.652344, 0.652344] 1.250000, [0.798828, 0.798828] . patient1_hu_scans = get_pixels_hu(scans1) patient2_hu_scans = get_pixels_hu(scans2) . def resample(image, scan, new_spacing=[1,1,1]): # Determine current pixel spacing spacing = np.array([scan[0].SliceThickness] + list(scan[0].PixelSpacing), dtype=np.float32) resize_factor = spacing / new_spacing new_real_shape = image.shape * resize_factor new_shape = np.round(new_real_shape) real_resize_factor = new_shape / image.shape new_spacing = spacing / real_resize_factor image = scipy.ndimage.interpolation.zoom(image, real_resize_factor) return image, new_spacing . image1, rounded_new_spacing1 = resample(patient1_hu_scans, scans1, [1,1,1]) image2, rounded_new_spacing2 = resample(patient2_hu_scans, scans2, [1,1,1]) print(f&quot;Original shape : {patient2_hu_scans.shape}&quot;) print(f&quot;Shape after resampling : {image2.shape}&quot;) . Original shape : (31, 843, 888) Shape after resampling : (39, 673, 709) . 3D Plotting . def plot_3d(image,threshold=800): # Position the scan upright, # so the head of the patient would be at the top facing the # camera p = image.transpose(2,1,0) verts, faces, _, _ = measure.marching_cubes_lewiner(p, threshold) fig = plt.figure(figsize=(10, 10)) ax = fig.add_subplot(111, projection=&#39;3d&#39;) # Fancy indexing: `verts[faces]` to generate a collection of # triangles mesh = Poly3DCollection(verts[faces], alpha=0.70) face_color = [0.35, 0.65, 0.75] mesh.set_facecolor(face_color) ax.add_collection3d(mesh) ax.set_xlim(0, p.shape[0]) ax.set_ylim(0, p.shape[1]) ax.set_zlim(0, p.shape[2]) plt.show() . plot_3d(image1) . &lt;ipython-input-26-494062cc5696&gt;:8: FutureWarning: marching_cubes_lewiner is deprecated in favor of marching_cubes. marching_cubes_lewiner will be removed in version 0.19 verts, faces, _, _ = measure.marching_cubes_lewiner(p, threshold) . plot_3d(patient1_hu_scans) . &lt;ipython-input-26-494062cc5696&gt;:8: FutureWarning: marching_cubes_lewiner is deprecated in favor of marching_cubes. marching_cubes_lewiner will be removed in version 0.19 verts, faces, _, _ = measure.marching_cubes_lewiner(p, threshold) . Segmentation . steps . Normalization of image | Clustering for separating lung with everything else | Threshold image | morphology- erosion followed by dialation | label different regions wih different colors | create lung mask | apply mask on original image and get final masked image | def make_lungmask(img, display=False): row_size = img.shape[0] col_size = img.shape[1] mean = np.mean(img) std = np.std(img) img = img-mean img = img/std # Find the average pixel value near the lungs # to renormalize washed out images middle = img[int(col_size/5):int(col_size/5*4), int(row_size/5):int(row_size/5*4)] mean = np.mean(middle) max = np.max(img) min = np.min(img) # to improve threshold finding, i&#39;m moving the underflow and overflow on the pixel spectrum img[img==max] = mean img[img==min] = mean # using kmeans to seperate foreground ( soft tissue / bone) and background (lung/air) kmeans = KMeans(n_clusters=2).fit(np.reshape(middle,[np.prod(middle.shape),1])) centers = sorted(kmeans.cluster_centers_.flatten()) threshold = np.mean(centers) # Threshold the image and the o/p will be a binary image, morphology works either on binary or gray scale images thresh_img = np.where(img&lt;threshold, 1.0, 0.0) eroded = morphology.erosion(thresh_img, np.ones([3,3])) dilation = morphology.dilation(eroded, np.ones([8,8])) labels = measure.label(dilation) # different labels are displayed in different colors label_vals = np.unique(labels) regions = measure.regionprops(labels) good_labels = [] for prop in regions: B = prop.bbox if B[2]-B[0]&lt;row_size/10*9 and B[3]-B[1]&lt;col_size/10*9 and B[0]&gt;row_size/5 and B[2]&lt;col_size/5*4: good_labels.append(prop.label) mask = np.ndarray([row_size, col_size], dtype=np.int8) mask[:]=0 # after just the lungs are left, we do another large dilation in prder to fill in and out lung mask for N in good_labels: mask = mask + np.where(labels==N,1,0) mask = morphology.dilation(mask,np.ones([10,10])) #last dilation if (display): fig, ax = plt.subplots(3, 2, figsize=[12, 12]) ax[0, 0].set_title(&quot;Original&quot;) ax[0, 0].imshow(img, cmap=&#39;gray&#39;) ax[0, 0].axis(&#39;off&#39;) ax[0, 1].set_title(&quot;Threshold&quot;) ax[0, 1].imshow(thresh_img, cmap=&#39;gray&#39;) ax[0, 1].axis(&#39;off&#39;) ax[1, 0].set_title(&quot;After Erosion and Dilation&quot;) ax[1, 0].imshow(dilation, cmap=&#39;gray&#39;) ax[1, 0].axis(&#39;off&#39;) ax[1, 1].set_title(&quot;Color Labels&quot;) ax[1, 1].imshow(labels) ax[1, 1].axis(&#39;off&#39;) ax[2, 0].set_title(&quot;Final Mask&quot;) ax[2, 0].imshow(mask, cmap=&#39;gray&#39;) ax[2, 0].axis(&#39;off&#39;) ax[2, 1].set_title(&quot;Apply Mask on Original&quot;) ax[2, 1].imshow(mask*img, cmap=&#39;gray&#39;) ax[2, 1].axis(&#39;off&#39;) plt.show() return mask*img . make_lungmask(image1[14], True) . array([[-0., -0., -0., ..., -0., -0., -0.], [-0., -0., -0., ..., -0., -0., -0.], [-0., -0., -0., ..., -0., -0., -0.], ..., [-0., -0., -0., ..., -0., -0., -0.], [-0., -0., -0., ..., -0., -0., -0.], [-0., -0., -0., ..., -0., -0., -0.]]) . def get_rows_cols(size): cols = 6 rows = size // cols if (int(size%cols) != 0): rows = rows+1 return rows,cols . def plot_stack(stack, start_with=10, show_every=3): size = (len(stack) - (start_with - 1))//show_every rows, cols = get_rows_cols(size) plt.tight_layout() fig,ax = plt.subplots(rows,cols,figsize=[12,12]) for i in range(size-1): ind = start_with + i*show_every ax[int(i/cols),int(i % cols)].set_title(&#39;slice %d&#39; % ind) ax[int(i/cols),int(i % cols)].imshow(stack[ind],cmap=&#39;gray&#39;) ax[int(i/cols),int(i % cols)].axis(&#39;off&#39;) plt.show() . plot_stack(patient1_hu_scans, start_with=0, show_every=1) . &lt;Figure size 640x480 with 0 Axes&gt; . masked_lung = [] for img in image1: masked_lung.append(make_lungmask(img)) plot_stack(masked_lung, start_with=0, show_every=1) . &lt;Figure size 640x480 with 0 Axes&gt; . To Save Segmented image to png/npz format . path = &quot;./segmented-images&quot; if not shutil.os.path.isdir(path): shutil.os.mkdir(path) . patients = train.Patient.unique()[0:10] for patient in patients: . #if not shutil.os.path.isdir(path + &quot;/&quot; + patient): # shutil.os.mkdir(path + &quot;/&quot; + patient) scans = load_slices(f&#39;{TRAIN_IMG_PATH}/{patient}&#39;) hu_imgs = get_pixels_hu(scans) rescaled_images, spacing = resample(hu_imgs, scans,[1,1,1]) masked_lung = [] for img_number in range(len(rescaled_images)): window_img = apply_window(rescaled_images[img_number], -600, 1200) masked_img = make_lungmask(window_img) masked_lung.append(masked_img) #cv2.imwrite(f&#39;{path}/{patient}/{img_number + 1}.png&#39;, masked_img) # Comment the below line if images required to store in .png format. np.savez(f&#39;{path}/{patient}&#39;,masked_lung) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/07/18/OSIC-PULMONARY.html",
            "relUrl": "/2021/07/18/OSIC-PULMONARY.html",
            "date": " • Jul 18, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Time Series Anomaly Detection and LSTM Autoencoder for ECG Data using Pytorch",
            "content": "Importing Libraries . import torch import copy import numpy as np import pandas as pd import seaborn as sns from pylab import rcParams import matplotlib.pyplot as plt from matplotlib import rc from sklearn.model_selection import train_test_split from torch import nn, optim import torch.nn.functional as F from arff2pandas import a2p %matplotlib inline %config InlineBackend.figure_format=&#39;retina&#39; sns.set(style=&#39;whitegrid&#39;, palette=&#39;muted&#39;, font_scale=1.2) HAPPY_COLORS_PALETTE = [&quot;#01BEFE&quot;, &quot;#FFDD00&quot;, &quot;#FF7D00&quot;, &quot;#FF006D&quot;, &quot;#ADFF02&quot;, &quot;#8F00FF&quot;] sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE)) rcParams[&#39;figure.figsize&#39;] = 12, 8 RANDOM_SEED = 42 np.random.seed(RANDOM_SEED) torch.manual_seed(RANDOM_SEED) . &lt;torch._C.Generator at 0x7f976c556370&gt; . Dataset Description . We have 5 types of hearbeats (classes): . Normal (N) | R-on-T Premature Ventricular Contraction (R-on-T PVC) | Premature Ventricular Contraction (PVC) | Supra-ventricular Premature or Ectopic Beat (SP or EB) | Unclassified Beat (UB). | . Assuming a healthy heart and a typical rate of 70 to 75 beats per minute, each cardiac cycle, or heartbeat, takes about 0.8 seconds to complete the cycle. Frequency: 60–100 per minute (Humans) Duration: 0.6–1 second (Humans) . device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;) . device . device(type=&#39;cuda&#39;) . with open(&#39;ECG5000_TRAIN.arff&#39;) as f: train = a2p.load(f) with open(&#39;ECG5000_TEST.arff&#39;) as f: test = a2p.load(f) . df = train.append(test) df = df.sample(frac=1.0) df.shape . (5000, 141) . df.head() . att1@NUMERIC att2@NUMERIC att3@NUMERIC att4@NUMERIC att5@NUMERIC att6@NUMERIC att7@NUMERIC att8@NUMERIC att9@NUMERIC att10@NUMERIC ... att132@NUMERIC att133@NUMERIC att134@NUMERIC att135@NUMERIC att136@NUMERIC att137@NUMERIC att138@NUMERIC att139@NUMERIC att140@NUMERIC target@{1,2,3,4,5} . 1001 1.469756 | -1.048520 | -3.394356 | -4.254399 | -4.162834 | -3.822570 | -3.003609 | -1.799773 | -1.500033 | -1.025095 | ... | 0.945178 | 1.275588 | 1.617218 | 1.580279 | 1.306195 | 1.351674 | 1.915517 | 1.672103 | -1.039932 | 1 | . 2086 -1.998602 | -3.770552 | -4.267091 | -4.256133 | -3.515288 | -2.554540 | -1.699639 | -1.566366 | -1.038815 | -0.425483 | ... | 1.008577 | 1.024698 | 1.051141 | 1.015352 | 0.988475 | 1.050191 | 1.089509 | 1.465382 | 0.799517 | 1 | . 2153 -1.187772 | -3.365038 | -3.695653 | -4.094781 | -3.992549 | -3.425381 | -2.057643 | -1.277729 | -1.307397 | -0.623098 | ... | 1.085007 | 1.467196 | 1.413850 | 1.283822 | 0.923126 | 0.759235 | 0.932364 | 1.216265 | -0.824489 | 1 | . 555 0.604969 | -1.671363 | -3.236131 | -3.966465 | -4.067820 | -3.551897 | -2.582864 | -1.804755 | -1.688151 | -1.025897 | ... | 0.545222 | 0.649363 | 0.986846 | 1.234495 | 1.280039 | 1.215985 | 1.617971 | 2.196543 | 0.023843 | 1 | . 205 -1.197203 | -3.270123 | -3.778723 | -3.977574 | -3.405060 | -2.392634 | -1.726322 | -1.572748 | -0.920075 | -0.388731 | ... | 0.828168 | 0.914338 | 1.063077 | 1.393479 | 1.469756 | 1.392281 | 1.144732 | 1.668263 | 1.734676 | 1 | . 5 rows × 141 columns . CLASS_NORMAL = 1 class_names = [&#39;Normal&#39;, &#39;R on T&#39;, &#39;PVC&#39;, &#39;SP&#39;, &#39;UB&#39;] . new_columns = list(df.columns) new_columns[-1] = &#39;target&#39; df.columns = new_columns . df.head() . att1@NUMERIC att2@NUMERIC att3@NUMERIC att4@NUMERIC att5@NUMERIC att6@NUMERIC att7@NUMERIC att8@NUMERIC att9@NUMERIC att10@NUMERIC ... att132@NUMERIC att133@NUMERIC att134@NUMERIC att135@NUMERIC att136@NUMERIC att137@NUMERIC att138@NUMERIC att139@NUMERIC att140@NUMERIC target . 1001 1.469756 | -1.048520 | -3.394356 | -4.254399 | -4.162834 | -3.822570 | -3.003609 | -1.799773 | -1.500033 | -1.025095 | ... | 0.945178 | 1.275588 | 1.617218 | 1.580279 | 1.306195 | 1.351674 | 1.915517 | 1.672103 | -1.039932 | 1 | . 2086 -1.998602 | -3.770552 | -4.267091 | -4.256133 | -3.515288 | -2.554540 | -1.699639 | -1.566366 | -1.038815 | -0.425483 | ... | 1.008577 | 1.024698 | 1.051141 | 1.015352 | 0.988475 | 1.050191 | 1.089509 | 1.465382 | 0.799517 | 1 | . 2153 -1.187772 | -3.365038 | -3.695653 | -4.094781 | -3.992549 | -3.425381 | -2.057643 | -1.277729 | -1.307397 | -0.623098 | ... | 1.085007 | 1.467196 | 1.413850 | 1.283822 | 0.923126 | 0.759235 | 0.932364 | 1.216265 | -0.824489 | 1 | . 555 0.604969 | -1.671363 | -3.236131 | -3.966465 | -4.067820 | -3.551897 | -2.582864 | -1.804755 | -1.688151 | -1.025897 | ... | 0.545222 | 0.649363 | 0.986846 | 1.234495 | 1.280039 | 1.215985 | 1.617971 | 2.196543 | 0.023843 | 1 | . 205 -1.197203 | -3.270123 | -3.778723 | -3.977574 | -3.405060 | -2.392634 | -1.726322 | -1.572748 | -0.920075 | -0.388731 | ... | 0.828168 | 0.914338 | 1.063077 | 1.393479 | 1.469756 | 1.392281 | 1.144732 | 1.668263 | 1.734676 | 1 | . 5 rows × 141 columns . Exploratory Data Analysis . df.target.value_counts() . 1 2919 2 1767 4 194 3 96 5 24 Name: target, dtype: int64 . ax = sns.countplot(df.target) ax.set_xticklabels(class_names); . /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( . The normal class, has by far, the most examples. This is great because we&#39;ll use it to train our model. . Let&#39;s have a look at an averaged (smoothed out with one standard deviation on top and bottom of it) Time Series for each class: . def plot_time_series_class(data, class_name, ax, n_steps=10): time_series_df = pd.DataFrame(data) smooth_path = time_series_df.rolling(n_steps).mean() path_deviation = 2 * time_series_df.rolling(n_steps).std() under_line = (smooth_path - path_deviation)[0] over_line = (smooth_path + path_deviation)[0] ax.plot(smooth_path, linewidth=2) ax.fill_between( path_deviation.index, under_line, over_line, alpha=.125 ) ax.set_title(class_name) . classes = df.target.unique() fig, axs = plt.subplots( nrows = len(classes) // 3 + 1, ncols = 3, sharey=True, figsize=(14,8) ) for i, cls in enumerate(classes): ax = axs.flat[i] data = df[df.target == cls] .drop(labels=&#39;target&#39;, axis=1) .mean(axis=0) .to_numpy() plot_time_series_class(data, class_names[i], ax) fig.delaxes(axs.flat[-1]) fig.tight_layout(); . LSTM Autoencoder . I&#39;ll have a look at how to feed Time Series data to an Autoencoder. We&#39;ll use a couple of LSTM layers (hence the LSTM Autoencoder) to capture the temporal dependencies of the data. . To classify a sequence as normal or an anomaly, we&#39;ll pick a threshold above which a heartbeat is considered abnormal. . Reconstruction Loss . When training an Autoencoder, the objective is to reconstruct the input as best as possible. This is done by minimizing a loss function (just like in supervised learning). This function is known as reconstruction loss. Cross-entropy loss and Mean squared error are common examples. . Data Preprocessing . normal_df = df[df.target == str(CLASS_NORMAL)].drop(labels=&#39;target&#39;, axis=1) normal_df.shape . (2919, 140) . anomaly_df = df[df.target != str(CLASS_NORMAL)].drop(labels=&#39;target&#39;, axis=1) anomaly_df.shape . (2081, 140) . train_df, val_df = train_test_split( normal_df, test_size=0.15, random_state=RANDOM_SEED ) val_df, test_df = train_test_split( val_df, test_size=0.33, random_state=RANDOM_SEED ) . print(test_df.shape) print(val_df.shape) print(test_df.shape) . (145, 140) (293, 140) (145, 140) . def create_dataset(df): sequences = df.astype(np.float32).to_numpy().tolist() dataset = [torch.tensor(s).unsqueeze(1).float() for s in sequences] n_seq, seq_len, n_features = torch.stack(dataset).shape return dataset, seq_len, n_features . Each Time Series will be converted to a 2D Tensor in the shape sequence length x number of features (140x1 in our case). . train_dataset, seq_len, n_features = create_dataset(train_df) val_dataset, _, _ = create_dataset(val_df) test_normal_dataset, _, _ = create_dataset(test_df) test_anomaly_dataset, _, _ = create_dataset(anomaly_df) . LSTM Autoencoder . The general Autoencoder architecture consists of two components. An Encoder that compresses the input and a Decoder that tries to reconstruct it. . We&#39;ll use the LSTM Autoencoder from this GitHub repo with some small tweaks. Our model&#39;s job is to reconstruct Time Series data. Let&#39;s start with the Encoder: . class Encoder(nn.Module): def __init__(self, seq_len, n_features, embedding_dim=64): super(Encoder, self).__init__() self.seq_len, self.n_features = seq_len, n_features self.embedding_dim, self.hidden_dim = embedding_dim, 2 * embedding_dim self.rnn1 = nn.LSTM( input_size=n_features, hidden_size=self.hidden_dim, num_layers=1, batch_first=True ) self.rnn2 = nn.LSTM( input_size=self.hidden_dim, hidden_size=embedding_dim, num_layers=1, batch_first=True ) def forward(self, x): x = x.reshape((1, self.seq_len, self.n_features)) x, (_, _) = self.rnn1(x) x, (hidden_n, _) = self.rnn2(x) return hidden_n.reshape((self.n_features, self.embedding_dim)) . class Decoder(nn.Module): def __init__(self, seq_len, input_dim=64, n_features=1): super(Decoder, self).__init__() self.seq_len, self.input_dim = seq_len, input_dim self.hidden_dim, self.n_features = 2 * input_dim, n_features self.rnn1 = nn.LSTM( input_size=input_dim, hidden_size=input_dim, num_layers=1, batch_first=True ) self.rnn2 = nn.LSTM( input_size=input_dim, hidden_size=self.hidden_dim, num_layers=1, batch_first=True ) self.output_layer = nn.Linear(self.hidden_dim, n_features) def forward(self, x): x = x.repeat(self.seq_len, self.n_features) x = x.reshape((self.n_features, self.seq_len, self.input_dim)) x, (hidden_n, cell_n) = self.rnn1(x) x, (hidden_n, cell_n) = self.rnn2(x) x = x.reshape((self.seq_len, self.hidden_dim)) return self.output_layer(x) . class RecurrentAutoencoder(nn.Module): def __init__(self, seq_len, n_features, embedding_dim=64): super(RecurrentAutoencoder, self).__init__() self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device) self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device) def forward(self, x): x = self.encoder(x) x = self.decoder(x) return x . model = RecurrentAutoencoder(seq_len, n_features, 128) model = model.to(device) . Training . def train_model(model, train_dataset, val_dataset, n_epochs): optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) criterion = nn.L1Loss(reduction=&#39;sum&#39;).to(device) history = dict(train=[], val=[]) best_model_wts = copy.deepcopy(model.state_dict()) best_loss = 10000.0 for epoch in range(1, n_epochs + 1): model = model.train() train_losses = [] for seq_true in train_dataset: optimizer.zero_grad() seq_true = seq_true.to(device) seq_pred = model(seq_true) loss = criterion(seq_pred, seq_true) loss.backward() optimizer.step() train_losses.append(loss.item()) val_losses = [] model = model.eval() with torch.no_grad(): for seq_true in val_dataset: seq_true = seq_true.to(device) seq_pred = model(seq_true) loss = criterion(seq_pred, seq_true) val_losses.append(loss.item()) train_loss = np.mean(train_losses) val_loss = np.mean(val_losses) history[&#39;train&#39;].append(train_loss) history[&#39;val&#39;].append(val_loss) if val_loss &lt; best_loss: best_loss = val_loss best_model_wts = copy.deepcopy(model.state_dict()) print(f&#39;Epoch {epoch}: train loss {train_loss} val loss {val_loss}&#39;) model.load_state_dict(best_model_wts) return model.eval(), history . model, history = train_model( model, train_dataset, val_dataset, n_epochs=10 ) . Epoch 1: train loss 78.96793919924237 val loss 57.008918449740364 Epoch 2: train loss 55.24031583285534 val loss 51.29970774471556 Epoch 3: train loss 50.97752316869684 val loss 50.35719702919189 Epoch 4: train loss 50.59584151271465 val loss 40.614140123230605 Epoch 5: train loss 38.15368703352449 val loss 37.547762724319824 Epoch 6: train loss 34.309216836055214 val loss 37.58409660261239 Epoch 7: train loss 31.98069694416026 val loss 34.298767298154864 Epoch 8: train loss 28.60677365553278 val loss 27.40926725628433 Epoch 9: train loss 26.80304576254141 val loss 24.187094398732885 Epoch 10: train loss 25.63979911073856 val loss 29.823875609518318 . ax = plt.figure().gca() ax.plot(history[&#39;train&#39;]) ax.plot(history[&#39;val&#39;]) plt.ylabel(&#39;Loss&#39;) plt.xlabel(&#39;Epoch&#39;) plt.legend([&#39;train&#39;, &#39;test&#39;]) plt.title(&#39;Loss over training epochs&#39;) plt.show(); . MODEL_PATH = &#39;Time-Series-ECG5000-Pytorch.pth&#39; torch.save(model, MODEL_PATH) . Choosing a threshold . def predict(model, dataset): predictions, losses = [], [] criterion = nn.L1Loss(reduction=&#39;sum&#39;).to(device) with torch.no_grad(): model = model.eval() for seq_true in dataset: seq_true = seq_true.to(device) seq_pred = model(seq_true) loss = criterion(seq_pred, seq_true) predictions.append(seq_pred.cpu().numpy().flatten()) losses.append(loss.item()) return predictions, losses . _, losses = predict(model, train_dataset) sns.distplot(losses, bins=50, kde=True); . /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms). warnings.warn(msg, FutureWarning) . THRESHOLD = 26 . Evaluation . Normal hearbeats . predictions, pred_losses = predict(model, test_normal_dataset) sns.distplot(pred_losses, bins=50, kde=True); . /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms). warnings.warn(msg, FutureWarning) . correct = sum(l &lt;= THRESHOLD for l in pred_losses) print(f&#39;Correct normal predictions: {correct}/{len(test_normal_dataset)}&#39;) . Correct normal predictions: 111/145 . Anomalies . anomaly_dataset = test_anomaly_dataset[:len(test_normal_dataset)] . predictions, pred_losses = predict(model, anomaly_dataset) sns.distplot(pred_losses, bins=50, kde=True); . /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms). warnings.warn(msg, FutureWarning) . correct = sum(l &gt; THRESHOLD for l in pred_losses) print(f&#39;Correct anomaly predictions: {correct}/{len(anomaly_dataset)}&#39;) . Correct anomaly predictions: 144/145 . Looking at Examples . def plot_prediction(data, model, title, ax): predictions, pred_losses = predict(model, [data]) ax.plot(data, label=&#39;true&#39;) ax.plot(predictions[0], label=&#39;reconstructed&#39;) ax.set_title(f&#39;{title} (loss: {np.around(pred_losses[0], 2)})&#39;) ax.legend() . fig, axs = plt.subplots( nrows=2, ncols=6, sharey=True, sharex=True, figsize=(24, 8) ) for i, data in enumerate(test_normal_dataset[:6]): plot_prediction(data, model, title=&#39;Normal&#39;, ax=axs[0, i]) for i, data in enumerate(test_anomaly_dataset[:6]): plot_prediction(data, model, title=&#39;Anomaly&#39;, ax=axs[1, i]) fig.tight_layout(); .",
            "url": "https://mr-siddy.github.io/ML-blog/rnn/2021/07/17/Time-Series-ECG5000-Pytorch.html",
            "relUrl": "/rnn/2021/07/17/Time-Series-ECG5000-Pytorch.html",
            "date": " • Jul 17, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Transfer Learning for Image Classification in PyTorch",
            "content": "How CNN Learns . see CNN explainer - poloclub cnn . Pytorch CNN visualizations - very cool github . . Layer Visualizations - . CNN creates a layered understanding of data, Idea behind transfer learning is we take a CNN that has been already trained on a very large dataset (ex: Imagenet) ie. pretrained model, and we use some of the layers of these model to train custom models for a custom datasets that we are working with, so the features learned in those layers they are going to be useful for solving any image classifiation problem or any CV problem, the only needs to change is the classifier in the end . Dataset: Qxford-IIIT Pets dataset : https://www.robots.ox.ac.uk/~vgg/data/pets/ . from torchvision.datasets.utils import download_url . download_url(&#39;https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz&#39;,&#39;.&#39;) . import tarfile with tarfile.open(&#39;./oxford-iiit-pet.tgz&#39;, &#39;r:gz&#39;) as tar: tar.extractall(path=&#39;./data&#39;) . import os DATA_DIR = &#39;./data/oxford-iiit-pet/images&#39; files = os.listdir(DATA_DIR) files[:5] . [&#39;Maine_Coon_238.jpg&#39;, &#39;staffordshire_bull_terrier_32.jpg&#39;, &#39;great_pyrenees_10.jpg&#39;, &#39;leonberger_57.jpg&#39;, &#39;scottish_terrier_2.jpg&#39;] . def parse_breed(fname): parts = fname.split(&#39;_&#39;) return &#39; &#39;.join(parts[:-1]) . parse_breed(files[3]) . &#39;leonberger&#39; . from PIL import Image def open_image(path): with open(path, &#39;rb&#39;) as f: img = Image.open(f) return img.convert(&#39;RGB&#39;) . import matplotlib.pyplot as plt plt.imshow(open_image(os.path.join(DATA_DIR,files[4]))) . &lt;matplotlib.image.AxesImage at 0x7f0fd892b580&gt; . plt.imshow(open_image(os.path.join(DATA_DIR,files[500]))) . &lt;matplotlib.image.AxesImage at 0x7f0fd504dc40&gt; . Creating a Custom Pytorch Dataset . from torch.utils.data import Dataset # Dataset class needs 3 funcs to be implemented -- __init__, __len__, __getitem__ class PetsDataset(Dataset): def __init__(self, root, transform): super().__init__() self.root = root self.files = [fname for fname in os.listdir(root) if fname.endswith(&#39;.jpg&#39;)] self.classes = list(set(parse_breed(fname) for fname in files)) self.transform = transform def __len__(self): return len(self.files) def __getitem__(self, i): fname = self.files[i] fpath = os.path.join(self.root, fname) img = self.transform(open_image(fpath)) class_idx = self.classes.index(parse_breed(fname)) return img, class_idx . import torchvision.transforms as T img_size = 224 imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization stats that were used to normalize imagenet model dataset = PetsDataset(DATA_DIR, T.Compose([T.Resize(img_size), T.Pad(8, padding_mode=&#39;reflect&#39;), T.RandomCrop(img_size), T.ToTensor(), T.Normalize(*imagenet_stats)])) . len(dataset) . 7390 . dataset.classes . [&#39;english setter&#39;, &#39;chihuahua&#39;, &#39;german shorthaired&#39;, &#39;beagle&#39;, &#39;leonberger&#39;, &#39;newfoundland&#39;, &#39;Russian Blue&#39;, &#39;basset hound&#39;, &#39;american bulldog&#39;, &#39;scottish terrier&#39;, &#39;Ragdoll&#39;, &#39;pug&#39;, &#39;Abyssinian&#39;, &#39;Sphynx&#39;, &#39;english cocker spaniel&#39;, &#39;great pyrenees&#39;, &#39;Siamese&#39;, &#39;pomeranian&#39;, &#39;Persian&#39;, &#39;Maine Coon&#39;, &#39;Egyptian Mau&#39;, &#39;Bombay&#39;, &#39;Birman&#39;, &#39;miniature pinscher&#39;, &#39;keeshond&#39;, &#39;boxer&#39;, &#39;shiba inu&#39;, &#39;British Shorthair&#39;, &#39;saint bernard&#39;, &#39;staffordshire bull terrier&#39;, &#39;havanese&#39;, &#39;Bengal&#39;, &#39;wheaten terrier&#39;, &#39;samoyed&#39;, &#39;japanese chin&#39;, &#39;american pit bull terrier&#39;, &#39;yorkshire terrier&#39;] . len(dataset.classes) . 37 . import torch torch.cuda.empty_cache() import matplotlib.pyplot as plt %matplotlib inline def denormalize(images, means, stds): if len(images.shape) ==3: images = images.unsqueeze(0) means = torch.tensor(means).reshape(1,3,1,1) stds = torch.tensor(stds).reshape(1,3,1,1) return images*stds + means def show_image(img_tensor, label): print(&#39;Label:&#39;, dataset.classes[label], &#39;(&#39; + str(label) + &#39;)&#39;) img_tensor = denormalize(img_tensor, *imagenet_stats)[0].permute((1, 2, 0)) plt.imshow(img_tensor) . show_image(*dataset[10]) . Label: staffordshire bull terrier (29) . show_image(*dataset[111]) . Label: Abyssinian (12) . Creating Training and Validation Sets . from torch.utils.data import random_split . val_pct = 0.1 val_size = int(val_pct *len(dataset)) train_ds, valid_ds = random_split(dataset, [len(dataset) - val_size, val_size]) . len(train_ds), len(valid_ds) . (6651, 739) . from torch.utils.data import DataLoader batch_size = 64 train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True) valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=4, pin_memory=True) . from torchvision.utils import make_grid def show_batch(dl): for images, labels in dl: fig, ax = plt.subplots(figsize=(16, 16)) ax.set_xticks([]); ax.set_yticks([]) images = denormalize(images[:64], *imagenet_stats) ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0)) break . show_batch(train_dl) . Modifying a Pretrained Model (ResNet34) . Transfer learning : https://ruder.io/transfer-learning/ . import torch.nn as nn import torch.nn.functional as F def accuracy(outputs, labels): _, preds = torch.max(outputs, dim=1) return torch.tensor(torch.sum(preds == labels).item()/ len(preds)) class ImageClassificationBase(nn.Module): def training_step(self, batch): images, labels = batch out = self(images) loss = F.cross_entropy(out, labels) return loss def validation_step(self, batch): images, labels = batch out = self(images) loss = F.cross_entropy(out, labels) acc = accuracy(out, labels) return {&#39;val_loss&#39;: loss.detach(), &#39;val_acc&#39;: acc} def validation_epoch_end(self, outputs): batch_losses = [x[&#39;val_loss&#39;] for x in outputs] epoch_loss = torch.stack(batch_losses).mean() batch_accs = [x[&#39;val_acc&#39;] for x in outputs] epoch_acc = torch.stack(batch_accs).mean() return {&#39;val_loss&#39;: epoch_loss.item(), &#39;val_acc&#39;: epoch_acc.item()} def epoch_end(self, epoch, result): print(&quot;Epoch [{}], {} train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}&quot;.format( epoch, &quot;last_lr: {:.5f}&quot;.format(result[&#39;lrs&#39;][-1]) if &#39;lrs&#39; in result else &#39;&#39;, result[&#39;train_loss&#39;], result[&#39;val_loss&#39;], result[&#39;val_acc&#39;])) . from torchvision import models class PetsModel(ImageClassificationBase): def __init__(self, num_classes, pretrained=True): super().__init__() #use a pretrained mode self.network = models.resnet34(pretrained = pretrained) #replace last layer self.network.fc = nn.Linear(self.network.fc.in_features, num_classes) def forward(self, xb): return self.network(xb) . resnet = models.resnet34(pretrained=True) #condesed knowledge is captured and we got them bro we got them . resnet . ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer2): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer3): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (4): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (5): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (layer4): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=512, out_features=1000, bias=True) ) . GPU Utilities and Training Loop . def get_default_device(): &quot;&quot;&quot;Pick GPU if available, else CPU&quot;&quot;&quot; if torch.cuda.is_available(): return torch.device(&#39;cuda&#39;) else: return torch.device(&#39;cpu&#39;) def to_device(data, device): &quot;&quot;&quot;Move tensor(s) to chosen device&quot;&quot;&quot; if isinstance(data, (list, tuple)): return [to_device(x, device) for x in data] return data.to(device, non_blocking=True) class DeviceDataLoader(): &quot;&quot;&quot;Wrap a dataloader to move data to a device&quot;&quot;&quot; def __init__(self, dl, device): self.dl = dl self.device = device def __iter__(self): &quot;&quot;&quot;Yield a batch of data after moving it to device&quot;&quot;&quot; for b in self.dl: yield to_device(b, self.device) def __len__(self): &quot;&quot;&quot;Number of batches&quot;&quot;&quot; return len(self.dl) . import torch from tqdm.notebook import tqdm @torch.no_grad() def evaluate(model, val_loader): model.eval() outputs = [model.validation_step(batch) for batch in val_loader] return model.validation_epoch_end(outputs) def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD): history = [] optimizer = opt_func(model.parameters(), lr) for epoch in range(epochs): # Training Phase model.train() train_losses = [] for batch in tqdm(train_loader): loss = model.training_step(batch) train_losses.append(loss) loss.backward() optimizer.step() optimizer.zero_grad() # Validation phase result = evaluate(model, val_loader) result[&#39;train_loss&#39;] = torch.stack(train_losses).mean().item() model.epoch_end(epoch, result) history.append(result) return history def get_lr(optimizer): for param_group in optimizer.param_groups: return param_group[&#39;lr&#39;] def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD): torch.cuda.empty_cache() history = [] # Set up custom optimizer with weight decay optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay) # Set up one-cycle learning rate scheduler sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader)) for epoch in range(epochs): # Training Phase model.train() train_losses = [] lrs = [] for batch in tqdm(train_loader): loss = model.training_step(batch) train_losses.append(loss) loss.backward() # Gradient clipping if grad_clip: nn.utils.clip_grad_value_(model.parameters(), grad_clip) optimizer.step() optimizer.zero_grad() # Record &amp; update learning rate lrs.append(get_lr(optimizer)) sched.step() # Validation phase result = evaluate(model, val_loader) result[&#39;train_loss&#39;] = torch.stack(train_losses).mean().item() result[&#39;lrs&#39;] = lrs model.epoch_end(epoch, result) history.append(result) return history . device = get_default_device() device . device(type=&#39;cuda&#39;) . train_dl = DeviceDataLoader(train_dl, device) valid_dl = DeviceDataLoader(valid_dl, device) . Finetuning the Pretrained Model . model = PetsModel(len(dataset.classes), pretrained = True) to_device(model, device); . history = [evaluate(model, valid_dl)] history . /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.) return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode) . [{&#39;val_loss&#39;: 3.8598475456237793, &#39;val_acc&#39;: 0.037063341587781906}] . epochs = 5 max_lr = 0.01 grad_clip = 0.1 weight_decay = 1e-4 opt_func = torch.optim.Adam . %%time history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, grad_clip = grad_clip, weight_decay = weight_decay, opt_func = opt_func) . Epoch [0], last_lr: 0.00757 train_loss: 2.0365, val_loss: 7.6447, val_acc: 0.0372 Epoch [1], last_lr: 0.00950 train_loss: 2.2747, val_loss: 2.6041, val_acc: 0.3282 Epoch [2], last_lr: 0.00611 train_loss: 1.6090, val_loss: 2.3778, val_acc: 0.3658 Epoch [3], last_lr: 0.00188 train_loss: 0.9982, val_loss: 1.0220, val_acc: 0.6620 Epoch [4], last_lr: 0.00000 train_loss: 0.5643, val_loss: 0.7257, val_acc: 0.7617 CPU times: user 3min 45s, sys: 1min 41s, total: 5min 26s Wall time: 5min 28s . torch.cuda.memory_summary(device=None, abbreviated=False) . &#39;|===========================================================================| n| PyTorch CUDA memory summary, device ID 0 | n|| n| CUDA OOMs: 4 | cudaMalloc retries: 8 | n|===========================================================================| n| Metric | Cur Usage | Peak Usage | Tot Alloc | Tot Freed | n|| n| Allocated memory | 336430 KB | 2387 MB | 7256 GB | 7256 GB | n| from large pool | 312192 KB | 2363 MB | 7244 GB | 7243 GB | n| from small pool | 24238 KB | 25 MB | 12 GB | 12 GB | n|| n| Active memory | 336430 KB | 2387 MB | 7256 GB | 7256 GB | n| from large pool | 312192 KB | 2363 MB | 7244 GB | 7243 GB | n| from small pool | 24238 KB | 25 MB | 12 GB | 12 GB | n|| n| GPU reserved memory | 2412 MB | 2474 MB | 6472 MB | 4060 MB | n| from large pool | 2384 MB | 2446 MB | 6438 MB | 4054 MB | n| from small pool | 28 MB | 28 MB | 34 MB | 6 MB | n|| n| Non-releasable memory | 527826 KB | 945 MB | 6983 GB | 6982 GB | n| from large pool | 525440 KB | 943 MB | 6967 GB | 6967 GB | n| from small pool | 2386 KB | 3 MB | 15 GB | 15 GB | n|| n| Allocations | 548 | 803 | 448412 | 447864 | n| from large pool | 72 | 147 | 185894 | 185822 | n| from small pool | 476 | 659 | 262518 | 262042 | n|| n| Active allocs | 548 | 803 | 448412 | 447864 | n| from large pool | 72 | 147 | 185894 | 185822 | n| from small pool | 476 | 659 | 262518 | 262042 | n|| n| GPU reserved segments | 37 | 43 | 71 | 34 | n| from large pool | 23 | 31 | 54 | 31 | n| from small pool | 14 | 14 | 17 | 3 | n|| n| Non-releasable allocs | 58 | 68 | 254011 | 253953 | n| from large pool | 14 | 30 | 84721 | 84707 | n| from small pool | 44 | 54 | 169290 | 169246 | n|===========================================================================| n&#39; . Training a model from scratch . model2 = PetsModel(len(dataset.classes), pretrained=False) to_device(model2, device); . history2 = [evaluate(model2, valid_dl)] history2 . [{&#39;val_loss&#39;: 44.194881439208984, &#39;val_acc&#39;: 0.02642308734357357}] . While the pretrained model reached an accuracy of 80% in less than 3 minutes, the model without pretrained weights could only reach an accuracy of 24%. .",
            "url": "https://mr-siddy.github.io/ML-blog/deep_learning/2021/07/08/Transfer-learning-pytorch.html",
            "relUrl": "/deep_learning/2021/07/08/Transfer-learning-pytorch.html",
            "date": " • Jul 8, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Anime Image Generation using GANS - Pytorch",
            "content": "Introduction to Generative Modeling . Generative Adversarial Networks (GANs) use neural network for generative modeling, It is an unsupervised learning task in machine learning that involves automatically discovering and learning the ragularities or patterns in input data in such a way that the model can be used to generate or output new examples that plausibly could have been drawn from the original dataset ex:- thispersondoesnotexist.com . . HOW this works bruh : . GAN have two different neural networks, Generator network(takes input a random vector and it generates an image) and Discriminator network(model whose job is to diffrentiate between real images which are drawn from dataset and generated images) . WAY the training works : . we train Discriminator on batches of both Real and Generated images so it should be good at discriminating, we then use discriminator as a part of the loss function of the Generator we take a generated image from the generator we pass them through the discriminator and we try to fool the discriminator, then update the generator. . Generator tries to fool and Discriminator tries to catch the bluff . . GANs are difficult to train and are extremely sensitive to hyperparameters, activation function and regularisation . More Resources: off convex blog, GANs and Divergence Minimization . Dataset : Anime Face Dataset --&gt; https://www.kaggle.com/splcher/animefacedataset . project_name = &#39;anime-dcgan&#39; . Download and Explore the dataset using opendatasets library import opendatasets as od dataset_url = &#39;https://www.kaggle.com/splcher/animefacedataset&#39; od.download(dataset_url) . import os DATA_DIR = &quot;./animefacedataset&quot; print(os.listdir(DATA_DIR)) . [&#39;images&#39;] . print(os.listdir(DATA_DIR + &quot;/images&quot;)[:10]) . [&#39;23203_2008.jpg&#39;, &#39;21344_2008.jpg&#39;, &#39;50099_2015.jpg&#39;, &#39;42947_2013.jpg&#39;, &#39;59998_2018.jpg&#39;, &#39;5180_2003.jpg&#39;, &#39;27731_2009.jpg&#39;, &#39;39250_2012.jpg&#39;, &#39;13478_2006.jpg&#39;, &#39;39408_2012.jpg&#39;] . from torch.utils.data import DataLoader from torchvision.datasets import ImageFolder import torchvision.transforms as T . image_size = 64 # crop images to 64x64 pixels batch_size = 128 stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) # normalize the pixel values with mean and std deviation of 0.5, to get pixel value in range (-1,1) . train_ds = ImageFolder(DATA_DIR, transform=T.Compose([ T.Resize(image_size), T.CenterCrop(image_size), T.ToTensor(), T.Normalize(*stats) ])) train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True) . import torch from torchvision.utils import make_grid import matplotlib.pyplot as plt %matplotlib inline . def denorm(img_tensors): #std=0.5 mean return img_tensors * stats[1][0] + stats[0][0] . def show_images(images, nmax=64): fig, ax = plt.subplots(figsize=(8, 8)) ax.set_xticks([]); ax.set_yticks([]) ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0)) #pytorch images have color channels in the first dimension, where as matplotlib require color channels to be in the last dimension so we permute def show_batch(dl, nmax=64): for images, _ in dl: show_images(images, nmax) break . show_batch(train_dl) . Utilities for working with GPUs . def get_default_device(): if torch.cuda.is_available(): return torch.device(&#39;cuda&#39;) else: return torch.device(&#39;cpu&#39;) def to_device(data, device): if isinstance(data, (list, tuple)): return [to_device(x, device) for x in data] return data.to(device, non_blocking=True) class DeviceDataLoader(): def __init__(self, dl, device): self.dl = dl self.device = device def __iter__(self): for b in self.dl: yield to_device(b, self.device) def __len__(self): return len(self.dl) . device = get_default_device() device . device(type=&#39;cuda&#39;) . train_dl = DeviceDataLoader(train_dl, device) . Discriminator Network . it takes image as input and tries to classify is as &#39;real&#39; or &#39;generated&#39;. I&#39;ll use CNN with binary classification . . Also we&#39;ll use Leaky ReLU as activation function and sigmod function too . . import torch.nn as nn . discriminator = nn.Sequential( # in: 3 x 64 x 64 nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(64), nn.LeakyReLU(0.2, inplace=True), # out: 64 x 32 x 32 nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(128), nn.LeakyReLU(0.2, inplace=True), # out: 128 x 16 x 16 nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(256), nn.LeakyReLU(0.2, inplace=True), # out: 256 x 8 x 8 nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(512), nn.LeakyReLU(0.2, inplace=True), # out: 512 x 4 x 4 nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False), # out: 1 x 1 x 1 nn.Flatten(), nn.Sigmoid() ) . Because we use discriminator as a part of the loss function to train the genrator, ReLU will lead to a lot of outputs from the generator being lost, so Leaky ReLU allows the pass of a gradient signal even for the negative value, that makes the gradients from the discriminator flows stronger into the generator. . so the idea here is,none of imformation whould get lost using discriminator and gradient function to train generator . discriminator = to_device(discriminator, device) . Generator Network . input to generator is typically a vector or a matrix of random numbers (ie. latent tensor) . Generator will take a latent tensor of shape (128, 1, 1) and convert to an image tensor of shape (3 x 28 x 28) . To achive this we&#39;ll use ConvTranspose2d Layer from pytorch, which performs as a transposed convolution of deconvolution . To get a better understanding of Transposed Convolution . also read this Convolution arithmetic . . latent_size = 128 . generator = nn.Sequential( # in: latent_size x 1 x 1 nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False), nn.BatchNorm2d(512), nn.ReLU(True), # out: 512 x 4 x 4 nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(256), nn.ReLU(True), # out: 256 x 8 x 8 nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(128), nn.ReLU(True), # out: 128 x 16 x 16 nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False), nn.BatchNorm2d(64), nn.ReLU(True), # out: 64 x 32 x 32 nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False), nn.Tanh() # out: 3 x 64 x 64 ) . we are using tanh(): . hyperbolic tangent activation function : reduces values into the range -1 to 1 --&gt; when 3 x 64 x 64 feature map is generated from convtranspose2d its values can range between -infy to infy , so it convert them to -1 to 1 so that outputs of images are in range -1 to 1 . xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors print(xb.shape) fake_images = generator(xb) print(fake_images.shape) show_images(fake_images) . torch.Size([128, 128, 1, 1]) torch.Size([128, 3, 64, 64]) . generator = to_device(generator, device) . Discriminator Training . as the Discriminator is a binary classifier, we can use binary cross entropy loss function to quantify how well it is able to differentiate between real and generated images . . def train_discriminator(real_images, opt_d): # clear discriminator gradients opt_d.zero_grad() # Pass real images through the discriminator real_preds = discriminator(real_images) real_targets = torch.ones(real_images.size(0), 1, device=device) real_loss = F.binary_cross_entropy(real_preds, real_targets) real_score = torch.mean(real_preds).item() # Generate fake images latent = torch.randn(batch_size, latent_size, 1, 1, device=device) fake_images = generator(latent) # Pass fake images through discriminator fake_targets = torch.zeros(fake_images.size(0), 1, device=device) fake_preds = discriminator(fake_images) fake_loss = F.binary_cross_entropy(fake_preds, fake_targets) fake_score = torch.mean(fake_preds).item() # Update discriminator weights loss = real_loss + fake_loss loss.backward() opt_d.step() return loss.item(), real_score, fake_score . Here are the steps involved in training the discriminator. . We expect the discriminator to output 1 if the image was picked from the real MNIST dataset, and 0 if it was generated using the generator network. . | We first pass a batch of real images, and compute the loss, setting the target labels to 1. . | Then we pass a batch of fake images (generated using the generator) pass them into the discriminator, and compute the loss, setting the target labels to 0. . | Finally we add the two losses and use the overall loss to perform gradient descent to adjust the weights of the discriminator. . | . It&#39;s important to note that we don&#39;t change the weights of the generator model while training the discriminator (opt_d only affects the discriminator.parameters()) . Generator Training . Since the outputs of the generator are images, it&#39;s not obvious how we can train the generator. This is where we employ a rather elegant trick, which is to use the discriminator as a part of the loss function. . We generate a batch of images using the generator, pass the into the discriminator. . | We calculate the loss by setting the target labels to 1 i.e. real. We do this because the generator&#39;s objective is to &quot;fool&quot; the discriminator. . | We use the loss to perform gradient descent i.e. change the weights of the generator, so it gets better at generating real-like images to &quot;fool&quot; the discriminator. . | . def train_generator(opt_g): opt_g.zero_grad() #generate fake images latent = torch.randn(batch_size, latent_size, 1, 1, device=device) fake_images = generator(latent) #try to fool the discriminator preds = discriminator(fake_images) targets = torch.ones(batch_size, 1, device=device) loss = F.binary_cross_entropy(preds, targets) #update generator weights loss.backward() opt_g.step() return loss.item() . from torchvision.utils import save_image . sample_dir = &#39;generated&#39; os.makedirs(sample_dir, exist_ok=True) . def save_sample(index, latent_tensors, show=True): fake_images = generator(latent_tensors) fake_fname = &#39;generated-images-{0:0=4d}.png&#39;.format(index) save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8) print(&#39;Saving&#39;, fake_fname) if show: fig, ax = plt.subplots(figsize=(8,8)) ax.set_xticks([]); ax.set_yticks([]) ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0)) . # save one set of images before start training our model fixed_latent = torch.randn(64, latent_size, 1, 1, device=device) . save_sample(0, fixed_latent) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . Saving generated-images-0000.png . Full Training Loop . Let&#39;s define a fit function to train the discriminator and generator in tandem for each batch of training data. We&#39;ll use the Adam optimizer with some custom parameters (betas) that are known to work well for GANs. We will also save some sample generated images at regular intervals for inspection. . . from tqdm import tqdm import torch.nn.functional as F . def fit(epoch, lr, start_idx=1): torch.cuda.empty_cache() # Losses and scores losses_g = [] losses_d = [] real_scores = [] fake_scores = [] # create optimizers opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999)) opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999)) for epoch in range(epochs): for real_images, _ in tqdm(train_dl): # Train discriminator loss_d, real_score, fake_score = train_discriminator(real_images, opt_d) # Train generator loss_g = train_generator(opt_g) # Record losses and scores losses_g.append(loss_g) losses_d.append(loss_d) real_scores.append(real_score) fake_scores.append(fake_score) # log losses and scores (last batch) print(&quot;Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}&quot;.format(epoch+1, epochs, loss_g, loss_d, real_score, fake_score)) save_sample(epoch+start_idx, fixed_latent, show=False) return losses_g, losses_d, real_scores, fake_scores . lr = 0.0002 epochs = 10 . history = fit(epochs, lr) . 100%|██████████| 497/497 [06:34&lt;00:00, 1.26it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [1/10], loss_g: 7.7820, loss_d: 0.7976, real_score: 0.9692, fake_score: 0.5054 Saving generated-images-0001.png . 100%|██████████| 497/497 [03:09&lt;00:00, 2.62it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [2/10], loss_g: 6.3187, loss_d: 0.5204, real_score: 0.8973, fake_score: 0.3050 Saving generated-images-0002.png . 100%|██████████| 497/497 [03:08&lt;00:00, 2.63it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [3/10], loss_g: 3.3551, loss_d: 0.6221, real_score: 0.6364, fake_score: 0.0227 Saving generated-images-0003.png . 100%|██████████| 497/497 [03:10&lt;00:00, 2.61it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [4/10], loss_g: 5.2019, loss_d: 0.2498, real_score: 0.8556, fake_score: 0.0619 Saving generated-images-0004.png . 100%|██████████| 497/497 [03:12&lt;00:00, 2.58it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [5/10], loss_g: 5.7978, loss_d: 0.1832, real_score: 0.8876, fake_score: 0.0381 Saving generated-images-0005.png . 100%|██████████| 497/497 [03:11&lt;00:00, 2.60it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [6/10], loss_g: 5.6346, loss_d: 0.0792, real_score: 0.9730, fake_score: 0.0479 Saving generated-images-0006.png . 100%|██████████| 497/497 [03:08&lt;00:00, 2.64it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [7/10], loss_g: 4.3606, loss_d: 0.1008, real_score: 0.9223, fake_score: 0.0060 Saving generated-images-0007.png . 100%|██████████| 497/497 [03:18&lt;00:00, 2.50it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [8/10], loss_g: 5.5023, loss_d: 0.2340, real_score: 0.9572, fake_score: 0.1537 Saving generated-images-0008.png . 100%|██████████| 497/497 [03:23&lt;00:00, 2.44it/s] 0%| | 0/497 [00:00&lt;?, ?it/s] . Epoch [9/10], loss_g: 2.8159, loss_d: 0.7364, real_score: 0.6190, fake_score: 0.0310 Saving generated-images-0009.png . 100%|██████████| 497/497 [03:20&lt;00:00, 2.48it/s] . Epoch [10/10], loss_g: 4.4092, loss_d: 0.1745, real_score: 0.8755, fake_score: 0.0136 Saving generated-images-0010.png . . losses_g, losses_d, real_scores, fake_scores = history . torch.save(generator.state_dict(), &#39;Anime-Generator-state.pth&#39;) torch.save(discriminator.state_dict(), &#39;Anime-Discriminator-state.pth&#39;) . from IPython.display import Image . Image(&#39;./generated/generated-images-0001.png&#39;) . Image(&#39;./generated/generated-images-0007.png&#39;) . Image(&#39;./generated/generated-images-0010.png&#39;) . import cv2 import os vid_fname = &#39;gans_training.avi&#39; files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if &#39;generated&#39; in f] files.sort() out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*&#39;MP4V&#39;), 1, (530,530)) [out.write(cv2.imread(fname)) for fname in files] out.release() . Training in one video . We can also visualize how the loss changes over time. Visualizing losses is quite useful for debugging the training process. For GANs, we expect the generator&#39;s loss to reduce over time, without the discriminator&#39;s loss getting too high. . plt.plot(losses_d, &#39;-&#39;) plt.plot(losses_g, &#39;-&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;loss&#39;) plt.legend([&#39;Discriminator&#39;, &#39;Generator&#39;]) plt.title(&#39;Losses&#39;); . plt.plot(real_scores, &#39;-&#39;) plt.plot(fake_scores, &#39;-&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;score&#39;) plt.legend([&#39;Real&#39;, &#39;Fake&#39;]) plt.title(&#39;Scores&#39;); .",
            "url": "https://mr-siddy.github.io/ML-blog/gans/2021/06/25/GANs-1-Pytorch.html",
            "relUrl": "/gans/2021/06/25/GANs-1-Pytorch.html",
            "date": " • Jun 25, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Simple Gan Implementation",
            "content": "Simple Gan Implementation . Paper : https://arxiv.org/pdf/1406.2661.pdf . . # -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Thu Jun 16:11:54 2021 @author: siddy &quot;&quot;&quot; import torch import torch.nn as nn import torch.optim as optim import torchvision import torchvision.datasets as datasets from torch.utils.data import DataLoader import torchvision.transforms as transforms from torch.utils.tensorboard import SummaryWriter # to print to tensorboard class Discriminator(nn.Module): def __init__(self, in_features): super().__init__() self.disc = nn.Sequential( nn.Linear(in_features, 128), nn.LeakyReLU(0.01), nn.Linear(128, 1), nn.Sigmoid(), ) def forward(self, x): return self.disc(x) class Generator(nn.Module): def __init__(self, z_dim, img_dim): super().__init__() self.gen = nn.Sequential( nn.Linear(z_dim, 256), nn.LeakyReLU(0.01), nn.Linear(256, img_dim), nn.Tanh(), # normalize inputs to [-1, 1] so make outputs [-1, 1] ) def forward(self, x): return self.gen(x) # Hyperparameters etc. device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot; lr = 3e-4 z_dim = 64 image_dim = 28 * 28 * 1 # 784 batch_size = 32 num_epochs = 50 disc = Discriminator(image_dim).to(device) gen = Generator(z_dim, image_dim).to(device) fixed_noise = torch.randn((batch_size, z_dim)).to(device) transforms = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),] ) dataset = datasets.MNIST(root=&quot;dataset/&quot;, transform=transforms, download=False) loader = DataLoader(dataset, batch_size=batch_size, shuffle=True) opt_disc = optim.Adam(disc.parameters(), lr=lr) opt_gen = optim.Adam(gen.parameters(), lr=lr) criterion = nn.BCELoss() writer_fake = SummaryWriter(f&quot;logs/fake&quot;) writer_real = SummaryWriter(f&quot;logs/real&quot;) step = 0 for epoch in range(num_epochs): for batch_idx, (real, _) in enumerate(loader): real = real.view(-1, 784).to(device) batch_size = real.shape[0] ### Train Discriminator: max log(D(x)) + log(1 - D(G(z))) noise = torch.randn(batch_size, z_dim).to(device) fake = gen(noise) disc_real = disc(real).view(-1) lossD_real = criterion(disc_real, torch.ones_like(disc_real)) disc_fake = disc(fake).view(-1) lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake)) lossD = (lossD_real + lossD_fake) / 2 disc.zero_grad() lossD.backward(retain_graph=True) opt_disc.step() ### Train Generator: min log(1 - D(G(z))) &lt;-&gt; max log(D(G(z)) # where the second option of maximizing doesn&#39;t suffer from # saturating gradients output = disc(fake).view(-1) lossG = criterion(output, torch.ones_like(output)) gen.zero_grad() lossG.backward() opt_gen.step() if batch_idx == 0: print( f&quot;Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} Loss D: {lossD:.4f}, loss G: {lossG:.4f}&quot; ) with torch.no_grad(): fake = gen(fixed_noise).reshape(-1, 1, 28, 28) data = real.reshape(-1, 1, 28, 28) img_grid_fake = torchvision.utils.make_grid(fake, normalize=True) img_grid_real = torchvision.utils.make_grid(data, normalize=True) writer_fake.add_image( &quot;Mnist Fake Images&quot;, img_grid_fake, global_step=step ) writer_real.add_image( &quot;Mnist Real Images&quot;, img_grid_real, global_step=step ) step += 1 | .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/06/24/Simple-Gan-Implementation.html",
            "relUrl": "/2021/06/24/Simple-Gan-Implementation.html",
            "date": " • Jun 24, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "U Net From Scratch Using Pytorch",
            "content": "U-Net Paper Implementation using PyTorch . Main Diagram . . Network Architecture . The network architecture is illustrated in Figure 1. It consists of a contracting path (left side) and an expansive path (right side). The contracting path follows the typical architecture of a convolutional network. It consists of the repeated application of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling. At each downsampling step, we double the number of feature channels. Every step in the expansive path consists of an upsampling of the feature map followed by a 2x2 convolution (“up-convolution”) that halves the number of feature channels, a concatenation with the correspondingly cropped feature map from the contracting path, and two 3x3 convolutions, each followed by a ReLU. The cropping is necessary due to the loss of border pixels in every convolution. At the final layer, a 1x1 convolution is used to map each 64- component feature vector to the desired number of classes. In total the network has 23 convolutional layers. To allow a seamless tiling of the output segmentation map (see Figure 2), it is important to select the input tile size such that all 2x2 max-pooling operations are applied to a layer with an even x- and y-size. . &quot;&quot;&quot; Created on Mon Jun 20 16:08:19 2021 @author: mr-siddy &quot;&quot;&quot; import torch import torch.nn as nn def double_conv(in_c, out_c): conv = nn.Sequential( nn.Conv2d(in_c, out_c, kernel_size=3), nn.ReLU(inplace=True), nn.Conv2d(out_c, out_c, kernel_size=3), nn.ReLU(inplace=True) ) return conv def crop_img(tensor, target_tensor): target_size = target_tensor.size()[2] tensor_size = tensor.size()[2] delta = tensor_size - target_size delta = delta // 2 return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta] class UNet(nn.Module): def __init__(self): super(UNet, self).__init__() self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2) self.down_conv_1 = double_conv(1, 64) self.down_conv_2 = double_conv(64, 128) self.down_conv_3 = double_conv(128, 256) self.down_conv_4 = double_conv(256, 512) self.down_conv_5 = double_conv(512, 1024) self.up_trans_1 = nn.ConvTranspose2d( in_channels=1024, out_channels=512, kernel_size=2, stride=2) self.up_conv_1 = double_conv(1024, 512) self.up_trans_2 = nn.ConvTranspose2d( in_channels=512, out_channels=256, kernel_size=2, stride=2) self.up_conv_2 = double_conv(512, 256) self.up_trans_3 = nn.ConvTranspose2d( in_channels=256, out_channels=128, kernel_size=2, stride=2) self.up_conv_3 = double_conv(256, 128) self.up_trans_4 = nn.ConvTranspose2d( in_channels=128, out_channels=64, kernel_size=2, stride=2) self.up_conv_4 = double_conv(128, 64) self.out = nn.Conv2d( in_channels=64, out_channels=2, kernel_size=1) def forward(self, image): # bs, channel = c, height = h, width = w # encoder x1 = self.down_conv_1(image) # copy and crop x2 = self.max_pool_2x2(x1) x3 = self.down_conv_2(x2) # copy and crop x4 = self.max_pool_2x2(x3) x5 = self.down_conv_3(x4) # copy and crop x6 = self.max_pool_2x2(x5) x7 = self.down_conv_4(x6) # copy and crop x8 = self.max_pool_2x2(x7) x9 = self.down_conv_5(x8) # decoder x = self.up_trans_1(x9) y = crop_img(x7, x) x = self.up_conv_1(torch.cat([x, y], 1)) x = self.up_trans_2(x) y = crop_img(x5, x) x = self.up_conv_2(torch.cat([x, y], 1)) x = self.up_trans_3(x) y = crop_img(x3, x) x = self.up_conv_3(torch.cat([x, y], 1)) x = self.up_trans_4(x) y = crop_img(x1, x) x = self.up_conv_4(torch.cat([x, y], 1)) x = self.out(x) print(x.size()) return x if __name__ == &#39;__main__&#39;: image = torch.rand((1, 1, 572, 572)) model = UNet() print(model(image)) | .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/06/20/U-Net-from-Scratch-using-PyTorch.html",
            "relUrl": "/2021/06/20/U-Net-from-Scratch-using-PyTorch.html",
            "date": " • Jun 20, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Classifying Cifar-10 using ResNets - Pytorch",
            "content": "Understanding use of Regularization and Data Augmentation . Exploring the CIFAR10 Dataset . CIFAR-10 is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class. It was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. . Link:- https://www.kaggle.com/c/cifar-10 . Dataset-credentials:- https://www.cs.toronto.edu/~kriz/cifar.html . . import os import torch import torchvision import tarfile import torch.nn as nn import numpy as np import torch.nn.functional as F from torchvision.datasets.utils import download_url from torchvision.datasets import ImageFolder from torch.utils.data import DataLoader import torchvision.transforms as tt from torch.utils.data import random_split from torchvision.utils import make_grid import matplotlib import matplotlib.pyplot as plt %matplotlib inline matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39; . project_name = &#39;cifar10-resnet&#39; . data_dir = &#39;./data/cifar10&#39; print(os.listdir(data_dir)) classes = os.listdir(data_dir + &quot;/train&quot;) print(classes) . [&#39;train&#39;, &#39;test&#39;] [&#39;ship&#39;, &#39;cat&#39;, &#39;automobile&#39;, &#39;frog&#39;, &#39;airplane&#39;, &#39;dog&#39;, &#39;truck&#39;, &#39;deer&#39;, &#39;bird&#39;, &#39;horse&#39;] . Data Preprocessing . going to use test set for validation . Channel wise data normalisation . we will normalize the image tensors by substracting the mean and dividing by the standard deviation across each channel. it will mean the data across each channel to 0 and standard deviation to 1. normalizing data prevents the values from any one channel from disproportionately affecting the losses and gradients while training simply by having a higher or wider range of values that others . . Randomized data augmentation . Applying chosen transformations while loading images from the training dataset. we will pad each image by 4 pixels and then take a random crop of size 32 x 32 and then flip the image horizontly with a 50% probability. Since the transformation will be applied randomly and dynamically each time a particular image is loaded, the model sees slightly different images in each epoch of training, which allows it generalize better . . stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) train_tfms = tt.Compose([tt.RandomCrop(32, padding=4, padding_mode=&#39;reflect&#39;), # it is going to shift the image around upto 4 pixels(top/bottom/left/right) each time tt.RandomHorizontalFlip(), # default probab = 0.5 #tt.RandomRotation(), #tt.RandomResizedCrop(256, scale=(0.5, 0.9), ratio=(1, 1)), #tt.ColorJitter(brightness=0.1, contrast =0.1, saturation=0.1), tt.ToTensor(), tt.Normalize(*stats, inplace=True)]) valid_tfms = tt.Compose([tt.ToTensor(), tt.Normalize(*stats)]) # we can not apply transformations to validation set coz it is for testing on real data . we need normalized transformation for validation set too bcoz when we train the model using normalized data then model no longer understands the original pixel values, it only understands the mormalize pixel values which has been shifted using mean and standard deviations, therefore any new input that is used should also contain same normalization . train_ds = ImageFolder(data_dir+&#39;/train&#39;, train_tfms) valid_ds = ImageFolder(data_dir+&#39;/test&#39;, valid_tfms) . batch_size = 400 . train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=3, pin_memory=True) valid_dl = DataLoader(valid_ds, batch_size*2, num_workers=3, pin_memory=True) . def denormalize(images, means, stds): means = torch.tensor(means).reshape(1, 3, 1, 1) stds = torch.tensor(stds).reshape(1, 3, 1, 1) return images * stds + means def show_batch(dl): for images, labels in dl: fig, ax = plt.subplots(figsize=(12, 12)) ax.set_xticks([]); ax.set_yticks([]) denorm_images = denormalize(images, *stats) ax.imshow(make_grid(denorm_images[:64], nrow=8).permute(1, 2, 0).clamp(0, 1)) break . show_batch(train_dl) . Using a GPU . def get_default_device(): if torch.cuda.is_available(): return torch.device(&#39;cuda&#39;) else: return torch.device(&#39;cpu&#39;) . device = get_default_device() device . device(type=&#39;cuda&#39;) . def to_device(data, device): &quot;&quot;&quot;Move tensors to chosen device&quot;&quot;&quot; if isinstance(data, (list,tuple)): return [to_device(x, device) for x in data] return data.to(device, non_blocking = True) # to method . class DeviceDataLoader(): def __init__(self, dl, device): self.dl = dl self.device = device def __iter__(self): for b in self.dl: yield to_device(b, self.device) def __len__(self): return len(self.dl) . train_dl = DeviceDataLoader(train_dl, device) valid_dl = DeviceDataLoader(valid_dl, device) . Model with Residual Blocks and Batch Normalization . we will add residual block, that adds the original input back to the output feature map obtained by passing the input through one or more conv layers . without residual block, these layers are responsible for transforming the input into the output, our entire network in responsible for transforming images 3d rgb 32x32 color images into 10 output class probabilities but when we pass a residual layer then our conv layers are no longer responsible for converting the i/p to o/p rather they only have to calculate the difference between i/p and o/p coz, final o/p is the o/p of covn layer + i/p so simply o/p of conv layer is desired op - i/p layer . so the wieghts can learn more powerful features . . class SimpleResidualBlock(nn.Module): def __init__(self): super().__init__() self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1) self.relu1 = nn.ReLU() self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1) self.relu2 = nn.ReLU() # in a residual block we can not change the no of o/p channels, coz if we change it ex to 128 then we&#39;ll not be able to add the orginal i/p to o/p coz then i/p shape and o/p shape would not match def forward(self, x): out = self.conv1(x) out = self.relu1(out) out = self.conv2(out) return self.relu2(out) + x . simple_resnet = to_device(SimpleResidualBlock(), device) for images, labels in train_dl: print(images.shape) out = simple_resnet(images) print(out.shape) break del simple_resnet, images, labels torch.cuda.empty_cache() . torch.Size([400, 3, 32, 32]) torch.Size([400, 3, 32, 32]) . Batch Normalization layer: normalizes the o/p of previous layer . some cool resources : Residual blocks Batch Normalization ResNet9 . lmao cool animation down there ResNet34 : . Cmon dude see some more about ResNets . ResNet18 : . . we&#39;ll use ResNet9 architecture: . bro only diagram above is good for easy understanding so do not ignore it and for clarity --&gt; ctrl + mbtn-up . def accuracy(outputs, labels): _, preds = torch.max(outputs, dim=1) return torch.tensor(torch.sum(preds == labels).item()/len(preds)) class ImageClassificationBase(nn.Module): def training_step(self, batch): images, labels = batch out = self(images) loss = F.cross_entropy(out, labels) return loss def validation_step(self, batch): images, labels = batch out = self(images) loss = F.cross_entropy(out, labels) acc = accuracy(out, labels) return {&#39;val_loss&#39;: loss.detach(), &#39;val_acc&#39;: acc} def validation_epoch_end(self, outputs): batch_losses = [x[&#39;val_loss&#39;] for x in outputs] epoch_loss = torch.stack(batch_losses).mean() batch_accs = [x[&#39;val_acc&#39;] for x in outputs] epoch_acc = torch.stack(batch_accs).mean() return {&#39;val_loss&#39;: epoch_loss.item(), &#39;val_acc&#39;: epoch_acc.item()} def epoch_end(self, epoch, result): print(&quot;Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}&quot;.format( epoch, result[&#39;lrs&#39;][-1], result[&#39;train_loss&#39;], result[&#39;val_loss&#39;], result[&#39;val_acc&#39;])) . def conv_block(in_channels, out_channels, pool=False): layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), nn.BatchNorm2d(out_channels), nn.ReLU(inplace=True)] if pool: layers.append(nn.MaxPool2d(2)) return nn.Sequential(*layers) # * layers is same as passing one by one args to nn.Sequential class ResNet9(ImageClassificationBase): def __init__(self, in_channels, num_classes): super().__init__() # 400 x 3 x 32 x 32 self.conv1 = conv_block(in_channels, 64) # 64 x 32 x 32 self.conv2 = conv_block(64, 128, pool=True) # 128 x 16 x 16 self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128)) # 128 x 16 x 16 self.conv3 = conv_block(128, 256, pool=True) # 256 x 8 x 8 self.conv4 = conv_block(256, 512, pool=True) # 512 x 4 x 4 self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512)) # 512 x 4 x 4 self.classifier = nn.Sequential(nn.MaxPool2d(4), # 512 x 1 x 1 nn.Flatten(), # 512 nn.Dropout(0.2), # 512 --&gt;used to avoid overfitting nn.Linear(512, num_classes)) # 10 def forward(self, xb): out = self.conv1(xb) out = self.conv2(out) out = self.res1(out) + out out = self.conv3(out) out = self.conv4(out) out = self.res2(out) + out out = self.classifier(out) return out . model = to_device(ResNet9(3, 10), device) model . ResNet9( (conv1): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (conv2): Sequential( (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (res1): Sequential( (0): Sequential( (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (1): Sequential( (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) ) (conv3): Sequential( (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (conv4): Sequential( (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (res2): Sequential( (0): Sequential( (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) (1): Sequential( (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) ) ) (classifier): Sequential( (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False) (1): Flatten(start_dim=1, end_dim=-1) (2): Dropout(p=0.2, inplace=False) (3): Linear(in_features=512, out_features=10, bias=True) ) ) . Training the model . Before we train the model, we&#39;re going to make a bunch of small but important improvements to our fit function: . Learning rate scheduling: Instead of using a fixed learning rate, we will use a learning rate scheduler, which will change the learning rate after every batch of training. There are many strategies for varying the learning rate during training, and the one we&#39;ll use is called the &quot;One Cycle Learning Rate Policy&quot;, which involves starting with a low learning rate, gradually increasing it batch-by-batch to a high learning rate for about 30% of epochs, then gradually decreasing it to a very low value for the remaining epochs. Learn more: https://sgugger.github.io/the-1cycle-policy.html | . Yo start with a low learning rate and then slowly keeps inc lr so that model keeps making larger steps and then start dec the lr again coz once model approaches the good set of weights then we want to narrow down and pick the set of weights by taking really small steps towrds that optimal one . . Weight decay: regularization technique which prevents the weights from becoming too large by adding an additional term to the loss function.Learn more: https://towardsdatascience.com/this-thing-called-weight-decay-a7cd4bcfccab | . now Loss = MSE(y_hat, y) + wd * sum(w^2) . When we update weights using gradient descent we do the following: . w(t) = w(t-1) - lr * dLoss / dw . Now since our loss function has 2 terms in it, the derivative of the 2nd term w.r.t w would be: . d(wd w^2) / dw = 2 wd * w (similar to d(x^2)/dx = 2x) . Gradient clipping: Apart from the layer weights and outputs, it also helpful to limit the values of gradients to a small range to prevent undesirable changes in parameters due to large gradient values. This simple yet effective technique is called gradient clipping. Learn more: https://towardsdatascience.com/what-is-gradient-clipping-b8e815cdfb48 | . . @torch.no_grad() def evaluate(model, val_loader): model.eval() # tells model that we are currently evaluating and not training outputs = [model.validation_step(batch) for batch in val_loader] return model.validation_epoch_end(outputs) def get_lr(optimizer): for param_group in optimizer.param_groups: return param_group[&#39;lr&#39;] def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD): torch.cuda.empty_cache() history =[] optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay) sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader)) for epoch in range(epochs): model.train() train_losses= [] lrs = [] for batch in train_loader: loss = model.training_step(batch) train_losses.append(loss) loss.backward() if grad_clip: nn.utils.clip_grad_value_(model.parameters(), grad_clip) optimizer.step() optimizer.zero_grad() lrs.append(get_lr(optimizer)) sched.step() result = evaluate(model, val_loader) result[&#39;train_loss&#39;] = torch.stack(train_losses).mean().item() result[&#39;lrs&#39;] = lrs model.epoch_end(epoch, result) history.append(result) return history . history = [evaluate(model, valid_dl)] history . [{&#39;val_loss&#39;: 1.5891424417495728, &#39;val_acc&#39;: 0.4678846001625061}] . epochs = 16 max_lr = 0.01 grad_clip = 0.1 weight_decay = 1e-4 opt_func = torch.optim.Adam . %%time history += fit_one_cycle(epochs, max_lr, model, train_dl, valid_dl, grad_clip=grad_clip, weight_decay = weight_decay) . Epoch [0], last_lr: 0.00138, train_loss: 0.4685, val_loss: 0.5093, val_acc: 0.8230 Epoch [1], last_lr: 0.00394, train_loss: 0.5068, val_loss: 0.5091, val_acc: 0.8308 Epoch [2], last_lr: 0.00703, train_loss: 0.5393, val_loss: 0.8572, val_acc: 0.7250 Epoch [3], last_lr: 0.00935, train_loss: 0.5397, val_loss: 0.6107, val_acc: 0.8067 Epoch [4], last_lr: 0.00999, train_loss: 0.5024, val_loss: 0.5370, val_acc: 0.8198 Epoch [5], last_lr: 0.00972, train_loss: 0.4943, val_loss: 0.6554, val_acc: 0.7915 Epoch [6], last_lr: 0.00908, train_loss: 0.4549, val_loss: 0.4965, val_acc: 0.8401 Epoch [7], last_lr: 0.00812, train_loss: 0.4190, val_loss: 0.7664, val_acc: 0.7785 Epoch [8], last_lr: 0.00691, train_loss: 0.3934, val_loss: 0.4607, val_acc: 0.8482 Epoch [9], last_lr: 0.00556, train_loss: 0.3638, val_loss: 0.4654, val_acc: 0.8466 Epoch [10], last_lr: 0.00416, train_loss: 0.3323, val_loss: 0.4287, val_acc: 0.8637 Epoch [11], last_lr: 0.00283, train_loss: 0.2908, val_loss: 0.3947, val_acc: 0.8729 Epoch [12], last_lr: 0.00167, train_loss: 0.2651, val_loss: 0.3649, val_acc: 0.8847 Epoch [13], last_lr: 0.00077, train_loss: 0.2317, val_loss: 0.3137, val_acc: 0.8944 Epoch [14], last_lr: 0.00020, train_loss: 0.2126, val_loss: 0.2992, val_acc: 0.9022 Epoch [15], last_lr: 0.00000, train_loss: 0.1960, val_loss: 0.2925, val_acc: 0.9031 CPU times: user 8min 27s, sys: 3min 43s, total: 12min 10s Wall time: 12min 14s . def plot_accuracies(history): accuracies = [x[&#39;val_acc&#39;] for x in history] plt.plot(accuracies, &#39;-x&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;accuracy&#39;) plt.title(&#39;Accuracy vs. No. of epochs&#39;); . plot_accuracies(history) . def plot_losses(history): train_losses = [x.get(&#39;train_loss&#39;) for x in history] val_losses = [x[&#39;val_loss&#39;] for x in history] plt.plot(train_losses, &#39;-bx&#39;) plt.plot(val_losses, &#39;-rx&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;loss&#39;) plt.legend([&#39;Training&#39;, &#39;Validation&#39;]) plt.title(&#39;Loss vs. No of epochs&#39;); . plot_losses(history) . def plot_lrs(history): lrs = np.concatenate([x.get(&#39;lrs&#39;, []) for x in history]) plt.plot(lrs) plt.xlabel(&#39;Batch no.&#39;) plt.ylabel(&#39;Learning rate&#39;) plt.title(&#39;Learning Rate vs Batch no.&#39;); . plot_lrs(history) . Testing with individual images . def predict_image(img, model): xb = to_device(img.unsqueeze(0), device) yb = model(xb) _, pred = torch.max(yb, dim=1) return train_ds.classes[pred[0].item()] . img, label = valid_ds[2341] plt.imshow(img.permute(1, 2, 0).clamp(0, 1)) print(&#39;Label:&#39;, train_ds.classes[label], &#39;, Predicted:&#39;, predict_image(img, model)) . Label: bird , Predicted: bird . img, label = valid_ds[1002] plt.imshow(img.permute(1, 2, 0)) print(&#39;Label:&#39;, valid_ds.classes[label], &#39;, Predicted:&#39;, predict_image(img, model)) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . Label: automobile , Predicted: truck . img, label = valid_ds[1111] plt.imshow(img.permute(1, 2, 0)) print(&#39;Label:&#39;, valid_ds.classes[label], &#39;, Predicted:&#39;, predict_image(img, model)) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . Label: automobile , Predicted: automobile . img, label = valid_ds[1921] plt.imshow(img.permute(1, 2, 0)) print(&#39;Label:&#39;, valid_ds.classes[label], &#39;, Predicted:&#39;, predict_image(img, model)) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . Label: automobile , Predicted: automobile . torch.save(model.state_dict(), &#39;cifar-10-resnet9.pth&#39;) .",
            "url": "https://mr-siddy.github.io/ML-blog/deep_learning/2021/06/19/cifar10-resnets.html",
            "relUrl": "/deep_learning/2021/06/19/cifar10-resnets.html",
            "date": " • Jun 19, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Image Classification using Convolutional Neural Networks - Pytorch",
            "content": "Exploring the CIFAR10 Dataset . CIFAR-10 is an established computer-vision dataset used for object recognition. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6000 images per class. It was collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. . Link:- https://www.kaggle.com/c/cifar-10 . Dataset-credentials:- https://www.cs.toronto.edu/~kriz/cifar.html . . Importing Libraries . import os import torch import torchvision import tarfile from torchvision.datasets.utils import download_url from torch.utils.data import random_split . project_name = &#39;cifar10-cnn&#39; . dataset_url = &quot;https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz&quot; download_url(dataset_url, &#39;.&#39;) . with tarfile.open(&#39;./cifar10.tgz&#39;, &#39;r:gz&#39;) as tar: # r:gz --&gt; read mode in g zip format tar.extractall(path=&#39;./data&#39;) . data_dir = &#39;./data/cifar10&#39; print(os.listdir(data_dir)) classes = os.listdir(data_dir + &quot;/train&quot;) print(classes) . [&#39;test&#39;, &#39;train&#39;] [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;] . airplane_files = os.listdir(data_dir + &quot;/train/airplane&quot;) print(&quot;No. of test examples for airplanes: &quot;, len(airplane_files)) print(airplane_files[:5]) . No. of test examples for airplanes: 5000 [&#39;0001.png&#39;, &#39;0002.png&#39;, &#39;0003.png&#39;, &#39;0004.png&#39;, &#39;0005.png&#39;] . ship_test_files = os.listdir(data_dir + &quot;/test/ship&quot;) print(&quot;No of test examples for ship:&quot;, len(ship_test_files)) print(ship_test_files[10:50]) . No of test examples for ship: 1000 [&#39;0011.png&#39;, &#39;0012.png&#39;, &#39;0013.png&#39;, &#39;0014.png&#39;, &#39;0015.png&#39;, &#39;0016.png&#39;, &#39;0017.png&#39;, &#39;0018.png&#39;, &#39;0019.png&#39;, &#39;0020.png&#39;, &#39;0021.png&#39;, &#39;0022.png&#39;, &#39;0023.png&#39;, &#39;0024.png&#39;, &#39;0025.png&#39;, &#39;0026.png&#39;, &#39;0027.png&#39;, &#39;0028.png&#39;, &#39;0029.png&#39;, &#39;0030.png&#39;, &#39;0031.png&#39;, &#39;0032.png&#39;, &#39;0033.png&#39;, &#39;0034.png&#39;, &#39;0035.png&#39;, &#39;0036.png&#39;, &#39;0037.png&#39;, &#39;0038.png&#39;, &#39;0039.png&#39;, &#39;0040.png&#39;, &#39;0041.png&#39;, &#39;0042.png&#39;, &#39;0043.png&#39;, &#39;0044.png&#39;, &#39;0045.png&#39;, &#39;0046.png&#39;, &#39;0047.png&#39;, &#39;0048.png&#39;, &#39;0049.png&#39;, &#39;0050.png&#39;] . from torchvision.datasets import ImageFolder from torchvision.transforms import ToTensor . dataset = ImageFolder(data_dir + &#39;/train&#39;, transform = ToTensor()) . img, label = dataset[0] print(img.shape, label) img[2] # img tensor . torch.Size([3, 32, 32]) 0 . tensor([[0.7804, 0.7804, 0.7882, ..., 0.7843, 0.7804, 0.7765], [0.7961, 0.7961, 0.8000, ..., 0.8039, 0.7961, 0.7882], [0.8118, 0.8157, 0.8235, ..., 0.8235, 0.8157, 0.8078], ..., [0.8706, 0.8392, 0.7765, ..., 0.9686, 0.9686, 0.9686], [0.8745, 0.8667, 0.8627, ..., 0.9608, 0.9608, 0.9608], [0.8667, 0.8627, 0.8667, ..., 0.9529, 0.9529, 0.9529]]) . print(dataset.classes) . [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;] . import matplotlib import matplotlib.pyplot as plt %matplotlib inline matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39; . def show_example(img, label): print(&#39;Label: &#39;, dataset.classes[label], &quot;(&quot;+str(label)+&quot;)&quot;) plt.imshow(img.permute(1, 2, 0)) # matplot lib expects channels in final dimension . img, label = dataset[5] show_example(img, label) . Label: airplane (0) . show_example(*dataset[0]) . Label: airplane (0) . show_example(*dataset[1099]) . Label: airplane (0) . Training and Validation Datasets . random_seed = 42 torch.manual_seed(random_seed); # It helps to standardise validation set . val_size = 5000 train_size = len(dataset) - val_size train_ds, val_ds = random_split(dataset, [train_size, val_size]) len(train_ds), len(val_ds) . (45000, 5000) . Creating DataLoaders . from torch.utils.data.dataloader import DataLoader batch_size = 128 . train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory = True) val_dl = DataLoader(val_ds, batch_size*2, num_workers = 4, pin_memory = True) . from torchvision.utils import make_grid def show_batch(dl): for images, labels in dl: fig, ax = plt.subplots(figsize = (12, 6)) ax.set_xticks([]); ax.set_yticks([]) ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0)) break . show_batch(train_dl) . Defining the Conv Model . nn.Linear gives full connected layer architecture nn.Conv2d gives convolutional neural network . Basic working of CNN can be described as follows : . . Working of kernel can be describes as : . . Implementation of a convolution operation on a 1 channel image with a 3x3 kernel . def apply_kernel(image, kernel): ri, ci = image.shape #image dimension rk, ck = kernel.shape #kernel dimension ro, co = ri-rk+1, ci-ck+1 #output dimension output = torch.zeros([ro, co]) for i in range(ro): for j in range(co): output[i, j] = torch.sum(image[i:i+rk, j:j+ck] * kernel) return output . sample_image = torch.tensor([ [0, 0, 75, 80, 80], [0, 75, 80, 80, 80], [0, 75, 80, 80, 80], [0, 70, 75, 80, 80], [0, 0, 0, 0, 0] ], dtype = torch.float32) sample_kernel = torch.tensor([ [-1, -2, -1], [0, 0, 0], [1, 2, 1] ], dtype = torch.float32) apply_kernel(sample_image, sample_kernel) . tensor([[ 155., 85., 5.], [ -15., -15., -5.], [-230., -315., -320.]]) . For Multiple channels kernel will have same function over all channels . Refer this blog post for more in-depth intution of CNN :- Convolution in depth . Observation : 5x5 image got reduced to a 3x3 output, while kernel in running over internal values multiple times, but still values of corner are covered only once, so we&#39;ll use padding and it will return output as the same size as input . Padding can be understood using following diagram: . Now we have moved kernel by 1 position each time, we can move kernel by 2 positons too, this is call Stride . Stride can be understood using folloeing diagram: . For multi-channel images, a different kernel is applied to each channels, and the outputs are added together pixel-wise. . There are certain advantages offered by convolutional layers when working with image data: . Fewer parameters: A small set of parameters (the kernel) is used to calculate outputs of the entire image, so the model has much fewer parameters compared to a fully connected layer. | Sparsity of connections: In each layer, each output element only depends on a small number of input elements, which makes the forward and backward passes more efficient. | Parameter sharing and spatial invariance: The features learned by a kernel in one part of the image can be used to detect similar pattern in a different part of another image. | . We will also use a max-pooling layers to progressively decrease the height &amp; width of the output tensors from each convolutional layer. . . Applying Single Convolutional Layer followed by max pooling . import torch.nn as nn import torch.nn.functional as F . conv = nn.Conv2d(3, 8, kernel_size = 3, stride = 1, padding = 1) # 8 is no of kernels which also descide no of output channels ie feature map . pool = nn.MaxPool2d(2, 2) . for images, labels in train_dl: print(&#39;images.shape:&#39;, images.shape) out = conv(images) print(&#39;output.shape:&#39;, out.shape) out = pool(out) print(&#39;max-pool output.shape:&#39;, out.shape) # max pool will reduce size break . images.shape: torch.Size([128, 3, 32, 32]) output.shape: torch.Size([128, 8, 32, 32]) max-pool output.shape: torch.Size([128, 8, 16, 16]) . conv.weight.shape # we have 8 kernel and each kernel contain 3 matrices for 3 input channel and each of 3 matrix have 3x3 matrix that is gonna slide . torch.Size([8, 3, 3, 3]) . conv.weight[0, 0] . tensor([[-0.1398, 0.1772, 0.0425], [-0.0123, 0.1491, -0.0260], [ 0.0454, 0.1039, 0.0843]], grad_fn=&lt;SelectBackward&gt;) . conv.weight[0] . tensor([[[-0.1398, 0.1772, 0.0425], [-0.0123, 0.1491, -0.0260], [ 0.0454, 0.1039, 0.0843]], [[-0.1612, -0.0831, -0.1083], [ 0.1363, -0.0058, -0.0148], [ 0.0635, 0.0091, 0.0112]], [[-0.0657, -0.0093, 0.1648], [ 0.1584, -0.0931, 0.0160], [ 0.1131, -0.1040, 0.0193]]], grad_fn=&lt;SelectBackward&gt;) . simple_model = nn.Sequential( nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1), nn.MaxPool2d(2,2) ) . for images, labels, in train_dl: print(&#39;images.shape:&#39;, images.shape) out = simple_model(images) print(&#39;out.shape:&#39;, out.shape) break . images.shape: torch.Size([128, 3, 32, 32]) out.shape: torch.Size([128, 8, 16, 16]) . Now lets define CNN model . class ImageClassificationBase(nn.Module): def training_step(self, batch): images, labels = batch out = self(images) loss = F.cross_entropy(out, labels) return loss def validation_step(self, batch): images, labels = batch out = self(images) loss = F.cross_entropy(out, labels) acc = accuracy(out, labels) return {&#39;val_loss&#39;: loss.detach(), &#39;val_acc&#39;: acc} def validation_epoch_end(self, outputs): batch_losses = [x[&#39;val_loss&#39;] for x in outputs] epoch_loss = torch.stack(batch_losses).mean() batch_accs = [x[&#39;val_acc&#39;] for x in outputs] epoch_acc = torch.stack(batch_accs).mean() return {&#39;val_loss&#39;: epoch_loss.item(), &#39;val_acc&#39;: epoch_acc.item()} def epoch_end(self, epoch, result): print(&quot;Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}&quot;.format(epoch, result[&#39;train_loss&#39;], result[&#39;val_loss&#39;], result[&#39;val_acc&#39;])) def accuracy(outputs, labels): _, preds = torch.max(outputs, dim=1) return torch.tensor(torch.sum(preds == labels).item() / len(preds)) . class Cifar10CnnModel(ImageClassificationBase): def __init__(self): super().__init__() self.network = nn.Sequential( # input: 3 x 32 x 32 nn.Conv2d(3, 32, kernel_size=3, padding=1), # i/p 3 channels, applies 32 kernels to create o/p: 32 x 32 # output: 32 x 32 x 32 nn.ReLU(), nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), # output: 64 x 32 x 32 nn.ReLU(), nn.MaxPool2d(2, 2), # 32 x 32 --&gt; 16 x 16 #output 64 x 16 x 16 nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2), # output 128 x 8 x 8 nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(), nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2), # output 256 x 4 x 4 nn.Flatten(), # take 256x4x4 o/p feature map and flatten it out into a vector nn.Linear(256*4*4, 1024), nn.ReLU(), nn.Linear(1024, 512), nn.ReLU(), nn.Linear(512, 10)) def forward(self, xb): return self.network(xb) . model = Cifar10CnnModel() model . Cifar10CnnModel( (network): Sequential( (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU() (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU() (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU() (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU() (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU() (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU() (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (15): Flatten(start_dim=1, end_dim=-1) (16): Linear(in_features=4096, out_features=1024, bias=True) (17): ReLU() (18): Linear(in_features=1024, out_features=512, bias=True) (19): ReLU() (20): Linear(in_features=512, out_features=10, bias=True) ) ) . Look at out model : . for images, labels in train_dl: print(&#39;images.shape:&#39;, images.shape) out = model(images) print(&#39;out.shape:&#39;, out.shape) print(&#39;out[0]&#39;, out[0]) # out will have prob of each classes break . images.shape: torch.Size([128, 3, 32, 32]) out.shape: torch.Size([128, 10]) out[0] tensor([ 0.0391, -0.0104, 0.0005, 0.0281, -0.0311, -0.0069, 0.0147, -0.0170, 0.0353, 0.0030], grad_fn=&lt;SelectBackward&gt;) . Training our model using GPU . def get_default_device(): if torch.cuda.is_available(): return torch.device(&#39;cuda&#39;) else: return torch.device(&#39;cpu&#39;) . device = get_default_device() device . device(type=&#39;cuda&#39;) . def to_device(data, device): &quot;&quot;&quot;Move tensors to chosen device&quot;&quot;&quot; if isinstance(data, (list,tuple)): return [to_device(x, device) for x in data] return data.to(device, non_blocking = True) # to method . class DeviceDataLoader(): def __init__(self, dl, device): self.dl = dl self.device = device def __iter__(self): for b in self.dl: yield to_device(b, self.device) def __len__(self): return len(self.dl) . train_dl = DeviceDataLoader(train_dl, device) val_dl = DeviceDataLoader(val_dl, device) to_device(model, device); . @torch.no_grad() # tells when evaluate is being executed we dont want to compute any gradient def evaluate(model, val_loader): model.eval() # tells pytorch that these layers should be put into validation mode outputs = [model.validation_step(batch) for batch in val_loader] return model.validation_epoch_end(outputs) def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD): history = [] optimizer = opt_func(model.parameters(), lr) for epoch in range(epochs): # Training Phase model.train() # tells pytorch that these layers should be put into training mode train_losses = [] for batch in train_loader: loss = model.training_step(batch) train_losses.append(loss) loss.backward() optimizer.step() optimizer.zero_grad() # Validation Phase result = evaluate(model, val_loader) result[&#39;train_loss&#39;] = torch.stack(train_losses).mean().item() model.epoch_end(epoch, result) history.append(result) return history . model = to_device(Cifar10CnnModel(), device) . evaluate(model, val_dl) # with initial set of parameters --&gt; random result . {&#39;val_loss&#39;: 2.3025383949279785, &#39;val_acc&#39;: 0.10006892681121826} . num_epochs = 10 opt_func = torch.optim.Adam lr = 0.001 . history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func) . Epoch [0], train_loss: 1.7970, val_loss: 1.5241, val_acc: 0.4321 Epoch [1], train_loss: 1.2961, val_loss: 1.1054, val_acc: 0.5995 Epoch [2], train_loss: 1.0374, val_loss: 0.9509, val_acc: 0.6613 Epoch [3], train_loss: 0.8626, val_loss: 0.9137, val_acc: 0.6765 Epoch [4], train_loss: 0.7339, val_loss: 0.7842, val_acc: 0.7312 Epoch [5], train_loss: 0.6354, val_loss: 0.7274, val_acc: 0.7429 Epoch [6], train_loss: 0.5439, val_loss: 0.7468, val_acc: 0.7462 Epoch [7], train_loss: 0.4626, val_loss: 0.7059, val_acc: 0.7701 Epoch [8], train_loss: 0.3961, val_loss: 0.7297, val_acc: 0.7634 Epoch [9], train_loss: 0.3301, val_loss: 0.7733, val_acc: 0.7660 . def plot_accuracies(history): accuracies = [x[&#39;val_acc&#39;] for x in history] plt.plot(accuracies, &#39;-x&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;accuracy&#39;) plt.title(&#39;Accuracy vs. No. of epochs&#39;); . plot_accuracies(history) . def plot_losses(history): train_losses = [x.get(&#39;train_loss&#39;) for x in history] val_losses = [x[&#39;val_loss&#39;] for x in history] plt.plot(train_losses, &#39;-x&#39;) plt.plot(val_losses, &#39;-rx&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;loss&#39;) plt.legend([&#39;Training&#39;, &#39;Validation&#39;]) plt.title(&#39;Loss vs No of epochs&#39;) . plot_losses(history) . Training error goes down and val error getting up after some time : overfitting . example: . Testing with Individual Images . test_dataset = ImageFolder(data_dir+&#39;/test&#39;, transform=ToTensor()) . def predict_image(img, model): xb = to_device(img.unsqueeze(0), device) # convert to batch of 1 yb = model(xb) # get predictions from model _, preds = torch.max(yb, dim=1) # pick max probab return dataset.classes[preds[0].item()] # retrive label . img, label = test_dataset[1] plt.imshow(img.permute(1, 2, 0)) print(&#39;Label:&#39;, dataset.classes[label], &#39;, Predicted:&#39;, predict_image(img, model)) . Label: airplane , Predicted: airplane . img, label = test_dataset[1002] plt.imshow(img.permute(1, 2, 0)) print(&#39;Label:&#39;, dataset.classes[label], &#39;, Predicted:&#39;, predict_image(img, model)) . Label: automobile , Predicted: automobile . img, label = test_dataset[0] plt.imshow(img.permute(1, 2, 0)) print(&#39;Label:&#39;, dataset.classes[label], &#39;, Predicted:&#39;, predict_image(img, model)) . Label: airplane , Predicted: automobile . img, label = test_dataset[6153] plt.imshow(img.permute(1, 2, 0)) print(&#39;Label:&#39;, dataset.classes[label], &#39;, Predicted:&#39;, predict_image(img, model)) . Label: frog , Predicted: frog . test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device) result = evaluate(model, test_loader) result . {&#39;val_loss&#39;: 0.7635641694068909, &#39;val_acc&#39;: 0.765625} . torch.save(model.state_dict(), &#39;cifar10-cnn.pth&#39;) .",
            "url": "https://mr-siddy.github.io/ML-blog/deep_learning/2021/06/09/Image-Classification-CNN-pytorch.html",
            "relUrl": "/deep_learning/2021/06/09/Image-Classification-CNN-pytorch.html",
            "date": " • Jun 9, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Training Deep Neural Networks on a GPU",
            "content": "Importing Libraries . import torch import torchvision import numpy as np import matplotlib import matplotlib.pyplot as plt import torch.nn as nn import torch.nn.functional as F from torchvision.datasets import MNIST from torchvision.transforms import ToTensor from torchvision.utils import make_grid from torch.utils.data.dataloader import DataLoader from torch.utils.data import random_split %matplotlib inline matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#ffffff&#39; . dataset = MNIST(root=&#39;data/&#39;, download=False, transform=ToTensor()) . image, label = dataset[0] image.permute(1, 2, 0).shape . torch.Size([28, 28, 1]) . image, label = dataset[0] print(&#39;image.shape:&#39;, image.shape) plt.imshow(image.permute(1, 2, 0), cmap=&#39;gray&#39;) # plt.imshow expects channels to be last dimension in an image tensor, so we use permute to reorder print(&#39;label:&#39;, label) . image.shape: torch.Size([1, 28, 28]) label: 5 . len(dataset) . 60000 . dataset[0] . image, label = dataset[143] print(&#39;image.shape:&#39;, image.shape) plt.imshow(image.permute(1, 2, 0), cmap=&#39;gray&#39;) # plt.imshow expects channels to be last dimension in an image tensor, so we use permute to reorder print(&#39;label:&#39;, label) . image.shape: torch.Size([1, 28, 28]) label: 2 . validation-set using random_split . val_size = 10000 train_size = len(dataset) - val_size train_ds, val_ds = random_split(dataset, [train_size, val_size]) len(train_ds), len(val_ds) . (50000, 10000) . PyTorch data loaders . batch_size = 128 . train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True) val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True) . num_workers attribute tells the data loader instance how many sub-processes to use for data loading. By default, the num_workers value is set to zero, and a value of zero tells the loader to load the data inside the main process. . pin_memory (bool, optional) – If True, the data loader will copy tensors into CUDA pinned memory before returning them. . for images, _ in train_loader: print(&#39;images.shape&#39;, images.shape) print(&#39;grid.shape&#39;, make_grid(images, nrow=16).shape) break . images.shape torch.Size([128, 1, 28, 28]) grid.shape torch.Size([3, 242, 482]) . for images, _ in train_loader: print(&#39;image.shape:&#39;, image.shape) plt.figure(figsize=(16,8)) plt.axis(&#39;off&#39;) plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0))) break . image.shape: torch.Size([1, 28, 28]) . Creating NN . Hidden Layers, Activation function and Non-Linearity . for images, labels in train_loader: print(&#39;images.shape&#39;, images.shape) inputs = images.reshape(-1, 784) print(&#39;inputs.shape&#39;, inputs.shape) break . images.shape torch.Size([128, 1, 28, 28]) inputs.shape torch.Size([128, 784]) . input_size = inputs.shape[-1] #size of output from hidden layer is 32, can be inc or dec to change the learning capacity of model hidden_size = 32 . layer1 = nn.Linear(input_size, hidden_size ) # it will convert 784 to 32 . inputs.shape . torch.Size([128, 784]) . layer1_outputs = layer1(inputs) print(&#39;layer1_outputs&#39;, layer1_outputs.shape) . layer1_outputs torch.Size([128, 32]) . layer1_outputs_direct = inputs @ layer1.weight.t() + layer1.bias layer1_outputs_direct.shape . torch.Size([128, 32]) . torch.allclose(layer1_outputs, layer1_outputs_direct, 1e-3) . True . Thus, layer1_outputs and inputs have a linear relationship, i.e., each element of layer_outputs is a weighted sum of elements from inputs. Thus, even as we train the model and modify the weights, layer1 can only capture linear relationships between inputs and outputs. . . Next, we&#39;ll use the Rectified Linear Unit (ReLU) function as the activation function for the outputs. It has the formula relu(x) = max(0,x) i.e. it simply replaces negative values in a given tensor with the value 0. ReLU is a non-linear function . We can use the F.relu method to apply ReLU to the elements of a tensor. . . . F.relu(torch.tensor([[1, -1, 0], [-0.1, .2, 3]])) . tensor([[1.0000, 0.0000, 0.0000], [0.0000, 0.2000, 3.0000]]) . layer1_outputs.shape . torch.Size([128, 32]) . relu_outputs = F.relu(layer1_outputs) print(&#39;relu_outputs.shape:&#39;, relu_outputs.shape) print(&#39;min(layer1_outputs):&#39;, torch.min(layer1_outputs).item()) print(&#39;min(relu_outputs):&#39;, torch.min(relu_outputs).item()) . relu_outputs.shape: torch.Size([128, 32]) min(layer1_outputs): -0.6917587518692017 min(relu_outputs): 0.0 . output_size = 10 layer2 = nn.Linear(hidden_size, output_size) . layer2_outputs = layer2(relu_outputs) print(&#39;relu_outputs.shape:&#39;, relu_outputs.shape) print(&#39;layer2_outputs.shape:&#39;, layer2_outputs.shape) . relu_outputs.shape: torch.Size([128, 32]) layer2_outputs.shape: torch.Size([128, 10]) . inputs.shape . torch.Size([128, 784]) . F.cross_entropy(layer2_outputs, labels) . tensor(2.2991, grad_fn=&lt;NllLossBackward&gt;) . outputs = (F.relu(inputs @ layer1.weight.t() +layer1.bias)) @ layer2.weight.t() + layer2.bias . torch.allclose(outputs, layer2_outputs, 1e-3) . True . if we hadn&#39;t included a non-linear activation between the two linear layers, the final relationship b/w inputs and outputs would be Linear . outputs2 = (inputs @ layer1.weight.t() + layer1.bias) @ layer2.weight.t() + layer2.bias . combined_layer = nn.Linear(input_size, output_size) combined_layer.weight.data = layer2.weight @ layer1.weight combined_layer.bias.data = layer1.bias @ layer2.weight.t() + layer2.bias . outputs3 = inputs @ combined_layer.weight.t() + combined_layer.bias . torch.allclose(outputs2, outputs3, 1e-3) . False . Model . We are now ready to define our model. As discussed above, we&#39;ll create a neural network with one hidden layer. Here&#39;s what that means: . Instead of using a single nn.Linear object to transform a batch of inputs (pixel intensities) into outputs (class probabilities), we&#39;ll use two nn.Linear objects. Each of these is called a layer in the network. . | The first layer (also known as the hidden layer) will transform the input matrix of shape batch_size x 784 into an intermediate output matrix of shape batch_size x hidden_size. The parameter hidden_size can be configured manually (e.g., 32 or 64). . | We&#39;ll then apply a non-linear activation function to the intermediate outputs. The activation function transforms individual elements of the matrix. . | The result of the activation function, which is also of size batch_size x hidden_size, is passed into the second layer (also known as the output layer). The second layer transforms it into a matrix of size batch_size x 10. We can use this output to compute the loss and adjust weights using gradient descent. . | . As discussed above, our model will contain one hidden layer. Here&#39;s what it looks like visually: . . Let&#39;s define the model by extending the nn.Module class from PyTorch. . class MnistModel(nn.Module): def __init__(self, in_size, hidden_size, out_size): super().__init__() self.Linear1 = nn.Linear(in_size, hidden_size) # hidden layer self.Linear2 = nn.Linear(hidden_size, out_size) # output layer def forward(self, xb): xb = xb.view(xb.size(0),-1) # flatten image tensor out = self.Linear1(xb) # intermediate outputs using hidden layer out = F.relu(out) # applying activation function out = self.Linear2(out) # predictions using o/p layer return out def training_step(self, batch): images, labels = batch out = self(images) loss = F.cross_entropy(out, labels) return loss def validation_step(self, batch): images, labels = batch out = self(images) loss = F.cross_entropy(out, labels) acc = accuracy(out, labels) return {&#39;val_loss&#39;: loss, &#39;val_acc&#39;: acc} def validation_epoch_end(self, outputs): batch_loss = [x[&#39;val_loss&#39;] for x in outputs] epoch_loss = torch.stack(batch_loss).mean() # Combine losses batch_accs = [x[&#39;val_acc&#39;] for x in outputs] epoch_acc = torch.stack(batch_accs).mean() # combine accuracies return {&#39;val_loss&#39;: epoch_loss.item(), &#39;val_acc&#39;: epoch_acc.item()} def epoch_end(self, epoch, result): print(&quot;Epoch [{}], val_loss: {:4f}, val_acc: {:4f}&quot;.format(epoch, result[&#39;val_loss&#39;], result[&#39;val_acc&#39;])) . def accuracy(outputs, labels): _, preds = torch.max(outputs, dim=1) return torch.tensor(torch.sum(preds == labels).item() / len(preds)) . input_size = 784 hidden_size = 32 num_classes = 10 . model = MnistModel(input_size, hidden_size, out_size = num_classes) . for t in model.parameters(): # weights and bias for linear layer and hidden layer print(t.shape) . torch.Size([32, 784]) torch.Size([32]) torch.Size([10, 32]) torch.Size([10]) . for images, labels in train_loader: outputs = model(images) break loss = F.cross_entropy(outputs, labels) print(&#39;Loss:&#39;, loss.item()) print(&#39;outputs.shape: &#39;, outputs.shape) print(&#39;Sample outputs :&#39;, outputs[:2].data) . Loss: 2.3032402992248535 outputs.shape: torch.Size([128, 10]) Sample outputs : tensor([[ 0.0308, 0.1783, -0.0268, -0.1578, -0.1123, -0.0013, 0.1285, -0.0645, -0.0745, -0.0817], [-0.0028, 0.2039, -0.0196, -0.1190, -0.1853, 0.0436, 0.0258, 0.0813, -0.1292, -0.0431]]) . Training the Model using GPU . torch.cuda.is_available() . True . def get_default_device(): if torch.cuda.is_available(): return torch.device(&#39;cuda&#39;) else: return torch.device(&#39;cpu&#39;) . device = get_default_device() device . device(type=&#39;cuda&#39;) . def to_device(data, device): &quot;&quot;&quot;MOve tensors to chosen device&quot;&quot;&quot; if isinstance(data, (list,tuple)): return [to_device(x, device) for x in data] return data.to(device, non_blocking = True) # to method . for images, labels in train_loader: print(images.shape) print(images.device) images = to_device(images, device) print(images.device) break . torch.Size([128, 1, 28, 28]) cpu cuda:0 . DeviceDataLeader class to wrap our existing data loaders and move batches of data to the selected device, iter method to retrieve batches of data and an len to get number of batches . class DeviceDataLoader(): # wrap a dataloader to move data to device def __init__(self, dl , device): self.dl = dl self.device = device # yield a batch of data after moving it to device def __iter__(self): for b in self.dl: yield to_device(b, self.device) # number of batches def __len__(self): return len(self.dl) . # example def some_numbers(): yield 10 yield 20 yield 30 for value in some_numbers(): print(value) . 10 20 30 . train_loader = DeviceDataLoader(train_loader, device) val_loader = DeviceDataLoader(val_loader, device) . for xb, yb in val_loader: print(&#39;xb.device:&#39;, xb.device) print(&#39;yb:&#39;, yb) break . xb.device: cuda:0 yb: tensor([1, 4, 3, 7, 8, 2, 2, 2, 0, 1, 3, 7, 1, 2, 7, 6, 5, 2, 7, 6, 4, 6, 3, 0, 3, 7, 2, 1, 5, 1, 5, 0, 6, 0, 7, 1, 9, 3, 5, 6, 6, 6, 3, 1, 2, 7, 0, 1, 7, 4, 3, 9, 7, 2, 1, 4, 3, 4, 8, 3, 1, 0, 9, 6, 4, 0, 2, 5, 2, 6, 7, 4, 4, 6, 7, 3, 4, 0, 0, 2, 5, 5, 5, 5, 0, 9, 4, 3, 9, 6, 0, 4, 8, 6, 2, 8, 1, 7, 8, 2, 4, 4, 6, 6, 7, 0, 7, 4, 0, 1, 1, 9, 4, 0, 9, 2, 4, 2, 8, 6, 7, 1, 5, 3, 7, 8, 4, 2, 6, 8, 1, 7, 3, 8, 4, 4, 7, 9, 7, 2, 9, 6, 8, 7, 9, 4, 3, 5, 1, 9, 8, 9, 1, 3, 9, 6, 9, 9, 9, 9, 7, 4, 3, 3, 1, 2, 7, 8, 5, 8, 0, 8, 3, 1, 6, 3, 1, 0, 6, 6, 1, 5, 4, 7, 9, 4, 5, 4, 2, 3, 3, 2, 9, 6, 6, 3, 8, 4, 4, 2, 1, 7, 7, 3, 4, 5, 8, 2, 9, 9, 6, 8, 7, 6, 0, 6, 0, 0, 1, 1, 1, 4, 0, 9, 5, 2, 0, 3, 0, 0, 0, 4, 7, 9, 6, 0, 3, 4, 5, 6, 0, 0, 9, 7, 8, 6, 3, 0, 7, 8, 7, 7, 4, 0, 8, 0], device=&#39;cuda:0&#39;) . Training part . def evaluate(model, val_loader): outputs = [model.validation_step(batch) for batch in val_loader] return model.validation_epoch_end(outputs) def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD): history = [] optimizer = opt_func(model.parameters(), lr) for epoch in range(epochs): #training phase for batch in train_loader: loss = model.training_step(batch) loss.backward() optimizer.step() optimizer.zero_grad() #validation phase result = evaluate(model, val_loader) model.epoch_end(epoch, result) history.append(result) return history . model = MnistModel(input_size, hidden_size= hidden_size, out_size=num_classes) to_device(model, device) . MnistModel( (Linear1): Linear(in_features=784, out_features=32, bias=True) (Linear2): Linear(in_features=32, out_features=10, bias=True) ) . history = [evaluate(model, val_loader)] history . [{&#39;val_loss&#39;: 2.309469223022461, &#39;val_acc&#39;: 0.12490234524011612}] . history += fit(5, 0.5, model, train_loader, val_loader) . Epoch [0], val_loss: 0.202114, val_acc: 0.941016 Epoch [1], val_loss: 0.156000, val_acc: 0.953223 Epoch [2], val_loss: 0.156326, val_acc: 0.953516 Epoch [3], val_loss: 0.127720, val_acc: 0.962598 Epoch [4], val_loss: 0.119708, val_acc: 0.962793 . try with more less lr . history += fit(5, 0.1, model, train_loader, val_loader) . Epoch [0], val_loss: 0.109468, val_acc: 0.967578 Epoch [1], val_loss: 0.105522, val_acc: 0.968164 Epoch [2], val_loss: 0.105320, val_acc: 0.969824 Epoch [3], val_loss: 0.104688, val_acc: 0.969629 Epoch [4], val_loss: 0.104357, val_acc: 0.968555 . Lmao acc ~ 96% . losses = [x[&#39;val_loss&#39;] for x in history] plt.plot(losses, &#39;-x&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;loss&#39;) plt.title(&#39;Loss v/s Epochs&#39;) . Text(0.5, 1.0, &#39;Loss v/s Epochs&#39;) . accuracies = [x[&#39;val_acc&#39;] for x in history] plt.plot(accuracies, &#39;-x&#39;) plt.xlabel(&#39;epochs&#39;) plt.ylabel(&#39;accuracies&#39;) plt.title(&#39;Accuracies v/s Epochs&#39;) . Text(0.5, 1.0, &#39;Accuracies v/s Epochs&#39;) . Testing with Individual Images . test_dataset = MNIST(root=&#39;data/&#39;, train=False, transform=ToTensor()) . def predict_image(img, model): xb = to_device(img.unsqueeze(0), device) print(xb.device) yb = model(xb) _, preds = torch.max(yb, dim=1) return preds[0].item() . img, label = test_dataset[0] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label, &#39;Prediction:&#39;, predict_image(img, model)) . cuda:0 Label: 7 Prediction: 7 . img, label = test_dataset[123] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label, &#39;Prediction:&#39;, predict_image(img, model)) . cuda:0 Label: 6 Prediction: 6 . img, label = test_dataset[183] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label, &#39;Prediction:&#39;, predict_image(img, model)) . cuda:0 Label: 0 Prediction: 0 . test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size=256), device) result = evaluate(model, test_loader) result . {&#39;val_loss&#39;: 0.10134970396757126, &#39;val_acc&#39;: 0.9697265625} . torch.save(model.state_dict(), &#39;mnist-feedforward.pth&#39;) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/06/03/NN-on-GPU.html",
            "relUrl": "/2021/06/03/NN-on-GPU.html",
            "date": " • Jun 3, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Logistic Regression on MNIST Database using Pytorch",
            "content": "import torch import torchvision from torchvision.datasets import MNIST . Working with Image . We&#39;ll use the famous MNIST Handwritten Digits Database as our training dataset. It consists of 28px by 28px grayscale images of handwritten digits (0 to 9) and labels for each image indicating which digit it represents. Here are some sample images from the dataset: . . Data Preprocessing . dataset = MNIST(root=&#39;data/&#39;, download=True) . len(dataset) . 60000 . test_dataset = MNIST(root=&#39;data/&#39;, train=False) len(test_dataset) . 10000 . dataset[0] # it gives :- image(part of pillow), 5 (label digit) . (&lt;PIL.Image.Image image mode=L size=28x28 at 0x25EA9AE4748&gt;, 5) . import matplotlib.pyplot as plt #indicates to jupyter we want to plot graphs within the notebook, without this it will show in popup %matplotlib inline . image, label = dataset[0] plt.imshow(image, cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label) . Label: 5 . image, label = dataset[10] plt.imshow(image, cmap=&#39;gray&#39;) print(&#39;Label:&#39;, label) . Label: 3 . Pytorch dosen&#39;t know how to work with images, we need to convert images to tensors by specifying transform while creating our dataset . import torchvision.transforms as transform . dataset = MNIST(root=&#39;data/&#39;, train=True, transform=transform.ToTensor()) . img_tensor, label = dataset[0] print(img_tensor.shape,label) . torch.Size([1, 28, 28]) 5 . img_tensor . tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706, 0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275, 0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922, 0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922, 0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922, 0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]) . print(img_tensor[:,10:15,10:15]) print(torch.max(img_tensor),torch.min(img_tensor)) . tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000], [0.0000, 0.5451, 0.9922, 0.7451, 0.0078], [0.0000, 0.0431, 0.7451, 0.9922, 0.2745], [0.0000, 0.0000, 0.1373, 0.9451, 0.8824], [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]]) tensor(1.) tensor(0.) . plt.imshow(img_tensor[0,10:15,10:15], cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x25eadd15c08&gt; . Training and Validation Datasets . Training set - used to train the model, i.e., compute the loss and adjust the model&#39;s weights using gradient descent. | Validation set - used to evaluate the model during training, adjust hyperparameters (learning rate, etc.), and pick the best version of the model. | Test set - used to compare different models or approaches and report the model&#39;s final accuracy. | In the MNIST dataset, there are 60,000 training images and 10,000 test images. The test set is standardized so that different researchers can report their models&#39; results against the same collection of images. . Since there&#39;s no predefined validation set, we must manually split the 60,000 images into training and validation datasets. Let&#39;s set aside 10,000 randomly chosen images for validation. We can do this using the random_spilt method from PyTorch. . # using random_split from torch.utils.data import random_split train_ds, val_ds = random_split(dataset, [50000, 10000]) len(train_ds), len(val_ds) . (50000, 10000) . from torch.utils.data import DataLoader batch_size = 128 train_loader = DataLoader(train_ds, batch_size, shuffle=True) # shuffle=True for the training data loader to ensure batches generated in each epoch are different # randomization helps generalize and speed=up the training process val_loader = DataLoader(val_ds, batch_size ) . Model . A logistic regression model is almost identical to a linear regression model. It contains weights and bias matrices, and the output is obtained using simple matrix operations (pred = x @ w.t() + b). . | As we did with linear regression, we can use nn.Linear to create the model instead of manually creating and initializing the matrices. . | Since nn.Linear expects each training example to be a vector, each 1x28x28 image tensor is flattened into a vector of size 784 (28*28) before being passed into the model. . | The output for each image is a vector of size 10, with each element signifying the probability of a particular target label (i.e., 0 to 9). The predicted label for an image is simply the one with the highest probability. . | . import torch.nn as nn input_size = 28*28 num_classes = 10 #Logistic regression model model = nn.Linear(input_size, num_classes) . print(model.weight.shape) model.weight . torch.Size([10, 784]) . Parameter containing: tensor([[ 0.0097, -0.0244, -0.0155, ..., -0.0295, 0.0300, -0.0210], [ 0.0036, 0.0262, -0.0189, ..., 0.0118, 0.0162, -0.0324], [ 0.0041, -0.0117, -0.0011, ..., 0.0128, 0.0156, -0.0292], ..., [-0.0163, -0.0195, -0.0283, ..., -0.0236, 0.0138, 0.0091], [ 0.0336, -0.0344, 0.0232, ..., -0.0277, -0.0007, -0.0115], [ 0.0130, 0.0136, 0.0206, ..., 0.0128, -0.0171, -0.0017]], requires_grad=True) . print(model.bias.shape) model.bias . torch.Size([10]) . Parameter containing: tensor([ 0.0144, -0.0100, 0.0354, -0.0225, -0.0262, 0.0286, 0.0230, -0.0162, -0.0203, 0.0171], requires_grad=True) . so total parameters = 7850 . for images, labels in train_loader: print(labels) print(images.shape) outputs = model(images) print(outputs) break . tensor([7, 2, 1, 5, 4, 8, 6, 0, 0, 5, 3, 7, 9, 0, 8, 4, 5, 2, 5, 9, 3, 0, 6, 6, 4, 9, 2, 1, 5, 9, 3, 3, 4, 1, 0, 4, 2, 0, 0, 5, 6, 8, 9, 7, 6, 0, 4, 1, 2, 1, 9, 2, 6, 8, 5, 2, 8, 7, 7, 9, 7, 6, 7, 5, 9, 5, 5, 9, 1, 7, 5, 0, 7, 7, 2, 5, 0, 8, 1, 1, 7, 8, 7, 4, 7, 3, 1, 6, 4, 9, 9, 3, 9, 3, 5, 6, 6, 5, 6, 4, 2, 4, 5, 1, 8, 7, 0, 3, 9, 9, 5, 2, 7, 6, 9, 8, 5, 1, 3, 2, 3, 6, 4, 1, 3, 9, 7, 3]) torch.Size([128, 1, 28, 28]) . RuntimeError Traceback (most recent call last) &lt;ipython-input-21-170d6f073b97&gt; in &lt;module&gt; 4 print(labels) 5 print(images.shape) -&gt; 6 outputs = model(images) 7 print(outputs) 8 break ~ anaconda3 envs torch lib site-packages torch nn modules module.py in _call_impl(self, *input, **kwargs) 887 result = self._slow_forward(*input, **kwargs) 888 else: --&gt; 889 result = self.forward(*input, **kwargs) 890 for hook in itertools.chain( 891 _global_forward_hooks.values(), ~ anaconda3 envs torch lib site-packages torch nn modules linear.py in forward(self, input) 92 93 def forward(self, input: Tensor) -&gt; Tensor: &gt; 94 return F.linear(input, self.weight, self.bias) 95 96 def extra_repr(self) -&gt; str: ~ anaconda3 envs torch lib site-packages torch nn functional.py in linear(input, weight, bias) 1751 if has_torch_function_variadic(input, weight): 1752 return handle_torch_function(linear, (input, weight), input, weight, bias=bias) -&gt; 1753 return torch._C._nn.linear(input, weight, bias) 1754 1755 RuntimeError: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10) . error occurred bcoz, input data dosen&#39;t have right shape. images are of the shape 1x28x28, but we need them to be vectors of size 784 ie we need to flatten them --&gt; using .reshape . images.shape . torch.Size([128, 1, 28, 28]) . images.reshape(128,784).shape . torch.Size([128, 784]) . To include this additional function within out model, we need to define a custom model by extending the nn.Module class . Inside the __init__ constructor method, we instantiate the weights and biases using nn.Linear. And inside the forward method, which is invoked when we pass a batch of inputs to the model, we flatten the input tensor and pass it into self.linear. . xb.reshape(-1, 28*28) indicates to PyTorch that we want a view of the xb tensor with two dimensions. The length along the 2nd dimension is 28*28 (i.e., 784). One argument to .reshape can be set to -1 (in this case, the first dimension) to let PyTorch figure it out automatically based on the shape of the original tensor. . Note that the model no longer has .weight and .bias attributes (as they are now inside the .linear attribute), but it does have a .parameters method that returns a list containing the weights and bias. . class MnistModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(input_size, num_classes) def forward(self, xb): xb = xb.reshape(-1, 784) out = self.linear(xb) return out model = MnistModel() #object . model.linear . Linear(in_features=784, out_features=10, bias=True) . print(model.linear.weight.shape, model.linear.bias.shape) list(model.parameters()) # bundle all weights and biases . torch.Size([10, 784]) torch.Size([10]) . [Parameter containing: tensor([[ 3.4617e-02, 2.8410e-02, 2.5686e-02, ..., -1.5863e-02, -3.8656e-03, 1.5305e-02], [-1.8018e-02, 1.7917e-02, -3.0232e-02, ..., -5.3763e-03, -3.2701e-02, 1.7136e-02], [-3.4262e-02, 8.5667e-03, -2.0011e-02, ..., -1.8257e-02, 3.4308e-02, 1.8136e-02], ..., [ 9.5943e-03, 1.6986e-02, 2.2343e-02, ..., 4.5605e-03, 9.5017e-03, -2.5854e-04], [-1.4468e-02, -2.7529e-02, 2.9830e-02, ..., -9.3204e-03, 6.1549e-03, -2.5384e-02], [ 3.3574e-02, 2.1621e-03, -8.8337e-03, ..., -4.9651e-05, -2.1324e-02, 2.4071e-03]], requires_grad=True), Parameter containing: tensor([ 0.0054, -0.0311, 0.0240, 0.0014, -0.0334, 0.0090, -0.0151, -0.0068, 0.0042, -0.0279], requires_grad=True)] . for images, labels in train_loader: outputs = model(images) break print(&#39;output.shape :&#39;, outputs.shape) print(&#39;Sample outputs layer 0 :&#39;, outputs[0].data) print(&#39;Sample outputs layer 0 and 1 :&#39;, outputs[:2].data) . output.shape : torch.Size([128, 10]) Sample outputs layer 0 : tensor([-0.1530, -0.4023, 0.0156, -0.0506, 0.0551, -0.2542, 0.0123, -0.3361, -0.1795, 0.1995]) Sample outputs layer 0 and 1 : tensor([[-0.1530, -0.4023, 0.0156, -0.0506, 0.0551, -0.2542, 0.0123, -0.3361, -0.1795, 0.1995], [-0.2933, -0.3964, 0.2764, -0.0050, -0.0035, -0.0671, 0.2888, -0.2759, -0.1555, 0.0238]]) . For each of the 100 input images, we get 10 outputs, one for each class. As discussed earlier, we&#39;d like these outputs to represent probabilities. Each output row&#39;s elements must lie between 0 to 1 and add up to 1, which is not the case. . To convert the output rows into probabilities, we use the softmax function, which has the following formula: . . First, we replace each element yi in an output row by e^yi, making all the elements positive. . . Then, we divide them by their sum to ensure that they add up to 1. The resulting vector can thus be interpreted as probabilities. . we&#39;ll use the implementation that&#39;s provided within PyTorch because it works well with multidimensional tensors (a list of output rows in our case). . import torch.nn.functional as F . outputs[0:2] . tensor([[-0.1530, -0.4023, 0.0156, -0.0506, 0.0551, -0.2542, 0.0123, -0.3361, -0.1795, 0.1995], [-0.2933, -0.3964, 0.2764, -0.0050, -0.0035, -0.0671, 0.2888, -0.2759, -0.1555, 0.0238]], grad_fn=&lt;SliceBackward&gt;) . probs = F.softmax(outputs, dim=1) # apply softmax for each output row # see why dim=0 dosen&#39;t workout print(&quot;sample probabilities: n&quot;, probs[:2].data) #sample probs print(&quot;Sum: &quot;, torch.sum(probs[0]).item()) # addup probs of an output row . sample probabilities: tensor([[0.0942, 0.0734, 0.1115, 0.1044, 0.1160, 0.0851, 0.1111, 0.0784, 0.0917, 0.1340], [0.0774, 0.0698, 0.1368, 0.1032, 0.1034, 0.0970, 0.1385, 0.0787, 0.0888, 0.1063]]) Sum: 1.0 . max_probs, preds = torch.max(probs, dim=1) print(preds) print(max_probs) . tensor([9, 6, 2, 9, 2, 2, 9, 5, 3, 9, 3, 8, 6, 9, 2, 9, 9, 8, 9, 9, 9, 3, 6, 3, 6, 3, 5, 3, 2, 2, 3, 9, 9, 8, 2, 2, 9, 6, 6, 4, 2, 0, 9, 9, 2, 2, 9, 9, 2, 9, 9, 9, 9, 9, 9, 9, 6, 9, 3, 3, 6, 9, 9, 3, 2, 3, 9, 8, 4, 8, 8, 4, 9, 2, 5, 2, 9, 2, 8, 2, 2, 6, 3, 4, 9, 9, 9, 9, 6, 6, 9, 6, 9, 3, 9, 9, 0, 6, 3, 2, 3, 5, 5, 3, 8, 3, 8, 2, 4, 3, 0, 9, 9, 6, 6, 3, 5, 2, 3, 9, 3, 2, 7, 9, 9, 2, 9, 9]) tensor([0.1340, 0.1385, 0.1331, 0.1312, 0.1378, 0.1389, 0.1765, 0.1426, 0.1205, 0.1485, 0.1351, 0.1217, 0.1359, 0.1315, 0.1463, 0.1313, 0.1251, 0.1250, 0.1213, 0.1374, 0.1270, 0.1285, 0.1210, 0.1202, 0.1537, 0.1311, 0.1201, 0.1155, 0.1454, 0.1945, 0.1293, 0.1238, 0.1146, 0.1202, 0.1568, 0.1285, 0.1396, 0.1146, 0.1350, 0.1179, 0.1579, 0.1335, 0.1622, 0.1176, 0.1568, 0.1461, 0.1368, 0.1345, 0.1403, 0.1409, 0.1426, 0.1331, 0.1502, 0.1324, 0.1265, 0.1440, 0.1352, 0.1367, 0.1186, 0.1284, 0.1301, 0.1446, 0.1604, 0.1328, 0.1556, 0.1515, 0.1254, 0.1221, 0.1191, 0.1351, 0.1306, 0.1152, 0.1264, 0.1515, 0.1167, 0.1381, 0.1342, 0.1423, 0.1233, 0.1406, 0.1184, 0.1247, 0.1140, 0.1443, 0.1542, 0.1410, 0.1169, 0.1249, 0.1407, 0.1257, 0.1382, 0.1283, 0.1415, 0.1145, 0.1345, 0.1229, 0.1267, 0.1291, 0.1408, 0.1413, 0.1231, 0.1289, 0.1252, 0.1473, 0.1149, 0.1233, 0.1328, 0.1257, 0.1239, 0.1239, 0.1235, 0.1495, 0.1488, 0.1119, 0.1191, 0.1328, 0.1396, 0.1598, 0.1483, 0.1271, 0.1297, 0.1417, 0.1131, 0.1655, 0.1422, 0.1257, 0.1339, 0.1229], grad_fn=&lt;MaxBackward0&gt;) . labels . tensor([9, 8, 5, 3, 3, 3, 2, 1, 0, 7, 2, 5, 3, 4, 8, 7, 4, 1, 9, 4, 9, 4, 4, 7, 0, 9, 1, 7, 0, 0, 8, 5, 1, 8, 0, 4, 7, 8, 2, 5, 2, 1, 4, 6, 0, 8, 6, 9, 5, 4, 9, 4, 9, 3, 4, 6, 3, 8, 1, 2, 2, 4, 9, 9, 5, 6, 9, 1, 8, 5, 8, 2, 9, 0, 3, 0, 9, 7, 1, 1, 7, 8, 9, 7, 9, 4, 4, 6, 6, 3, 7, 5, 9, 8, 1, 9, 9, 0, 2, 0, 0, 5, 1, 3, 9, 8, 1, 6, 9, 4, 6, 2, 5, 6, 8, 2, 1, 0, 2, 5, 7, 6, 7, 7, 0, 1, 4, 6]) . Evaluation Metric and Loss Function . outputs[:2] . tensor([[-0.1530, -0.4023, 0.0156, -0.0506, 0.0551, -0.2542, 0.0123, -0.3361, -0.1795, 0.1995], [-0.2933, -0.3964, 0.2764, -0.0050, -0.0035, -0.0671, 0.2888, -0.2759, -0.1555, 0.0238]], grad_fn=&lt;SliceBackward&gt;) . preds == labels . tensor([ True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, True, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, True, False, True, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, True, False, False, True, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False]) . torch.sum(preds == labels) # this is telling how many out of 128 were get predicted correctly . tensor(21) . Accuracy of predictions . def accuracy(outputs, labels): _, preds = torch.max(outputs, dim=1) return torch.tensor(torch.sum(preds == labels).item() / len(preds)) . accuracy(outputs,labels) . tensor(0.1641) . The == operator performs an element-wise comparison of two tensors with the same shape and returns a tensor of the same shape, containing True for unequal elements and False for equal elements. Passing the result to torch.sum returns the number of labels that were predicted correctly. Finally, we divide by the total number of images to get the accuracy. . Note that we don&#39;t need to apply softmax to the outputs since its results have the same relative order. This is because e^x is an increasing function, i.e., if y1 &gt; y2, then e^y1 &gt; e^y2. The same holds after averaging out the values to get the softmax. . Let&#39;s calculate the accuracy of the current model on the first batch of data. . Accuracy is an excellent way for us (humans) to evaluate the model. However, we can&#39;t use it as a loss function for optimizing our model using gradient descent for the following reasons: . It&#39;s not a differentiable function. torch.max and == are both non-continuous and non-differentiable operations, so we can&#39;t use the accuracy for computing gradients w.r.t the weights and biases. . | It doesn&#39;t take into account the actual probabilities predicted by the model, so it can&#39;t provide sufficient feedback for incremental improvements. . | For these reasons, accuracy is often used as an evaluation metric for classification, but not as a loss function. A commonly used loss function for classification problems is the cross-entropy, which has the following formula: . . While it looks complicated, it&#39;s actually quite simple: . For each output row, pick the predicted probability for the correct label. E.g., if the predicted probabilities for an image are [0.1, 0.3, 0.2, ...] and the correct label is 1, we pick the corresponding element 0.3 and ignore the rest. . | Then, take the logarithm of the picked probability. If the probability is high, i.e., close to 1, then its logarithm is a very small negative value, close to 0. And if the probability is low (close to 0), then the logarithm is a very large negative value. We also multiply the result by -1, which results is a large postive value of the loss for poor predictions. . | . . Finally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data. | . Unlike accuracy, cross-entropy is a continuous and differentiable function. It also provides useful feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). These two factors make cross-entropy a better choice for the loss function. . As you might expect, PyTorch provides an efficient and tensor-friendly implementation of cross-entropy as part of the torch.nn.functional package. Moreover, it also performs softmax internally, so we can directly pass in the model&#39;s outputs without converting them into probabilities. . probs . tensor([[0.0942, 0.0734, 0.1115, ..., 0.0784, 0.0917, 0.1340], [0.0774, 0.0698, 0.1368, ..., 0.0787, 0.0888, 0.1063], [0.1088, 0.0800, 0.1331, ..., 0.0638, 0.0798, 0.1175], ..., [0.1022, 0.0864, 0.1257, ..., 0.0881, 0.1148, 0.1158], [0.0974, 0.0822, 0.0975, ..., 0.0675, 0.0971, 0.1339], [0.0905, 0.1213, 0.1075, ..., 0.0760, 0.1040, 0.1229]], grad_fn=&lt;SoftmaxBackward&gt;) . loss_fn = F.cross_entropy . loss = loss_fn(outputs, labels) . print(loss) . tensor(2.3150, grad_fn=&lt;NllLossBackward&gt;) . Training the model . def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD): optimizer = opt_func(model.parameters(), lr) history = [] # for reading epoch-wise results for epoch in range(epochs): #training phase for batch in train_loader: loss = model.training_step(batch) loss.backward() optimizer.step() # change the gradients using the learning rate optimizer.zero_grad() #validation phase result = evaluate(model, val_loader) model.epoch_end(epoch, result) history.append(result) return history . def evaluate(model, val_loader): outputs = [model.validation_step(batch) for batch in val_loader] #list comprehension return model.validation_epoch_end(outputs) . Gaps to fill-in are : training_step, validation_step, validation_epoch_end, epoch_end used by : fit, evaluate . class MnistModel(nn.Module): def __init__(self): super().__init__() self.linear = nn.Linear(input_size, num_classes) def forward(self, xb): xb = xb.reshape(-1, 784) out = self.linear(xb) return out def training_step(self, batch): images, labels = batch out = self(images) # Generate predictions loss = F.cross_entropy(out, labels) # Calculate loss return loss def validation_step(self, batch): images, labels = batch out = self(images) # Generate predictions loss = F.cross_entropy(out, labels) #loss acc = accuracy(out, labels) # clac accuracy return {&#39;val_loss&#39;: loss, &#39;val_acc&#39;: acc} def validation_epoch_end(self, outputs): batch_losses = [x[&#39;val_loss&#39;] for x in outputs] epoch_loss = torch.stack(batch_losses).mean() #combine losses batch_accs = [x[&#39;val_acc&#39;] for x in outputs] epoch_accs = torch.stack(batch_accs).mean() #combine accuracies return {&#39;val_loss&#39;: epoch_loss.item(), &#39;val_acc&#39;: epoch_accs.item()} def epoch_end(self, epoch, result): print(&quot;Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}&quot;.format(epoch, result[&#39;val_loss&#39;], result[&#39;val_acc&#39;])) model = MnistModel() . result0 = evaluate(model, val_loader) result0 . {&#39;val_loss&#39;: 2.283280611038208, &#39;val_acc&#39;: 0.10749604552984238} . Train the model . history1 = fit(5, 0.001, model, train_loader, val_loader) . Epoch [0], val_loss: 1.9208, val_acc: 0.6665 Epoch [1], val_loss: 1.6565, val_acc: 0.7396 Epoch [2], val_loss: 1.4599, val_acc: 0.7663 Epoch [3], val_loss: 1.3116, val_acc: 0.7836 Epoch [4], val_loss: 1.1978, val_acc: 0.7975 . history2 = fit(5, 0.001, model, train_loader, val_loader) . Epoch [0], val_loss: 1.1083, val_acc: 0.8057 Epoch [1], val_loss: 1.0365, val_acc: 0.8137 Epoch [2], val_loss: 0.9777, val_acc: 0.8194 Epoch [3], val_loss: 0.9287, val_acc: 0.8240 Epoch [4], val_loss: 0.8873, val_acc: 0.8287 . history3 = fit(5, 0.001, model, train_loader, val_loader) . Epoch [0], val_loss: 0.8517, val_acc: 0.8326 Epoch [1], val_loss: 0.8210, val_acc: 0.8360 Epoch [2], val_loss: 0.7939, val_acc: 0.8392 Epoch [3], val_loss: 0.7700, val_acc: 0.8419 Epoch [4], val_loss: 0.7487, val_acc: 0.8445 . history4 = fit(5, 0.001, model, train_loader, val_loader) . Epoch [0], val_loss: 0.7295, val_acc: 0.8467 Epoch [1], val_loss: 0.7123, val_acc: 0.8480 Epoch [2], val_loss: 0.6966, val_acc: 0.8495 Epoch [3], val_loss: 0.6822, val_acc: 0.8513 Epoch [4], val_loss: 0.6691, val_acc: 0.8527 . Visualization . history = [result0] + history1 + history2 + history3 + history4 accuracies = [result[&#39;val_acc&#39;] for result in history] plt.plot(accuracies, &#39;-x&#39;) plt.xlabel(&#39;epoch&#39;) plt.ylabel(&#39;accuracy&#39;) plt.title(&#39;Accuarcy vs No of epochs&#39;); . Testing on Individual Images . from torchvision import transforms . test_dataset = MNIST(root=&#39;data/&#39;, train = False, transform = transforms.ToTensor()) . img, label = test_dataset[0] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;shape&#39;, img.shape) print(&#39;label&#39;,label) . shape torch.Size([1, 28, 28]) label 7 . def predict_image(img, model): xb = img.unsqueeze(0) yb = model(xb) _, preds = torch.max(yb, dim=1) return preds[0].item() . img.unsqueeze simply adds another dimension at the begining of the 1x28x28 tensor, making it a 1x1x28x28 tensor, which the model views as a batch containing a single image. . img, label = test_dataset[0] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;label:&#39;,label, &#39;, predicted:&#39;,predict_image(img, model)) . label: 7 , predicted: 7 . img, label = test_dataset[1] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;label:&#39;,label, &#39;, predicted:&#39;,predict_image(img, model)) . label: 2 , predicted: 2 . img, label = test_dataset[5] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;label:&#39;,label, &#39;, predicted:&#39;,predict_image(img, model)) . label: 1 , predicted: 1 . img, label = test_dataset[193] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;label:&#39;,label, &#39;, predicted:&#39;,predict_image(img, model)) . label: 9 , predicted: 9 . img, label = test_dataset[1839] plt.imshow(img[0], cmap=&#39;gray&#39;) print(&#39;label:&#39;,label, &#39;, predicted:&#39;,predict_image(img, model)) # Here Model in Breaking Up . label: 2 , predicted: 8 . test_loader = DataLoader(test_dataset, batch_size=256) result = evaluate(model, test_loader) result . {&#39;val_loss&#39;: 0.6401068568229675, &#39;val_acc&#39;: 0.8603515625} . Saving and Loading the Model . torch.save(model.state_dict(), &#39;mnist-logistic.pth&#39;) # .state_dict returns Ordered Dict containig all the weights and bias matrices mapped to right attributes of the model . model.state_dict() . OrderedDict([(&#39;linear.weight&#39;, tensor([[ 0.0064, -0.0261, 0.0092, ..., 0.0320, 0.0143, 0.0129], [-0.0179, 0.0100, 0.0158, ..., 0.0125, -0.0167, 0.0209], [ 0.0081, 0.0290, -0.0355, ..., 0.0334, -0.0284, -0.0074], ..., [-0.0097, -0.0077, 0.0133, ..., 0.0153, -0.0036, 0.0283], [ 0.0289, -0.0290, -0.0317, ..., -0.0190, 0.0308, -0.0353], [-0.0043, 0.0184, -0.0096, ..., 0.0319, -0.0038, -0.0067]])), (&#39;linear.bias&#39;, tensor([-0.0544, 0.1269, 0.0047, -0.0240, 0.0016, 0.0284, -0.0175, 0.0452, -0.0609, -0.0155]))]) . model_2 = MnistModel() model_2.load_state_dict(torch.load(&#39;mnist-logistic.pth&#39;)) model_2.state_dict() . OrderedDict([(&#39;linear.weight&#39;, tensor([[ 0.0064, -0.0261, 0.0092, ..., 0.0320, 0.0143, 0.0129], [-0.0179, 0.0100, 0.0158, ..., 0.0125, -0.0167, 0.0209], [ 0.0081, 0.0290, -0.0355, ..., 0.0334, -0.0284, -0.0074], ..., [-0.0097, -0.0077, 0.0133, ..., 0.0153, -0.0036, 0.0283], [ 0.0289, -0.0290, -0.0317, ..., -0.0190, 0.0308, -0.0353], [-0.0043, 0.0184, -0.0096, ..., 0.0319, -0.0038, -0.0067]])), (&#39;linear.bias&#39;, tensor([-0.0544, 0.1269, 0.0047, -0.0240, 0.0016, 0.0284, -0.0175, 0.0452, -0.0609, -0.0155]))]) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/06/01/Logistic-MNIST-Pytorch.html",
            "relUrl": "/2021/06/01/Logistic-MNIST-Pytorch.html",
            "date": " • Jun 1, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "Introduction to Pytorch",
            "content": "import torch . Tensors . Tenson is a number, vector, matrix, or any N- Dimensional array. . t1 = torch.tensor(4.) t1 . tensor(4.) . t1.dtype . torch.float32 . t2 = torch.tensor([1., 2, 3, 4]) print(t2) # ALl the tensor elements are of same data type # Matrix - 2D tensor t3 = torch.tensor([[5, 6], [7,8], [9,10]]) print(t3) . tensor([1., 2., 3., 4.]) tensor([[ 5, 6], [ 7, 8], [ 9, 10]]) . # most of the time we will use floating point numbers t4 = torch.tensor([ [[11,12,13], [13,14,15]], [[15,16,17], [17,18,19.]] ]) t4 . tensor([[[11., 12., 13.], [13., 14., 15.]], [[15., 16., 17.], [17., 18., 19.]]]) . Tensors can have any number of dimensions and different lengths along each dimension. we can inspect length using .shape property . print(t1) t1.shape . tensor(4.) . torch.Size([]) . print(t2) t2.shape . tensor([1., 2., 3., 4.]) . torch.Size([4]) . print(t3) t3.shape . tensor([[ 5, 6], [ 7, 8], [ 9, 10]]) . torch.Size([3, 2]) . print(t4) t4.shape # start from outer most bracket and count number of elements in that ie. here 2 elements both matrices than we go 1 bracket in and there is also 2 list elements and so on ..... . tensor([[[11., 12., 13.], [13., 14., 15.]], [[15., 16., 17.], [17., 18., 19.]]]) . torch.Size([2, 2, 3]) . we can not make a tensor with an improper shape . Tensor Operations and Gradients . x = torch.tensor(3.) w = torch.tensor(4., requires_grad=True) # b = torch.tensor(5., requires_grad=True) x,w,b . (tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True)) . y = w * x + b y . tensor(17., grad_fn=&lt;AddBackward0&gt;) . y.backward() # derivatives of y w.r.t each of input tensors are stored in .grad property of respective tensors . print(&#39;dy/dx&#39;, x.grad) print(&#39;dy/dw&#39;, w.grad) print(&#39;dy/db&#39;, b.grad) . dy/dx None dy/dw tensor(3.) dy/db tensor(1.) . we have not specified requires_grad=True in x, this tells pytorch that we are not intrested in drivatives of any future output w.r.t x but we are intrested for w and b .... so requires_grad property is important to save millions of usless coputations of derrivatives as per requirement . &quot;grad&quot; in w.grad is short for gradient, which is another term for derivative primarily used while dealing with vectors and matrices . Tensor Functions . t6 = torch.full((3,2), 42) t6 . tensor([[42, 42], [42, 42], [42, 42]]) . t7 = torch.cat((t3,t6)) t7 . tensor([[ 5, 6], [ 7, 8], [ 9, 10], [42, 42], [42, 42], [42, 42]]) . t8 = torch.sin(t7) t8 . tensor([[-0.9589, -0.2794], [ 0.6570, 0.9894], [ 0.4121, -0.5440], [-0.9165, -0.9165], [-0.9165, -0.9165], [-0.9165, -0.9165]]) . t9 = t8.reshape(3,2,2) t9 . tensor([[[-0.9589, -0.2794], [ 0.6570, 0.9894]], [[ 0.4121, -0.5440], [-0.9165, -0.9165]], [[-0.9165, -0.9165], [-0.9165, -0.9165]]]) . Inter-operability with Numpy . import numpy as np . x = np.array([[1,2],[3, 4.]]) x . array([[1., 2.], [3., 4.]]) . y = torch.from_numpy(x) y . tensor([[1., 2.], [3., 4.]], dtype=torch.float64) . x.dtype, y.dtype . (dtype(&#39;float64&#39;), torch.float64) . z = y.numpy() z . array([[1., 2.], [3., 4.]]) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/05/29/PyTorch-Basics.html",
            "relUrl": "/2021/05/29/PyTorch-Basics.html",
            "date": " • May 29, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "Implementation of Linear Regression and Gradient Descent using Pytorch",
            "content": "Linear regression. model that predicts crop yields for apples and oranges (target variables) by looking at the average temperature, rainfall, and humidity (input variables or features) in a region. Here&#39;s the training data: . . In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias : . yield_apple = w11 * temp + w12 * rainfall + w13 * humidity + b1 yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2 . Visually, it means that the yield of apples is a linear or planar function of temperature, rainfall and humidity: . . import torch import numpy as np . Training Data . inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype=&#39;float32&#39;) . targets = np.array([[56,70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype=&#39;float32&#39;) . inputs = torch.from_numpy(inputs) targets = torch.from_numpy(targets) print(inputs) print(targets) . tensor([[ 73., 67., 43.], [ 91., 88., 64.], [ 87., 134., 58.], [102., 43., 37.], [ 69., 96., 70.]]) tensor([[ 56., 70.], [ 81., 101.], [119., 133.], [ 22., 37.], [103., 119.]]) . Linear Regression Model from Scratch . w = torch.randn(2, 3, requires_grad=True) # torch.randn : creates a tensor with givent shape with random elements picked with normal distribution b = torch.randn(2, requires_grad= True) print(w) print(b) . tensor([[ 0.0728, -2.0486, 0.2053], [ 1.4556, -1.4721, -1.4280]], requires_grad=True) tensor([-2.6483, -2.7893], requires_grad=True) . Our model is just X * W_transpose + Bias . def model(x): return x @ w.t() + b # @-&gt; matrix multiplication in pytorch, .t() returns the transpose of a tensor . inputs @ w.t() + b . tensor([[-125.7638, -56.5679], [-163.1629, -91.2699], [-258.9209, -156.2401], [ -75.7193, 29.5415], [-179.9207, -143.6369]], grad_fn=&lt;AddBackward0&gt;) . preds = model(inputs) preds . tensor([[-125.7638, -56.5679], [-163.1629, -91.2699], [-258.9209, -156.2401], [ -75.7193, 29.5415], [-179.9207, -143.6369]], grad_fn=&lt;AddBackward0&gt;) . print(targets) . tensor([[ 56., 70.], [ 81., 101.], [119., 133.], [ 22., 37.], [103., 119.]]) . diff = preds - targets # diff * diff # * means element wise multiplication not matrix multiplication torch.sum(diff*diff) / diff.numel() # numel -&gt; number of element in diff matrix . tensor(53075.1758, grad_fn=&lt;DivBackward0&gt;) . Loss function . MSE Loss :- On average, each element in prediction differs from the actual target by the square root of the loss . def mse(t1,t2): diff = t1 - t2 return torch.sum(diff * diff) / diff.numel() . loss = mse(preds, targets) print(loss) . tensor(53075.1758, grad_fn=&lt;DivBackward0&gt;) . loss.backward() . print(w) print(w.grad) # derivative of the loss w.r.t element in w . tensor([[ 0.0728, -2.0486, 0.2053], [ 1.4556, -1.4721, -1.4280]], requires_grad=True) tensor([[-19571.1211, -23133.6465, -13756.3496], [-14156.5244, -17938.3672, -10636.8340]]) . print(b) print(b.grad) . tensor([-2.6483, -2.7893], requires_grad=True) tensor([-236.8975, -175.6347]) . Grad of loss w.r.t each element in tensor indicates the rate of change of loss or slope of the loss function . we can substract from each weight element a small quantity proportional to the derivative of the loss w.r.t that element to reduce the loss slightly . print(w) w.grad . tensor([[ 0.0728, -2.0486, 0.2053], [ 1.4556, -1.4721, -1.4280]], requires_grad=True) . tensor([[-19571.1211, -23133.6465, -13756.3496], [-14156.5244, -17938.3672, -10636.8340]]) . print(w) w.grad * 1e-5 # new weights to near w . tensor([[ 0.0728, -2.0486, 0.2053], [ 1.4556, -1.4721, -1.4280]], requires_grad=True) . tensor([[-0.1957, -0.2313, -0.1376], [-0.1416, -0.1794, -0.1064]]) . with torch.no_grad(): w -= w.grad * 1e-5 # 1e-5 is the step ie small coz loss is large.....Learning Rate b -= b.grad * 1e-5 . torch.no_grad() to indicate to Pytorch that we shouldn&#39;t take track, calculate, or modify gradients while updating the weights and biases . w, b . (tensor([[ 0.2685, -1.8173, 0.3429], [ 1.5971, -1.2927, -1.3216]], requires_grad=True), tensor([-2.6459, -2.7876], requires_grad=True)) . preds = model(inputs) loss = mse(preds, targets) print(loss) . tensor(37202.4609, grad_fn=&lt;DivBackward0&gt;) . Now reset the gradients to 0 . w.grad.zero_() b.grad.zero_() print(w.grad) print(b.grad) . tensor([[0., 0., 0.], [0., 0., 0.]]) tensor([0., 0.]) . Train the Model using Gradient descent . preds = model(inputs) print(preds) . tensor([[ -90.0597, -29.6393], [-116.1892, -55.7924], [-202.9139, -113.7154], [ -40.7170, 55.6320], [-134.5765, -109.2006]], grad_fn=&lt;AddBackward0&gt;) . loss = mse(preds, targets) print(loss) . tensor(37202.4609, grad_fn=&lt;DivBackward0&gt;) . loss.backward() print(w.grad) print(b.grad) . tensor([[-15880.6006, -19155.8594, -11304.5137], [-11370.2803, -14927.9023, -8782.6719]]) tensor([-193.0913, -142.5432]) . update the weights and biases using gradientdescent . with torch.no_grad(): w -= w.grad * 1e-5 b -= b.grad * 1e-5 w.grad.zero_() b.grad.zero_() . print(w) print(b) . tensor([[ 0.4273, -1.6257, 0.4559], [ 1.7108, -1.1434, -1.2338]], requires_grad=True) tensor([-2.6440, -2.7862], requires_grad=True) . preds = model(inputs) loss = mse(preds, targets) print(loss) . tensor(26488.4434, grad_fn=&lt;DivBackward0&gt;) . Train on multiple Epochs . for i in range(100): preds = model(inputs) loss = mse(preds, targets) loss.backward() with torch.no_grad(): w -= w.grad * 1e-5 b -= b.grad * 1e-5 w.grad.zero_() b.grad.zero_() . preds = model(inputs) loss = mse(preds, targets) print(loss) . tensor(1333.2324, grad_fn=&lt;DivBackward0&gt;) . print(preds) print(targets) . tensor([[ 65.7250, 83.3404], [ 92.7282, 99.8337], [ 80.9948, 113.9022], [ 73.8770, 114.4924], [ 88.8938, 71.9206]], grad_fn=&lt;AddBackward0&gt;) tensor([[ 56., 70.], [ 81., 101.], [119., 133.], [ 22., 37.], [103., 119.]]) . Linear Regression using Pytorch built-ins . import torch.nn as nn . inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [74, 66, 43], [91, 87, 65], [88, 134, 59], [101, 44, 37], [68, 96, 71], [73, 66, 44], [92, 87, 64], [87, 135, 57], [103, 43 ,36], [68, 97, 70]], dtype=&#39;float32&#39;) targets = np.array([[56,70], [81, 101], [119, 133], [22, 37], [103, 119], [57,69], [80,102], [118, 132], [21, 38], [104, 118], [57, 69], [82, 100], [118, 134], [20, 38], [102, 120]], dtype=&#39;float32&#39;) inputs = torch.from_numpy(inputs) targets = torch.from_numpy(targets) . print(inputs) print(targets) . tensor([[ 73., 67., 43.], [ 91., 88., 64.], [ 87., 134., 58.], [102., 43., 37.], [ 69., 96., 70.], [ 74., 66., 43.], [ 91., 87., 65.], [ 88., 134., 59.], [101., 44., 37.], [ 68., 96., 71.], [ 73., 66., 44.], [ 92., 87., 64.], [ 87., 135., 57.], [103., 43., 36.], [ 68., 97., 70.]]) tensor([[ 56., 70.], [ 81., 101.], [119., 133.], [ 22., 37.], [103., 119.], [ 57., 69.], [ 80., 102.], [118., 132.], [ 21., 38.], [104., 118.], [ 57., 69.], [ 82., 100.], [118., 134.], [ 20., 38.], [102., 120.]]) . Dataset and DataLoader . creating a TensorDataset, which allows access to rows from inputs and targets as tuples and provide standard APIs for working many different types pf datasets in Pytorch . from torch.utils.data import TensorDataset . train_ds = TensorDataset(inputs, targets) train_ds[0:3] # 0 to 3-1 . (tensor([[ 73., 67., 43.], [ 91., 88., 64.], [ 87., 134., 58.]]), tensor([[ 56., 70.], [ 81., 101.], [119., 133.]])) . from torch.utils.data import DataLoader . batch_size = 5 train_dl = DataLoader(train_ds, batch_size, shuffle=True) . inputs . tensor([[ 73., 67., 43.], [ 91., 88., 64.], [ 87., 134., 58.], [102., 43., 37.], [ 69., 96., 70.], [ 74., 66., 43.], [ 91., 87., 65.], [ 88., 134., 59.], [101., 44., 37.], [ 68., 96., 71.], [ 73., 66., 44.], [ 92., 87., 64.], [ 87., 135., 57.], [103., 43., 36.], [ 68., 97., 70.]]) . for xb, yb in train_dl: print(xb) print(yb) break . tensor([[102., 43., 37.], [ 91., 87., 65.], [ 69., 96., 70.], [ 88., 134., 59.], [ 74., 66., 43.]]) tensor([[ 22., 37.], [ 80., 102.], [103., 119.], [118., 132.], [ 57., 69.]]) . nn.Linear . Instead of initialising the weights and biases manually, we can define the model using the nn.Linear . model = nn.Linear(3, 2) print(model.weight) print(model.bias) . Parameter containing: tensor([[-0.1637, 0.0519, -0.1459], [-0.2050, 0.2159, -0.0023]], requires_grad=True) Parameter containing: tensor([-0.1157, -0.1562], requires_grad=True) . list(model.parameters()) . [Parameter containing: tensor([[-0.1637, 0.0519, -0.1459], [-0.2050, 0.2159, -0.0023]], requires_grad=True), Parameter containing: tensor([-0.1157, -0.1562], requires_grad=True)] . preds = model(inputs) . preds . tensor([[-14.8669, -0.7540], [-19.7889, 0.0420], [-15.8733, 10.8090], [-19.9838, -11.8685], [-16.6477, 6.2663], [-15.0825, -1.1750], [-19.9867, -0.1762], [-16.1830, 10.6017], [-19.7683, -11.4475], [-16.6298, 6.4690], [-15.0646, -0.9722], [-20.0045, -0.3789], [-15.6756, 11.0272], [-20.0016, -12.0712], [-16.4321, 6.6873]], grad_fn=&lt;AddmmBackward&gt;) . Loss Function . import torch.nn.functional as F . loss_fn = F.mse_loss . loss = loss_fn(model(inputs), targets) print(loss) . tensor(9453.6309, grad_fn=&lt;MseLossBackward&gt;) . Optimizer . we will use stochastic gradient descent -&gt; optim.SGD . opt = torch.optim.SGD(model.parameters(), lr=1e-5) #lr is the learning rate . Train the Model . def fit(num_epochs, model, loss_fn, opt, train_dl): for epoch in range(num_epochs): for xb, xy in train_dl: pred = model(xb) # Generate Predictions loss = loss_fn(pred, yb) # calculate loss loss.backward() # compute gradient opt.step() # update parameters using gradient opt.zero_grad() # reset the gradient to zero if (epoch+1) % 10 == 0: print(&#39;Epoch [{}/{}], Loss: {:.4f}&#39;.format(epoch+1, num_epochs, loss.item())) . fit(100, model, loss_fn, opt, train_dl) . Epoch [10/100], Loss: 1473.9495 Epoch [20/100], Loss: 1101.0323 Epoch [30/100], Loss: 1247.5220 Epoch [40/100], Loss: 1066.2527 Epoch [50/100], Loss: 1192.7886 Epoch [60/100], Loss: 1239.0150 Epoch [70/100], Loss: 916.5994 Epoch [80/100], Loss: 986.2520 Epoch [90/100], Loss: 1190.9945 Epoch [100/100], Loss: 1572.8744 . preds = model(inputs) . preds . tensor([[ 62.2054, 75.3431], [ 81.8397, 99.3478], [ 75.8782, 91.9953], [ 78.3076, 94.4091], [ 70.4413, 85.9155], [ 62.8510, 76.1146], [ 82.2799, 99.9035], [ 76.9230, 93.2708], [ 77.6620, 93.6375], [ 70.2358, 85.6997], [ 62.6455, 75.8988], [ 82.4854, 100.1193], [ 75.4381, 91.4396], [ 78.5131, 94.6249], [ 69.7957, 85.1440]], grad_fn=&lt;AddmmBackward&gt;) . targets . tensor([[ 56., 70.], [ 81., 101.], [119., 133.], [ 22., 37.], [103., 119.], [ 57., 69.], [ 80., 102.], [118., 132.], [ 21., 38.], [104., 118.], [ 57., 69.], [ 82., 100.], [118., 134.], [ 20., 38.], [102., 120.]]) . Random input Batch . model(torch.tensor([[75, 63, 44.]])) # we&#39;ll get a batch of output . tensor([[63.9573, 77.4678]], grad_fn=&lt;AddmmBackward&gt;) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/05/28/Torch-LR-GD.html",
            "relUrl": "/2021/05/28/Torch-LR-GD.html",
            "date": " • May 28, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "Gradient Boosting Machines (GBMs) with XGBoost",
            "content": "Problem Statement . This tutorial takes a practical and coding-focused approach. We&#39;ll learn gradient boosting by applying it to a real-world dataset from the Rossmann Store Sales competition on Kaggle: . Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality. . With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the &quot;Sales&quot; column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment. . View and download the data here: https://www.kaggle.com/c/rossmann-store-sales/data . Download Data . import os import opendatasets as od import pandas as pd pd.set_option(&quot;display.max_columns&quot;, 120) pd.set_option(&quot;display.max_rows&quot;, 120) . od.download(&#39;https://www.kaggle.com/c/rossmann-store-sales&#39;) . Skipping, found downloaded files in &#34;./rossmann-store-sales&#34; (use force=True to force download) . data_dir = os.listdir(&#39;rossmann-store-sales/&#39;) . data_dir . [&#39;sample_submission.csv&#39;, &#39;store.csv&#39;, &#39;test.csv&#39;, &#39;train.csv&#39;] . ross_df = pd.read_csv(&#39;./rossmann-store-sales/train.csv&#39;, low_memory=False) test_df = pd.read_csv(&#39;./rossmann-store-sales/test.csv&#39;) store_df = pd.read_csv(&#39;./rossmann-store-sales/store.csv&#39;) submission_df = pd.read_csv(&#39;./rossmann-store-sales/sample_submission.csv&#39;) . ross_df . Store DayOfWeek Date Sales Customers Open Promo StateHoliday SchoolHoliday . 0 1 | 5 | 2015-07-31 | 5263 | 555 | 1 | 1 | 0 | 1 | . 1 2 | 5 | 2015-07-31 | 6064 | 625 | 1 | 1 | 0 | 1 | . 2 3 | 5 | 2015-07-31 | 8314 | 821 | 1 | 1 | 0 | 1 | . 3 4 | 5 | 2015-07-31 | 13995 | 1498 | 1 | 1 | 0 | 1 | . 4 5 | 5 | 2015-07-31 | 4822 | 559 | 1 | 1 | 0 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1017204 1111 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | . 1017205 1112 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | . 1017206 1113 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | . 1017207 1114 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | . 1017208 1115 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | . 1017209 rows × 9 columns . test_df . Id Store DayOfWeek Date Open Promo StateHoliday SchoolHoliday . 0 1 | 1 | 4 | 2015-09-17 | 1.0 | 1 | 0 | 0 | . 1 2 | 3 | 4 | 2015-09-17 | 1.0 | 1 | 0 | 0 | . 2 3 | 7 | 4 | 2015-09-17 | 1.0 | 1 | 0 | 0 | . 3 4 | 8 | 4 | 2015-09-17 | 1.0 | 1 | 0 | 0 | . 4 5 | 9 | 4 | 2015-09-17 | 1.0 | 1 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 41083 41084 | 1111 | 6 | 2015-08-01 | 1.0 | 0 | 0 | 0 | . 41084 41085 | 1112 | 6 | 2015-08-01 | 1.0 | 0 | 0 | 0 | . 41085 41086 | 1113 | 6 | 2015-08-01 | 1.0 | 0 | 0 | 0 | . 41086 41087 | 1114 | 6 | 2015-08-01 | 1.0 | 0 | 0 | 0 | . 41087 41088 | 1115 | 6 | 2015-08-01 | 1.0 | 0 | 0 | 1 | . 41088 rows × 8 columns . store_df . Store StoreType Assortment CompetitionDistance CompetitionOpenSinceMonth CompetitionOpenSinceYear Promo2 Promo2SinceWeek Promo2SinceYear PromoInterval . 0 1 | c | a | 1270.0 | 9.0 | 2008.0 | 0 | NaN | NaN | NaN | . 1 2 | a | a | 570.0 | 11.0 | 2007.0 | 1 | 13.0 | 2010.0 | Jan,Apr,Jul,Oct | . 2 3 | a | a | 14130.0 | 12.0 | 2006.0 | 1 | 14.0 | 2011.0 | Jan,Apr,Jul,Oct | . 3 4 | c | c | 620.0 | 9.0 | 2009.0 | 0 | NaN | NaN | NaN | . 4 5 | a | a | 29910.0 | 4.0 | 2015.0 | 0 | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1110 1111 | a | a | 1900.0 | 6.0 | 2014.0 | 1 | 31.0 | 2013.0 | Jan,Apr,Jul,Oct | . 1111 1112 | c | c | 1880.0 | 4.0 | 2006.0 | 0 | NaN | NaN | NaN | . 1112 1113 | a | c | 9260.0 | NaN | NaN | 0 | NaN | NaN | NaN | . 1113 1114 | a | c | 870.0 | NaN | NaN | 0 | NaN | NaN | NaN | . 1114 1115 | d | c | 5350.0 | NaN | NaN | 1 | 22.0 | 2012.0 | Mar,Jun,Sept,Dec | . 1115 rows × 10 columns . merged_df = ross_df.merge(store_df, how=&#39;left&#39;, on=&#39;Store&#39;) merged_test_df = test_df.merge(store_df, how=&#39;left&#39;, on=&#39;Store&#39;) . merged_df . Store DayOfWeek Date Sales Customers Open Promo StateHoliday SchoolHoliday StoreType Assortment CompetitionDistance CompetitionOpenSinceMonth CompetitionOpenSinceYear Promo2 Promo2SinceWeek Promo2SinceYear PromoInterval . 0 1 | 5 | 2015-07-31 | 5263 | 555 | 1 | 1 | 0 | 1 | c | a | 1270.0 | 9.0 | 2008.0 | 0 | NaN | NaN | NaN | . 1 2 | 5 | 2015-07-31 | 6064 | 625 | 1 | 1 | 0 | 1 | a | a | 570.0 | 11.0 | 2007.0 | 1 | 13.0 | 2010.0 | Jan,Apr,Jul,Oct | . 2 3 | 5 | 2015-07-31 | 8314 | 821 | 1 | 1 | 0 | 1 | a | a | 14130.0 | 12.0 | 2006.0 | 1 | 14.0 | 2011.0 | Jan,Apr,Jul,Oct | . 3 4 | 5 | 2015-07-31 | 13995 | 1498 | 1 | 1 | 0 | 1 | c | c | 620.0 | 9.0 | 2009.0 | 0 | NaN | NaN | NaN | . 4 5 | 5 | 2015-07-31 | 4822 | 559 | 1 | 1 | 0 | 1 | a | a | 29910.0 | 4.0 | 2015.0 | 0 | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1017204 1111 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | a | a | 1900.0 | 6.0 | 2014.0 | 1 | 31.0 | 2013.0 | Jan,Apr,Jul,Oct | . 1017205 1112 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | c | c | 1880.0 | 4.0 | 2006.0 | 0 | NaN | NaN | NaN | . 1017206 1113 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | a | c | 9260.0 | NaN | NaN | 0 | NaN | NaN | NaN | . 1017207 1114 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | a | c | 870.0 | NaN | NaN | 0 | NaN | NaN | NaN | . 1017208 1115 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | d | c | 5350.0 | NaN | NaN | 1 | 22.0 | 2012.0 | Mar,Jun,Sept,Dec | . 1017209 rows × 18 columns . Exploratory Data Analysis . Preprocessing and Feature Engineering . merged_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 1017209 entries, 0 to 1017208 Data columns (total 18 columns): # Column Non-Null Count Dtype -- -- 0 Store 1017209 non-null int64 1 DayOfWeek 1017209 non-null int64 2 Date 1017209 non-null object 3 Sales 1017209 non-null int64 4 Customers 1017209 non-null int64 5 Open 1017209 non-null int64 6 Promo 1017209 non-null int64 7 StateHoliday 1017209 non-null object 8 SchoolHoliday 1017209 non-null int64 9 StoreType 1017209 non-null object 10 Assortment 1017209 non-null object 11 CompetitionDistance 1014567 non-null float64 12 CompetitionOpenSinceMonth 693861 non-null float64 13 CompetitionOpenSinceYear 693861 non-null float64 14 Promo2 1017209 non-null int64 15 Promo2SinceWeek 509178 non-null float64 16 Promo2SinceYear 509178 non-null float64 17 PromoInterval 509178 non-null object dtypes: float64(5), int64(8), object(5) memory usage: 147.5+ MB . Date . def split_date(df): df[&#39;Date&#39;] = pd.to_datetime(df[&#39;Date&#39;]) df[&#39;Year&#39;] = df.Date.dt.year df[&#39;Month&#39;] = df.Date.dt.month df[&#39;Day&#39;] = df.Date.dt.day df[&#39;WeekofYear&#39;] = df.Date.dt.isocalendar().week . split_date(merged_df) split_date(merged_test_df) . merged_df . Store DayOfWeek Date Sales Customers Open Promo StateHoliday SchoolHoliday StoreType Assortment CompetitionDistance CompetitionOpenSinceMonth CompetitionOpenSinceYear Promo2 Promo2SinceWeek Promo2SinceYear PromoInterval Year Month Day WeekofYear . 0 1 | 5 | 2015-07-31 | 5263 | 555 | 1 | 1 | 0 | 1 | c | a | 1270.0 | 9.0 | 2008.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | . 1 2 | 5 | 2015-07-31 | 6064 | 625 | 1 | 1 | 0 | 1 | a | a | 570.0 | 11.0 | 2007.0 | 1 | 13.0 | 2010.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | . 2 3 | 5 | 2015-07-31 | 8314 | 821 | 1 | 1 | 0 | 1 | a | a | 14130.0 | 12.0 | 2006.0 | 1 | 14.0 | 2011.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | . 3 4 | 5 | 2015-07-31 | 13995 | 1498 | 1 | 1 | 0 | 1 | c | c | 620.0 | 9.0 | 2009.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | . 4 5 | 5 | 2015-07-31 | 4822 | 559 | 1 | 1 | 0 | 1 | a | a | 29910.0 | 4.0 | 2015.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1017204 1111 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | a | a | 1900.0 | 6.0 | 2014.0 | 1 | 31.0 | 2013.0 | Jan,Apr,Jul,Oct | 2013 | 1 | 1 | 1 | . 1017205 1112 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | c | c | 1880.0 | 4.0 | 2006.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | . 1017206 1113 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | a | c | 9260.0 | NaN | NaN | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | . 1017207 1114 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | a | c | 870.0 | NaN | NaN | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | . 1017208 1115 | 2 | 2013-01-01 | 0 | 0 | 0 | 0 | a | 1 | d | c | 5350.0 | NaN | NaN | 1 | 22.0 | 2012.0 | Mar,Jun,Sept,Dec | 2013 | 1 | 1 | 1 | . 1017209 rows × 22 columns . Store Open/Closed . merged_df[merged_df.Open ==0].Sales.value_counts() . 0 172817 Name: Sales, dtype: int64 . Instead of trying to model this relationship, it would be better to hard-code it in our predictions, and remove the rows where the store is closed. We won&#39;t remove any rows from the test set, since we need to make predictions for every row. . merged_df = merged_df[merged_df.Open == 1].copy() . Competition . merged_df.sample(10) . Store DayOfWeek Date Sales Customers Open Promo StateHoliday SchoolHoliday StoreType Assortment CompetitionDistance CompetitionOpenSinceMonth CompetitionOpenSinceYear Promo2 Promo2SinceWeek Promo2SinceYear PromoInterval Year Month Day WeekofYear . 81229 950 | 3 | 2015-05-20 | 6709 | 619 | 1 | 1 | 0 | 0 | a | a | 8460.0 | 11.0 | 1994.0 | 0 | NaN | NaN | NaN | 2015 | 5 | 20 | 21 | . 3394 50 | 2 | 2015-07-28 | 5115 | 390 | 1 | 1 | 0 | 1 | d | a | 6260.0 | 11.0 | 2009.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 28 | 31 | . 157691 477 | 4 | 2015-03-12 | 5154 | 394 | 1 | 0 | 0 | 0 | d | a | 770.0 | 7.0 | 2010.0 | 1 | 35.0 | 2010.0 | Jan,Apr,Jul,Oct | 2015 | 3 | 12 | 11 | . 1013035 286 | 5 | 2013-01-04 | 4505 | 442 | 1 | 0 | 0 | 1 | a | a | 1460.0 | 4.0 | 2015.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 4 | 1 | . 366973 757 | 4 | 2014-08-14 | 4553 | 465 | 1 | 0 | 0 | 1 | a | c | 3450.0 | NaN | NaN | 0 | NaN | NaN | NaN | 2014 | 8 | 14 | 33 | . 40863 724 | 4 | 2015-06-25 | 5821 | 635 | 1 | 0 | 0 | 0 | d | c | 5900.0 | NaN | NaN | 0 | NaN | NaN | NaN | 2015 | 6 | 25 | 26 | . 416853 629 | 1 | 2014-06-23 | 7655 | 637 | 1 | 0 | 0 | 0 | d | a | 510.0 | 7.0 | 2014.0 | 1 | 23.0 | 2015.0 | Mar,Jun,Sept,Dec | 2014 | 6 | 23 | 26 | . 213001 37 | 3 | 2015-01-21 | 4175 | 535 | 1 | 0 | 0 | 0 | c | a | 4230.0 | 12.0 | 2014.0 | 0 | NaN | NaN | NaN | 2015 | 1 | 21 | 4 | . 228007 548 | 4 | 2015-01-08 | 4576 | 359 | 1 | 1 | 0 | 1 | d | c | 3760.0 | 2.0 | 2009.0 | 0 | NaN | NaN | NaN | 2015 | 1 | 8 | 2 | . 59667 573 | 1 | 2015-06-08 | 3584 | 310 | 1 | 0 | 0 | 0 | a | a | 1190.0 | 11.0 | 2012.0 | 1 | 36.0 | 2013.0 | Jan,Apr,Jul,Oct | 2015 | 6 | 8 | 24 | . we can use the columns CompetitionOpenSince[Month/Year] columns from store_df to compute the number of months for which a competitor has been open near the store. . def comp_months(df): df[&#39;CompetitionOpen&#39;] = 12 * (df.Year - df.CompetitionOpenSinceYear) + (df.Month - df.CompetitionOpenSinceMonth) df[&#39;CompetitionOpen&#39;] = df[&#39;CompetitionOpen&#39;].map(lambda x: 0 if x &lt; 0 else x).fillna(0) . comp_months(merged_df) comp_months(merged_test_df) . merged_df.head(10) . Store DayOfWeek Date Sales Customers Open Promo StateHoliday SchoolHoliday StoreType Assortment CompetitionDistance CompetitionOpenSinceMonth CompetitionOpenSinceYear Promo2 Promo2SinceWeek Promo2SinceYear PromoInterval Year Month Day WeekofYear CompetitionOpen . 0 1 | 5 | 2015-07-31 | 5263 | 555 | 1 | 1 | 0 | 1 | c | a | 1270.0 | 9.0 | 2008.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 82.0 | . 1 2 | 5 | 2015-07-31 | 6064 | 625 | 1 | 1 | 0 | 1 | a | a | 570.0 | 11.0 | 2007.0 | 1 | 13.0 | 2010.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | 92.0 | . 2 3 | 5 | 2015-07-31 | 8314 | 821 | 1 | 1 | 0 | 1 | a | a | 14130.0 | 12.0 | 2006.0 | 1 | 14.0 | 2011.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | 103.0 | . 3 4 | 5 | 2015-07-31 | 13995 | 1498 | 1 | 1 | 0 | 1 | c | c | 620.0 | 9.0 | 2009.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 70.0 | . 4 5 | 5 | 2015-07-31 | 4822 | 559 | 1 | 1 | 0 | 1 | a | a | 29910.0 | 4.0 | 2015.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 3.0 | . 5 6 | 5 | 2015-07-31 | 5651 | 589 | 1 | 1 | 0 | 1 | a | a | 310.0 | 12.0 | 2013.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 19.0 | . 6 7 | 5 | 2015-07-31 | 15344 | 1414 | 1 | 1 | 0 | 1 | a | c | 24000.0 | 4.0 | 2013.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 27.0 | . 7 8 | 5 | 2015-07-31 | 8492 | 833 | 1 | 1 | 0 | 1 | a | a | 7520.0 | 10.0 | 2014.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 9.0 | . 8 9 | 5 | 2015-07-31 | 8565 | 687 | 1 | 1 | 0 | 1 | a | c | 2030.0 | 8.0 | 2000.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 179.0 | . 9 10 | 5 | 2015-07-31 | 7185 | 681 | 1 | 1 | 0 | 1 | a | a | 3160.0 | 9.0 | 2009.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 70.0 | . merged_df[[&#39;Date&#39;, &#39;CompetitionDistance&#39;, &#39;CompetitionOpenSinceYear&#39;, &#39;CompetitionOpenSinceMonth&#39;, &#39;CompetitionOpen&#39;]] . Date CompetitionDistance CompetitionOpenSinceYear CompetitionOpenSinceMonth CompetitionOpen . 0 2015-07-31 | 1270.0 | 2008.0 | 9.0 | 82.0 | . 1 2015-07-31 | 570.0 | 2007.0 | 11.0 | 92.0 | . 2 2015-07-31 | 14130.0 | 2006.0 | 12.0 | 103.0 | . 3 2015-07-31 | 620.0 | 2009.0 | 9.0 | 70.0 | . 4 2015-07-31 | 29910.0 | 2015.0 | 4.0 | 3.0 | . ... ... | ... | ... | ... | ... | . 1016776 2013-01-01 | 150.0 | 2006.0 | 9.0 | 76.0 | . 1016827 2013-01-01 | 860.0 | 1999.0 | 10.0 | 159.0 | . 1016863 2013-01-01 | 840.0 | NaN | NaN | 0.0 | . 1017042 2013-01-01 | 1430.0 | NaN | NaN | 0.0 | . 1017190 2013-01-01 | 720.0 | 2002.0 | 3.0 | 130.0 | . 844392 rows × 5 columns . Additional Promotion . merged_df . Store DayOfWeek Date Sales Customers Open Promo StateHoliday SchoolHoliday StoreType Assortment CompetitionDistance CompetitionOpenSinceMonth CompetitionOpenSinceYear Promo2 Promo2SinceWeek Promo2SinceYear PromoInterval Year Month Day WeekofYear CompetitionOpen . 0 1 | 5 | 2015-07-31 | 5263 | 555 | 1 | 1 | 0 | 1 | c | a | 1270.0 | 9.0 | 2008.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 82.0 | . 1 2 | 5 | 2015-07-31 | 6064 | 625 | 1 | 1 | 0 | 1 | a | a | 570.0 | 11.0 | 2007.0 | 1 | 13.0 | 2010.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | 92.0 | . 2 3 | 5 | 2015-07-31 | 8314 | 821 | 1 | 1 | 0 | 1 | a | a | 14130.0 | 12.0 | 2006.0 | 1 | 14.0 | 2011.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | 103.0 | . 3 4 | 5 | 2015-07-31 | 13995 | 1498 | 1 | 1 | 0 | 1 | c | c | 620.0 | 9.0 | 2009.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 70.0 | . 4 5 | 5 | 2015-07-31 | 4822 | 559 | 1 | 1 | 0 | 1 | a | a | 29910.0 | 4.0 | 2015.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 3.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1016776 682 | 2 | 2013-01-01 | 3375 | 566 | 1 | 0 | a | 1 | b | a | 150.0 | 9.0 | 2006.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 76.0 | . 1016827 733 | 2 | 2013-01-01 | 10765 | 2377 | 1 | 0 | a | 1 | b | b | 860.0 | 10.0 | 1999.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 159.0 | . 1016863 769 | 2 | 2013-01-01 | 5035 | 1248 | 1 | 0 | a | 1 | b | b | 840.0 | NaN | NaN | 1 | 48.0 | 2012.0 | Jan,Apr,Jul,Oct | 2013 | 1 | 1 | 1 | 0.0 | . 1017042 948 | 2 | 2013-01-01 | 4491 | 1039 | 1 | 0 | a | 1 | b | b | 1430.0 | NaN | NaN | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 0.0 | . 1017190 1097 | 2 | 2013-01-01 | 5961 | 1405 | 1 | 0 | a | 1 | b | b | 720.0 | 3.0 | 2002.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 130.0 | . 844392 rows × 23 columns . add some additional columns to indicate how long a store has been running Promo2 and whether a new round of Promo2 starts in the current month. . def check_promo_month(row): month2str = {1:&#39;Jan&#39;, 2:&#39;Feb&#39;, 3:&#39;Mar&#39;, 4:&#39;Apr&#39;, 5:&#39;May&#39;, 6:&#39;Jun&#39;, 7:&#39;Jul&#39;, 8:&#39;Aug&#39;, 9:&#39;Sept&#39;, 10:&#39;Oct&#39;, 11:&#39;Nov&#39;, 12:&#39;Dec&#39;} try: months = (row[&#39;PromoInterval&#39;] or &#39;&#39;).split(&#39;,&#39;) if row[&#39;Promo2Open&#39;] and month2str[row[&#39;Month&#39;]] in months: return -1 else: return 0 except Exception: return 0 def promo_cols(df): # month since Promo2 was open df[&#39;Promo2Open&#39;] = 12 * (df.Year-df.Promo2SinceYear) + (df.WeekofYear - df.Promo2SinceWeek) * 7/30.5 df[&#39;Promo2Open&#39;] = df[&#39;Promo2Open&#39;] .map(lambda x: 0 if x &lt; 0 else x).fillna(0) * df[&#39;Promo2&#39;] #wether a new round of promotions was started in the current month df[&#39;IsPromo2Month&#39;] = df.apply(check_promo_month, axis=1) * df[&#39;Promo2&#39;] . promo_cols(merged_df) promo_cols(merged_test_df) merged_df . Store DayOfWeek Date Sales Customers Open Promo StateHoliday SchoolHoliday StoreType Assortment CompetitionDistance CompetitionOpenSinceMonth CompetitionOpenSinceYear Promo2 Promo2SinceWeek Promo2SinceYear PromoInterval Year Month Day WeekofYear CompetitionOpen Promo2Open IsPromo2Month . 0 1 | 5 | 2015-07-31 | 5263 | 555 | 1 | 1 | 0 | 1 | c | a | 1270.0 | 9.0 | 2008.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 82.0 | 0.000000 | 0 | . 1 2 | 5 | 2015-07-31 | 6064 | 625 | 1 | 1 | 0 | 1 | a | a | 570.0 | 11.0 | 2007.0 | 1 | 13.0 | 2010.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | 92.0 | 64.131148 | -1 | . 2 3 | 5 | 2015-07-31 | 8314 | 821 | 1 | 1 | 0 | 1 | a | a | 14130.0 | 12.0 | 2006.0 | 1 | 14.0 | 2011.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | 103.0 | 51.901639 | -1 | . 3 4 | 5 | 2015-07-31 | 13995 | 1498 | 1 | 1 | 0 | 1 | c | c | 620.0 | 9.0 | 2009.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 70.0 | 0.000000 | 0 | . 4 5 | 5 | 2015-07-31 | 4822 | 559 | 1 | 1 | 0 | 1 | a | a | 29910.0 | 4.0 | 2015.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 3.0 | 0.000000 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1016776 682 | 2 | 2013-01-01 | 3375 | 566 | 1 | 0 | a | 1 | b | a | 150.0 | 9.0 | 2006.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 76.0 | 0.000000 | 0 | . 1016827 733 | 2 | 2013-01-01 | 10765 | 2377 | 1 | 0 | a | 1 | b | b | 860.0 | 10.0 | 1999.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 159.0 | 0.000000 | 0 | . 1016863 769 | 2 | 2013-01-01 | 5035 | 1248 | 1 | 0 | a | 1 | b | b | 840.0 | NaN | NaN | 1 | 48.0 | 2012.0 | Jan,Apr,Jul,Oct | 2013 | 1 | 1 | 1 | 0.0 | 1.213115 | -1 | . 1017042 948 | 2 | 2013-01-01 | 4491 | 1039 | 1 | 0 | a | 1 | b | b | 1430.0 | NaN | NaN | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 0.0 | 0.000000 | 0 | . 1017190 1097 | 2 | 2013-01-01 | 5961 | 1405 | 1 | 0 | a | 1 | b | b | 720.0 | 3.0 | 2002.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 130.0 | 0.000000 | 0 | . 844392 rows × 25 columns . merged_df[[&#39;Date&#39;, &#39;Promo2&#39;, &#39;Promo2SinceYear&#39;, &#39;Promo2SinceWeek&#39;, &#39;PromoInterval&#39;, &#39;Promo2Open&#39;, &#39;IsPromo2Month&#39;]].sample(20) . Date Promo2 Promo2SinceYear Promo2SinceWeek PromoInterval Promo2Open IsPromo2Month . 778123 2013-08-03 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 485713 2014-04-22 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 212896 2015-01-22 | 1 | 2009.0 | 45.0 | Feb,May,Aug,Nov | 62.590164 | 0 | . 998575 2013-01-17 | 1 | 2014.0 | 10.0 | Mar,Jun,Sept,Dec | 0.000000 | 0 | . 408579 2014-06-30 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 891338 2013-04-23 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 884400 2013-04-30 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 892016 2013-04-23 | 1 | 2011.0 | 22.0 | Feb,May,Aug,Nov | 22.852459 | 0 | . 645306 2013-11-30 | 1 | 2009.0 | 37.0 | Jan,Apr,Jul,Oct | 50.524590 | 0 | . 429670 2014-06-11 | 1 | 2009.0 | 37.0 | Jan,Apr,Jul,Oct | 57.016393 | 0 | . 989989 2013-01-25 | 1 | 2013.0 | 5.0 | Feb,May,Aug,Nov | 0.000000 | 0 | . 110965 2015-04-23 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 723857 2013-09-21 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 445329 2014-05-28 | 1 | 2014.0 | 40.0 | Jan,Apr,Jul,Oct | 0.000000 | 0 | . 1298 2015-07-30 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 575426 2014-02-01 | 1 | 2015.0 | 23.0 | Mar,Jun,Sept,Dec | 0.000000 | 0 | . 232178 2015-01-04 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . 196856 2015-02-05 | 1 | 2011.0 | 9.0 | Jan,Apr,Jul,Oct | 47.311475 | 0 | . 926871 2013-03-23 | 1 | 2014.0 | 40.0 | Jan,Apr,Jul,Oct | 0.000000 | 0 | . 950895 2013-03-01 | 0 | NaN | NaN | NaN | 0.000000 | 0 | . merged_df . Store DayOfWeek Date Sales Customers Open Promo StateHoliday SchoolHoliday StoreType Assortment CompetitionDistance CompetitionOpenSinceMonth CompetitionOpenSinceYear Promo2 Promo2SinceWeek Promo2SinceYear PromoInterval Year Month Day WeekofYear CompetitionOpen Promo2Open IsPromo2Month . 0 1 | 5 | 2015-07-31 | 5263 | 555 | 1 | 1 | 0 | 1 | c | a | 1270.0 | 9.0 | 2008.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 82.0 | 0.000000 | 0 | . 1 2 | 5 | 2015-07-31 | 6064 | 625 | 1 | 1 | 0 | 1 | a | a | 570.0 | 11.0 | 2007.0 | 1 | 13.0 | 2010.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | 92.0 | 64.131148 | -1 | . 2 3 | 5 | 2015-07-31 | 8314 | 821 | 1 | 1 | 0 | 1 | a | a | 14130.0 | 12.0 | 2006.0 | 1 | 14.0 | 2011.0 | Jan,Apr,Jul,Oct | 2015 | 7 | 31 | 31 | 103.0 | 51.901639 | -1 | . 3 4 | 5 | 2015-07-31 | 13995 | 1498 | 1 | 1 | 0 | 1 | c | c | 620.0 | 9.0 | 2009.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 70.0 | 0.000000 | 0 | . 4 5 | 5 | 2015-07-31 | 4822 | 559 | 1 | 1 | 0 | 1 | a | a | 29910.0 | 4.0 | 2015.0 | 0 | NaN | NaN | NaN | 2015 | 7 | 31 | 31 | 3.0 | 0.000000 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1016776 682 | 2 | 2013-01-01 | 3375 | 566 | 1 | 0 | a | 1 | b | a | 150.0 | 9.0 | 2006.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 76.0 | 0.000000 | 0 | . 1016827 733 | 2 | 2013-01-01 | 10765 | 2377 | 1 | 0 | a | 1 | b | b | 860.0 | 10.0 | 1999.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 159.0 | 0.000000 | 0 | . 1016863 769 | 2 | 2013-01-01 | 5035 | 1248 | 1 | 0 | a | 1 | b | b | 840.0 | NaN | NaN | 1 | 48.0 | 2012.0 | Jan,Apr,Jul,Oct | 2013 | 1 | 1 | 1 | 0.0 | 1.213115 | -1 | . 1017042 948 | 2 | 2013-01-01 | 4491 | 1039 | 1 | 0 | a | 1 | b | b | 1430.0 | NaN | NaN | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 0.0 | 0.000000 | 0 | . 1017190 1097 | 2 | 2013-01-01 | 5961 | 1405 | 1 | 0 | a | 1 | b | b | 720.0 | 3.0 | 2002.0 | 0 | NaN | NaN | NaN | 2013 | 1 | 1 | 1 | 130.0 | 0.000000 | 0 | . 844392 rows × 25 columns . Input and Target Columns . merged_df.columns . Index([&#39;Store&#39;, &#39;DayOfWeek&#39;, &#39;Date&#39;, &#39;Sales&#39;, &#39;Customers&#39;, &#39;Open&#39;, &#39;Promo&#39;, &#39;StateHoliday&#39;, &#39;SchoolHoliday&#39;, &#39;StoreType&#39;, &#39;Assortment&#39;, &#39;CompetitionDistance&#39;, &#39;CompetitionOpenSinceMonth&#39;, &#39;CompetitionOpenSinceYear&#39;, &#39;Promo2&#39;, &#39;Promo2SinceWeek&#39;, &#39;Promo2SinceYear&#39;, &#39;PromoInterval&#39;, &#39;Year&#39;, &#39;Month&#39;, &#39;Day&#39;, &#39;WeekofYear&#39;, &#39;CompetitionOpen&#39;, &#39;Promo2Open&#39;, &#39;IsPromo2Month&#39;], dtype=&#39;object&#39;) . input_cols = [&#39;Store&#39;, &#39;DayOfWeek&#39;, &#39;Promo&#39;, &#39;StateHoliday&#39;, &#39;SchoolHoliday&#39;, &#39;StoreType&#39;, &#39;Assortment&#39;, &#39;CompetitionDistance&#39;, &#39;CompetitionOpen&#39;, &#39;Day&#39;, &#39;Month&#39;, &#39;Year&#39;, &#39;WeekofYear&#39;, &#39;Promo2&#39;, &#39;Promo2Open&#39;, &#39;IsPromo2Month&#39;] target_col = &#39;Sales&#39; . inputs = merged_df[input_cols].copy() targets = merged_df[target_col].copy() . test_inputs = merged_test_df[input_cols].copy() . inputs . Store DayOfWeek Promo StateHoliday SchoolHoliday StoreType Assortment CompetitionDistance CompetitionOpen Day Month Year WeekofYear Promo2 Promo2Open IsPromo2Month . 0 1 | 5 | 1 | 0 | 1 | c | a | 1270.0 | 82.0 | 31 | 7 | 2015 | 31 | 0 | 0.000000 | 0 | . 1 2 | 5 | 1 | 0 | 1 | a | a | 570.0 | 92.0 | 31 | 7 | 2015 | 31 | 1 | 64.131148 | -1 | . 2 3 | 5 | 1 | 0 | 1 | a | a | 14130.0 | 103.0 | 31 | 7 | 2015 | 31 | 1 | 51.901639 | -1 | . 3 4 | 5 | 1 | 0 | 1 | c | c | 620.0 | 70.0 | 31 | 7 | 2015 | 31 | 0 | 0.000000 | 0 | . 4 5 | 5 | 1 | 0 | 1 | a | a | 29910.0 | 3.0 | 31 | 7 | 2015 | 31 | 0 | 0.000000 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1016776 682 | 2 | 0 | a | 1 | b | a | 150.0 | 76.0 | 1 | 1 | 2013 | 1 | 0 | 0.000000 | 0 | . 1016827 733 | 2 | 0 | a | 1 | b | b | 860.0 | 159.0 | 1 | 1 | 2013 | 1 | 0 | 0.000000 | 0 | . 1016863 769 | 2 | 0 | a | 1 | b | b | 840.0 | 0.0 | 1 | 1 | 2013 | 1 | 1 | 1.213115 | -1 | . 1017042 948 | 2 | 0 | a | 1 | b | b | 1430.0 | 0.0 | 1 | 1 | 2013 | 1 | 0 | 0.000000 | 0 | . 1017190 1097 | 2 | 0 | a | 1 | b | b | 720.0 | 130.0 | 1 | 1 | 2013 | 1 | 0 | 0.000000 | 0 | . 844392 rows × 16 columns . numeric_cols = [&#39;Store&#39;, &#39;Promo&#39;, &#39;SchoolHoliday&#39;, &#39;CompetitionDistance&#39;, &#39;CompetitionOpen&#39;, &#39;Promo2&#39;, &#39;Promo2Open&#39;, &#39;IsPromo2Month&#39;, &#39;Day&#39;, &#39;Month&#39;, &#39;Year&#39;, &#39;WeekofYear&#39;] categorical_cols = [&#39;DayOfWeek&#39;, &#39;StateHoliday&#39;, &#39;StoreType&#39;, &#39;Assortment&#39;] . Impute missing Numrical Data . inputs[numeric_cols].isna().sum() . Store 0 Promo 0 SchoolHoliday 0 CompetitionDistance 2186 CompetitionOpen 0 Promo2 0 Promo2Open 0 IsPromo2Month 0 Day 0 Month 0 Year 0 WeekofYear 0 dtype: int64 . test_inputs[numeric_cols].isna().sum() . Store 0 Promo 0 SchoolHoliday 0 CompetitionDistance 96 CompetitionOpen 0 Promo2 0 Promo2Open 0 IsPromo2Month 0 Day 0 Month 0 Year 0 WeekofYear 0 dtype: int64 . Seems like competition distance is the only missing value, and we can simply fill it with the highest value (to indicate that competition is very far away). . max_distance = inputs.CompetitionDistance.max() max_distance . 75860.0 . inputs[&#39;CompetitionDistance&#39;].fillna(max_distance*2, inplace=True) test_inputs[&#39;CompetitionDistance&#39;].fillna(max_distance*2, inplace=True) . Scale Numeric Value . from sklearn.preprocessing import MinMaxScaler . scaler = MinMaxScaler().fit(inputs[numeric_cols]) . inputs[numeric_cols] = scaler.transform(inputs[numeric_cols]) test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols]) . inputs[numeric_cols].head(10) . Store Promo SchoolHoliday CompetitionDistance CompetitionOpen Promo2 Promo2Open IsPromo2Month Day Month Year WeekofYear . 0 0.000000 | 1.0 | 1.0 | 0.008240 | 0.059163 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 1 0.000898 | 1.0 | 1.0 | 0.003626 | 0.066378 | 1.0 | 0.890710 | 0.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 2 0.001795 | 1.0 | 1.0 | 0.093013 | 0.074315 | 1.0 | 0.720856 | 0.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 3 0.002693 | 1.0 | 1.0 | 0.003955 | 0.050505 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 4 0.003591 | 1.0 | 1.0 | 0.197034 | 0.002165 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 5 0.004488 | 1.0 | 1.0 | 0.001912 | 0.013709 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 6 0.005386 | 1.0 | 1.0 | 0.158075 | 0.019481 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 7 0.006284 | 1.0 | 1.0 | 0.049440 | 0.006494 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 8 0.007181 | 1.0 | 1.0 | 0.013250 | 0.129149 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . 9 0.008079 | 1.0 | 1.0 | 0.020699 | 0.050505 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | . Encode Categorical Columns . from sklearn.preprocessing import OneHotEncoder . encoder = OneHotEncoder(sparse=False, handle_unknown=&#39;ignore&#39;).fit(inputs[categorical_cols]) encoded_cols = list(encoder.get_feature_names(categorical_cols)) . inputs[encoded_cols] = encoder.transform(inputs[categorical_cols]) test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols]) . encoded_cols . [&#39;DayOfWeek_1&#39;, &#39;DayOfWeek_2&#39;, &#39;DayOfWeek_3&#39;, &#39;DayOfWeek_4&#39;, &#39;DayOfWeek_5&#39;, &#39;DayOfWeek_6&#39;, &#39;DayOfWeek_7&#39;, &#39;StateHoliday_0&#39;, &#39;StateHoliday_a&#39;, &#39;StateHoliday_b&#39;, &#39;StateHoliday_c&#39;, &#39;StoreType_a&#39;, &#39;StoreType_b&#39;, &#39;StoreType_c&#39;, &#39;StoreType_d&#39;, &#39;Assortment_a&#39;, &#39;Assortment_b&#39;, &#39;Assortment_c&#39;] . X = inputs[numeric_cols + encoded_cols] X_test = test_inputs[numeric_cols + encoded_cols] . X.head(10) . Store Promo SchoolHoliday CompetitionDistance CompetitionOpen Promo2 Promo2Open IsPromo2Month Day Month Year WeekofYear DayOfWeek_1 DayOfWeek_2 DayOfWeek_3 DayOfWeek_4 DayOfWeek_5 DayOfWeek_6 DayOfWeek_7 StateHoliday_0 StateHoliday_a StateHoliday_b StateHoliday_c StoreType_a StoreType_b StoreType_c StoreType_d Assortment_a Assortment_b Assortment_c . 0 0.000000 | 1.0 | 1.0 | 0.008240 | 0.059163 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 1 0.000898 | 1.0 | 1.0 | 0.003626 | 0.066378 | 1.0 | 0.890710 | 0.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2 0.001795 | 1.0 | 1.0 | 0.093013 | 0.074315 | 1.0 | 0.720856 | 0.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 3 0.002693 | 1.0 | 1.0 | 0.003955 | 0.050505 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 4 0.003591 | 1.0 | 1.0 | 0.197034 | 0.002165 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 5 0.004488 | 1.0 | 1.0 | 0.001912 | 0.013709 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 6 0.005386 | 1.0 | 1.0 | 0.158075 | 0.019481 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 7 0.006284 | 1.0 | 1.0 | 0.049440 | 0.006494 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 8 0.007181 | 1.0 | 1.0 | 0.013250 | 0.129149 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 9 0.008079 | 1.0 | 1.0 | 0.020699 | 0.050505 | 0.0 | 0.000000 | 1.0 | 1.0 | 0.545455 | 1.0 | 0.588235 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . checkout_otherswork . Gradient Boosting . The average value of the target column and uses as an initial prediction every input. | The residuals (difference) of the predictions with the targets are computed. | A decision tree of limited depth is trained to predict just the residuals for each input. | Predictions from the decision tree are scaled using a parameter called the learning rate (this prevents overfitting) | Scaled predictions fro the tree are added to the previous predictions to obtain the new and improved predictions. | Steps 2 to 5 are repeated to create new decision trees, each of which is trained to predict just the residuals from the previous prediction. | The term &quot;gradient&quot; refers to the fact that each decision tree is trained with the purpose of reducing the loss from the previous iteration (similar to gradient descent). The term &quot;boosting&quot; refers the general technique of training new models to improve the results of an existing model. . For a mathematical explanation of gradient boosting, check out the following resources: . XGBoost Documentation | Video Tutorials on StatQuest | . Here&#39;s a visual representation of gradient boosting: . . Gradient Boosting Machines: . Traning . from xgboost import XGBRegressor . ?XGBRegressor . model = XGBRegressor(random_state=42, n_jobs=-1, n_estimators=20, max_depth=4) . lets train model using model.fit . %%time model.fit(X, targets) . CPU times: user 42.7 s, sys: 981 ms, total: 43.7 s Wall time: 4.16 s . XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1, importance_type=&#39;gain&#39;, interaction_constraints=&#39;&#39;, learning_rate=0.300000012, max_delta_step=0, max_depth=4, min_child_weight=1, missing=nan, monotone_constraints=&#39;()&#39;, n_estimators=20, n_jobs=-1, num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#39;exact&#39;, validate_parameters=1, verbosity=None) . Prediction . preds = model.predict(X) . preds . array([ 8127.9404, 7606.919 , 8525.857 , ..., 6412.8247, 9460.068 , 10302.145 ], dtype=float32) . Evaluation . from sklearn.metrics import mean_squared_error . def rmse(a, b): return mean_squared_error(a, b, squared=False) . rmse(preds, targets) . 2377.752008804669 . merged_df.Sales.min(), merged_df.Sales.max() . (0, 41551) . import matplotlib.pyplot as plt %matplotlib inline plt.hist(merged_df.Sales.sample(10000)) . (array([3.640e+02, 4.017e+03, 3.639e+03, 1.357e+03, 3.930e+02, 1.420e+02, 5.900e+01, 2.300e+01, 4.000e+00, 2.000e+00]), array([ 0. , 3002.6, 6005.2, 9007.8, 12010.4, 15013. , 18015.6, 21018.2, 24020.8, 27023.4, 30026. ]), &lt;BarContainer object of 10 artists&gt;) . Visualization . from xgboost import plot_tree from matplotlib.pylab import rcParams rcParams[&#39;figure.figsize&#39;] = 60,60 . plot_tree(model, rankdir=&#39;LR&#39;, num_trees=0); . plot_tree(model, rankdir=&#39;LR&#39;, num_trees=1); . plot_tree(model, rankdir=&#39;LR&#39;, num_trees=19); . trees = model.get_booster().get_dump() . len(trees) . 20 . print(trees[0]) . 0:[Promo&lt;0.5] yes=1,no=2,missing=1 1:[StoreType_b&lt;0.5] yes=3,no=4,missing=3 3:[Assortment_a&lt;0.5] yes=7,no=8,missing=7 7:[CompetitionDistance&lt;0.00220830599] yes=15,no=16,missing=15 15:leaf=2309.51147 16:leaf=1823.30444 8:[WeekofYear&lt;0.911764741] yes=17,no=18,missing=17 17:leaf=1619.43994 18:leaf=2002.44897 4:[CompetitionDistance&lt;0.00800922886] yes=9,no=10,missing=9 9:[CompetitionDistance&lt;0.00672379695] yes=19,no=20,missing=19 19:leaf=2740.44067 20:leaf=5576.85889 10:[DayOfWeek_7&lt;0.5] yes=21,no=22,missing=21 21:leaf=1898.36487 22:leaf=2961.08765 2:[DayOfWeek_1&lt;0.5] yes=5,no=6,missing=5 5:[Month&lt;0.954545498] yes=11,no=12,missing=11 11:[StoreType_b&lt;0.5] yes=23,no=24,missing=23 23:leaf=2295.30566 24:leaf=3294.27759 12:[Day&lt;0.333333343] yes=25,no=26,missing=25 25:leaf=2754.58521 26:leaf=3246.39014 6:[Month&lt;0.954545498] yes=13,no=14,missing=13 13:[CompetitionDistance&lt;0.00135135138] yes=27,no=28,missing=27 27:leaf=3347.80688 28:leaf=2839.39551 14:[Day&lt;0.25] yes=29,no=30,missing=29 29:leaf=3400.54419 30:leaf=4059.85938 . Feature Importance . importance_df = pd.DataFrame({ &#39;feature&#39;: X.columns, &#39;importance&#39;:model.feature_importances_ }).sort_values(&#39;importance&#39;, ascending=False) . importance_df.head(10) . feature importance . 1 Promo | 0.317473 | . 24 StoreType_b | 0.086472 | . 12 DayOfWeek_1 | 0.082269 | . 5 Promo2 | 0.063986 | . 3 CompetitionDistance | 0.045053 | . 29 Assortment_c | 0.040226 | . 27 Assortment_a | 0.038759 | . 9 Month | 0.038493 | . 0 Store | 0.038119 | . 8 Day | 0.033209 | . import seaborn as sns plt.figure(figsize=(10, 6)) plt.title(&#39;Feature Importance&#39;) sns.barplot(data=importance_df.head(10), x=&#39;importance&#39;, y=&#39;feature&#39;); . K Fold Cross Validation . from sklearn.model_selection import KFold . def train_and_evaluate(X_train, train_targets, X_val, val_targets, **params): model = XGBRegressor(random_state=42, n_jobs=-1, **params) model.fit(X_train, train_targets) train_rmse = rmse(model.predict(X_train), train_targets) val_rmse = rmse(model.predict(X_val), val_targets) return model, train_rmse, val_rmse . kfold = KFold(n_splits=5) . models = [] for train_idxs, val_idxs in kfold.split(X): X_train, train_targets = X.iloc[train_idxs], targets.iloc[train_idxs] X_val, val_targets = X.iloc[val_idxs], targets.iloc[val_idxs] model, train_rmse, val_rmse = train_and_evaluate(X_train, train_targets, X_val, val_targets, max_depth=4, n_estimators=20) models.append(model) print(&#39;Train RMSE: {}, Validation RMSE: {}&#39;.format(train_rmse, val_rmse)) . Train RMSE: 2352.216448531526, Validation RMSE: 2424.6228916973314 Train RMSE: 2406.709513789309, Validation RMSE: 2451.9646038059277 Train RMSE: 2365.7354745443067, Validation RMSE: 2336.984157073758 Train RMSE: 2366.4732092777763, Validation RMSE: 2460.8995475901697 Train RMSE: 2379.3752997474626, Validation RMSE: 2440.665320626728 . import numpy as np def predict_avg(models, inputs): return np.mean([model.predict(inputs) for model in models], axis=0) . preds = predict_avg(models, X) . preds . array([8021.374 , 7577.715 , 8747.863 , ..., 7615.0303, 7924.784 , 9600.297 ], dtype=float32) . Hyperparameter Tuning and Regularization . Just like other machine learning models, there are several hyperparameters we can to adjust the capacity of model and reduce overfitting. . . Check out the following resources to learn more about hyperparameter supported by XGBoost: . https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor | https://xgboost.readthedocs.io/en/latest/parameter.html | . model . XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1, importance_type=&#39;gain&#39;, interaction_constraints=&#39;&#39;, learning_rate=0.300000012, max_delta_step=0, max_depth=4, min_child_weight=1, missing=nan, monotone_constraints=&#39;()&#39;, n_estimators=20, n_jobs=-1, num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=&#39;exact&#39;, validate_parameters=1, verbosity=None) . def test_params_kfold(n_splits, **params): train_rmses, val_rmses, models = [], [], [] kfold = KFold(n_splits) for train_idxs, val_idxs in kfold.split(X): X_train, train_targets = X.iloc[train_idxs], targets.iloc[train_idxs] X_val, val_targets = X.iloc[val_idxs], targets.iloc[val_idxs] model, train_rmse, val_rmse = train_and_evaluate(X_train, train_targets, X_val, val_targets, **params) models.append(model) train_rmses.append(train_rmse) val_rmses.append(val_rmse) print(&#39;Train RMSE: {}, Validation RMSE: {}&#39;.format(np.mean(train_rmses), np.mean(val_rmses))) return models . from sklearn.model_selection import train_test_split . X_train, X_val, train_targets, val_targets = train_test_split(X, targets, test_size=0.1) . def test_params(**params): model = XGBRegressor(n_jobs=-1, random_state=42, **params) model.fit(X_train, train_targets) train_rmse = rmse(model.predict(X_train), train_targets) val_rmse = rmse(model.predict(X_val), val_targets) print(&#39;Train RMSE: {}, Validation RMSE: {}&#39;.format(train_rmse, val_rmse)) . n_estimators . test_params(n_estimators=10) . Train RMSE: 2362.76195480308, Validation RMSE: 2348.702085349391 . test_params(n_estimators=30) . Train RMSE: 1848.646131664556, Validation RMSE: 1839.8374140100673 . test_params(n_estimators=100) . Train RMSE: 1189.0907835721493, Validation RMSE: 1182.191673835398 . test_params(n_estimators=240) . Train RMSE: 900.8147134992857, Validation RMSE: 909.3936493978623 . max_depth . test_params(max_depth=2) . Train RMSE: 2337.546637614515, Validation RMSE: 2315.858142292135 . test_params(max_depth=5) . Train RMSE: 1420.072022973741, Validation RMSE: 1411.0540606302004 . test_params(max_depth=10) . Train RMSE: 687.2499006884119, Validation RMSE: 775.8096745259544 . learning_rate . test_params(n_estimators=50, learning_rate=0.01) . Train RMSE: 5044.48850172585, Validation RMSE: 5036.89440315394 . test_params(n_estimators=50, learning_rate=0.1) . Train RMSE: 2200.172003242853, Validation RMSE: 2183.102936809057 . test_params(n_estimators=50, learning_rate=0.3) . Train RMSE: 1541.0745464792515, Validation RMSE: 1529.8196486972695 . test_params(n_estimators=50, learning_rate=0.9) . Train RMSE: 1121.9325695263058, Validation RMSE: 1123.541189011288 . Booster . test_params(booster=&#39;gblinear&#39;) . Train RMSE: 2730.688924077907, Validation RMSE: 2707.009329528743 . Putting it Together and Making Predictions . model = XGBRegressor(n_jobs=-1, random_state=42, n_estimators=1000, learning_rate=0.2, max_depth=10, subsample=0.9, colsample_bytree=0.7) . %%time model.fit(X, targets) . CPU times: user 1h 6min 23s, sys: 13.4 s, total: 1h 6min 36s Wall time: 5min 49s . XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1, importance_type=&#39;gain&#39;, interaction_constraints=&#39;&#39;, learning_rate=0.2, max_delta_step=0, max_depth=10, min_child_weight=1, missing=nan, monotone_constraints=&#39;()&#39;, n_estimators=1000, n_jobs=-1, num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.9, tree_method=&#39;exact&#39;, validate_parameters=1, verbosity=None) . test_preds = model.predict(X_test) . submission_df[&#39;Sales&#39;] = test_preds . test_df.Open.isna().sum() . 11 . submission_df[&#39;Sales&#39;] = submission_df[&#39;Sales&#39;] * test_df.Open.fillna(1.) . submission_df . Id Sales . 0 1 | 3978.170898 | . 1 2 | 7715.094727 | . 2 3 | 8728.141602 | . 3 4 | 7502.937012 | . 4 5 | 7036.492676 | . ... ... | ... | . 41083 41084 | 2987.847168 | . 41084 41085 | 6813.018066 | . 41085 41086 | 6863.016602 | . 41086 41087 | 23361.136719 | . 41087 41088 | 6743.966797 | . 41088 rows × 2 columns . submission_df.to_csv(&#39;submission.csv&#39;, index=None) .",
            "url": "https://mr-siddy.github.io/ML-blog/ml/2021/05/20/GBMs-1-XGBoost.html",
            "relUrl": "/ml/2021/05/20/GBMs-1-XGBoost.html",
            "date": " • May 20, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "Decision Trees and Random Forest",
            "content": "import opendatasets as od import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import seaborn as sns import os %matplotlib inline pd.set_option(&#39;display.max_columns&#39;, None) pd.set_option(&#39;display.max_rows&#39;, 150) sns.set_style(&#39;darkgrid&#39;) matplotlib.rcParams[&#39;font.size&#39;] = 14 matplotlib.rcParams[&#39;figure.figsize&#39;] = (10, 6) matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#00000000&#39; . os.listdir(&#39;weather-dataset-rattle-package&#39;) . [&#39;weatherAUS.csv&#39;] . raw_df = pd.read_csv(&#39;weather-dataset-rattle-package/weatherAUS.csv&#39;) . raw_df.head(10) . Date Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday RainTomorrow . 0 2008-12-01 | Albury | 13.4 | 22.9 | 0.6 | NaN | NaN | W | 44.0 | W | WNW | 20.0 | 24.0 | 71.0 | 22.0 | 1007.7 | 1007.1 | 8.0 | NaN | 16.9 | 21.8 | No | No | . 1 2008-12-02 | Albury | 7.4 | 25.1 | 0.0 | NaN | NaN | WNW | 44.0 | NNW | WSW | 4.0 | 22.0 | 44.0 | 25.0 | 1010.6 | 1007.8 | NaN | NaN | 17.2 | 24.3 | No | No | . 2 2008-12-03 | Albury | 12.9 | 25.7 | 0.0 | NaN | NaN | WSW | 46.0 | W | WSW | 19.0 | 26.0 | 38.0 | 30.0 | 1007.6 | 1008.7 | NaN | 2.0 | 21.0 | 23.2 | No | No | . 3 2008-12-04 | Albury | 9.2 | 28.0 | 0.0 | NaN | NaN | NE | 24.0 | SE | E | 11.0 | 9.0 | 45.0 | 16.0 | 1017.6 | 1012.8 | NaN | NaN | 18.1 | 26.5 | No | No | . 4 2008-12-05 | Albury | 17.5 | 32.3 | 1.0 | NaN | NaN | W | 41.0 | ENE | NW | 7.0 | 20.0 | 82.0 | 33.0 | 1010.8 | 1006.0 | 7.0 | 8.0 | 17.8 | 29.7 | No | No | . 5 2008-12-06 | Albury | 14.6 | 29.7 | 0.2 | NaN | NaN | WNW | 56.0 | W | W | 19.0 | 24.0 | 55.0 | 23.0 | 1009.2 | 1005.4 | NaN | NaN | 20.6 | 28.9 | No | No | . 6 2008-12-07 | Albury | 14.3 | 25.0 | 0.0 | NaN | NaN | W | 50.0 | SW | W | 20.0 | 24.0 | 49.0 | 19.0 | 1009.6 | 1008.2 | 1.0 | NaN | 18.1 | 24.6 | No | No | . 7 2008-12-08 | Albury | 7.7 | 26.7 | 0.0 | NaN | NaN | W | 35.0 | SSE | W | 6.0 | 17.0 | 48.0 | 19.0 | 1013.4 | 1010.1 | NaN | NaN | 16.3 | 25.5 | No | No | . 8 2008-12-09 | Albury | 9.7 | 31.9 | 0.0 | NaN | NaN | NNW | 80.0 | SE | NW | 7.0 | 28.0 | 42.0 | 9.0 | 1008.9 | 1003.6 | NaN | NaN | 18.3 | 30.2 | No | Yes | . 9 2008-12-10 | Albury | 13.1 | 30.1 | 1.4 | NaN | NaN | W | 28.0 | S | SSE | 15.0 | 11.0 | 58.0 | 27.0 | 1007.0 | 1005.7 | NaN | NaN | 20.1 | 28.2 | Yes | No | . raw_df.shape . (145460, 23) . raw_df.info() # to check column types of dataset . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 145460 entries, 0 to 145459 Data columns (total 23 columns): # Column Non-Null Count Dtype -- -- 0 Date 145460 non-null object 1 Location 145460 non-null object 2 MinTemp 143975 non-null float64 3 MaxTemp 144199 non-null float64 4 Rainfall 142199 non-null float64 5 Evaporation 82670 non-null float64 6 Sunshine 75625 non-null float64 7 WindGustDir 135134 non-null object 8 WindGustSpeed 135197 non-null float64 9 WindDir9am 134894 non-null object 10 WindDir3pm 141232 non-null object 11 WindSpeed9am 143693 non-null float64 12 WindSpeed3pm 142398 non-null float64 13 Humidity9am 142806 non-null float64 14 Humidity3pm 140953 non-null float64 15 Pressure9am 130395 non-null float64 16 Pressure3pm 130432 non-null float64 17 Cloud9am 89572 non-null float64 18 Cloud3pm 86102 non-null float64 19 Temp9am 143693 non-null float64 20 Temp3pm 141851 non-null float64 21 RainToday 142199 non-null object 22 RainTomorrow 142193 non-null object dtypes: float64(16), object(7) memory usage: 25.5+ MB . raw_df.dropna(subset=[&#39;RainTomorrow&#39;], inplace=True) . raw_df.head(2) . Date Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday RainTomorrow . 0 2008-12-01 | Albury | 13.4 | 22.9 | 0.6 | NaN | NaN | W | 44.0 | W | WNW | 20.0 | 24.0 | 71.0 | 22.0 | 1007.7 | 1007.1 | 8.0 | NaN | 16.9 | 21.8 | No | No | . 1 2008-12-02 | Albury | 7.4 | 25.1 | 0.0 | NaN | NaN | WNW | 44.0 | NNW | WSW | 4.0 | 22.0 | 44.0 | 25.0 | 1010.6 | 1007.8 | NaN | NaN | 17.2 | 24.3 | No | No | . raw_df.shape # shape has become 142193 . (142193, 23) . Training Validation and Test Sets . plt.title(&quot;no.of Rows per Year&quot;) sns.countplot(x=pd.to_datetime(raw_df.Date).dt.year); . year = pd.to_datetime(raw_df.Date).dt.year train_df = raw_df[year&lt;2015] val_df = raw_df[year==2015] test_df = raw_df[year&gt;2015] print(train_df.shape, val_df.shape, test_df.shape) . (98988, 23) (17231, 23) (25974, 23) . Input and Target Columns . input_cols = list(train_df.columns)[1:-1] target_cols = &#39;RainTomorrow&#39; . target_cols . &#39;RainTomorrow&#39; . input_cols . [&#39;Location&#39;, &#39;MinTemp&#39;, &#39;MaxTemp&#39;, &#39;Rainfall&#39;, &#39;Evaporation&#39;, &#39;Sunshine&#39;, &#39;WindGustDir&#39;, &#39;WindGustSpeed&#39;, &#39;WindDir9am&#39;, &#39;WindDir3pm&#39;, &#39;WindSpeed9am&#39;, &#39;WindSpeed3pm&#39;, &#39;Humidity9am&#39;, &#39;Humidity3pm&#39;, &#39;Pressure9am&#39;, &#39;Pressure3pm&#39;, &#39;Cloud9am&#39;, &#39;Cloud3pm&#39;, &#39;Temp9am&#39;, &#39;Temp3pm&#39;, &#39;RainToday&#39;] . train_inputs = train_df[input_cols].copy() train_targets = train_df[target_cols].copy() val_inputs = val_df[input_cols].copy() val_targets = val_df[target_cols].copy() test_inputs = test_df[input_cols].copy() test_targets = test_df[target_cols].copy() . numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist() categorical_cols = train_inputs.select_dtypes(&#39;object&#39;).columns.tolist() . print(numeric_cols) . [&#39;MinTemp&#39;, &#39;MaxTemp&#39;, &#39;Rainfall&#39;, &#39;Evaporation&#39;, &#39;Sunshine&#39;, &#39;WindGustSpeed&#39;, &#39;WindSpeed9am&#39;, &#39;WindSpeed3pm&#39;, &#39;Humidity9am&#39;, &#39;Humidity3pm&#39;, &#39;Pressure9am&#39;, &#39;Pressure3pm&#39;, &#39;Cloud9am&#39;, &#39;Cloud3pm&#39;, &#39;Temp9am&#39;, &#39;Temp3pm&#39;] . print(categorical_cols) . [&#39;Location&#39;, &#39;WindGustDir&#39;, &#39;WindDir9am&#39;, &#39;WindDir3pm&#39;, &#39;RainToday&#39;] . Imputing Missing Numeric Values . train_inputs[numeric_cols].isna().sum().sort_values(ascending=False) . Sunshine 40696 Evaporation 37110 Cloud3pm 36766 Cloud9am 35764 Pressure9am 9345 Pressure3pm 9309 WindGustSpeed 6902 Humidity9am 1265 Humidity3pm 1186 WindSpeed3pm 1140 WindSpeed9am 1133 Rainfall 1000 Temp9am 783 Temp3pm 663 MinTemp 434 MaxTemp 198 dtype: int64 . from sklearn.impute import SimpleImputer . imputer = SimpleImputer(strategy = &#39;mean&#39;).fit(raw_df[numeric_cols]) # imputer will figureout the avg for each of cols . train_inputs[numeric_cols] = imputer.transform(train_inputs[numeric_cols]) # fill empty data val_inputs[numeric_cols] = imputer.transform(val_inputs[numeric_cols]) test_inputs[numeric_cols] = imputer.transform(test_inputs[numeric_cols]) . train_inputs[numeric_cols].isna().sum() . MinTemp 0 MaxTemp 0 Rainfall 0 Evaporation 0 Sunshine 0 WindGustSpeed 0 WindSpeed9am 0 WindSpeed3pm 0 Humidity9am 0 Humidity3pm 0 Pressure9am 0 Pressure3pm 0 Cloud9am 0 Cloud3pm 0 Temp9am 0 Temp3pm 0 dtype: int64 . Scaling Numeric Features . from sklearn.preprocessing import MinMaxScaler . val_inputs.describe().loc[[&#39;min&#39;, &#39;max&#39;]] . MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustSpeed WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm . min -8.2 | -3.2 | 0.0 | 0.0 | 0.0 | 7.0 | 0.0 | 0.0 | 4.0 | 0.0 | 988.1 | 982.2 | 0.0 | 0.0 | -6.2 | -4.0 | . max 31.9 | 45.4 | 247.2 | 70.4 | 14.5 | 135.0 | 87.0 | 74.0 | 100.0 | 100.0 | 1039.3 | 1037.3 | 8.0 | 8.0 | 37.5 | 42.8 | . scaler = MinMaxScaler().fit(raw_df[numeric_cols]) . train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols]) val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols]) test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols]) . val_inputs.describe().loc[[&#39;min&#39;, &#39;max&#39;]] . MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustSpeed WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm . min 0.007075 | 0.030246 | 0.000000 | 0.000000 | 0.0 | 0.007752 | 0.000000 | 0.000000 | 0.04 | 0.0 | 0.125620 | 0.0816 | 0.000000 | 0.000000 | 0.021097 | 0.026871 | . max 0.952830 | 0.948960 | 0.666307 | 0.485517 | 1.0 | 1.000000 | 0.669231 | 0.850575 | 1.00 | 1.0 | 0.971901 | 0.9632 | 0.888889 | 0.888889 | 0.943038 | 0.925144 | . Encoding Categorical Data . from sklearn.preprocessing import OneHotEncoder . train_df[categorical_cols].fillna(&#39;Unkown&#39;) val_df[categorical_cols].fillna(&#39;Unkown&#39;) test_df[categorical_cols].fillna(&#39;Unknown&#39;) . Location WindGustDir WindDir9am WindDir3pm RainToday . 2498 Albury | ENE | Unknown | ESE | No | . 2499 Albury | SSE | SSE | SE | No | . 2500 Albury | ENE | ESE | ENE | Yes | . 2501 Albury | SSE | SE | SSE | Yes | . 2502 Albury | ENE | SE | SSE | Yes | . ... ... | ... | ... | ... | ... | . 145454 Uluru | E | ESE | E | No | . 145455 Uluru | E | SE | ENE | No | . 145456 Uluru | NNW | SE | N | No | . 145457 Uluru | N | SE | WNW | No | . 145458 Uluru | SE | SSE | N | No | . 25974 rows × 5 columns . encoder = OneHotEncoder(sparse=False, handle_unknown=&#39;ignore&#39;).fit(raw_df[categorical_cols]) . encoded_cols = list(encoder.get_feature_names(categorical_cols)) . train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols]) val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols]) test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols]) . print(encoded_cols) . [&#39;Location_Adelaide&#39;, &#39;Location_Albany&#39;, &#39;Location_Albury&#39;, &#39;Location_AliceSprings&#39;, &#39;Location_BadgerysCreek&#39;, &#39;Location_Ballarat&#39;, &#39;Location_Bendigo&#39;, &#39;Location_Brisbane&#39;, &#39;Location_Cairns&#39;, &#39;Location_Canberra&#39;, &#39;Location_Cobar&#39;, &#39;Location_CoffsHarbour&#39;, &#39;Location_Dartmoor&#39;, &#39;Location_Darwin&#39;, &#39;Location_GoldCoast&#39;, &#39;Location_Hobart&#39;, &#39;Location_Katherine&#39;, &#39;Location_Launceston&#39;, &#39;Location_Melbourne&#39;, &#39;Location_MelbourneAirport&#39;, &#39;Location_Mildura&#39;, &#39;Location_Moree&#39;, &#39;Location_MountGambier&#39;, &#39;Location_MountGinini&#39;, &#39;Location_Newcastle&#39;, &#39;Location_Nhil&#39;, &#39;Location_NorahHead&#39;, &#39;Location_NorfolkIsland&#39;, &#39;Location_Nuriootpa&#39;, &#39;Location_PearceRAAF&#39;, &#39;Location_Penrith&#39;, &#39;Location_Perth&#39;, &#39;Location_PerthAirport&#39;, &#39;Location_Portland&#39;, &#39;Location_Richmond&#39;, &#39;Location_Sale&#39;, &#39;Location_SalmonGums&#39;, &#39;Location_Sydney&#39;, &#39;Location_SydneyAirport&#39;, &#39;Location_Townsville&#39;, &#39;Location_Tuggeranong&#39;, &#39;Location_Uluru&#39;, &#39;Location_WaggaWagga&#39;, &#39;Location_Walpole&#39;, &#39;Location_Watsonia&#39;, &#39;Location_Williamtown&#39;, &#39;Location_Witchcliffe&#39;, &#39;Location_Wollongong&#39;, &#39;Location_Woomera&#39;, &#39;WindGustDir_E&#39;, &#39;WindGustDir_ENE&#39;, &#39;WindGustDir_ESE&#39;, &#39;WindGustDir_N&#39;, &#39;WindGustDir_NE&#39;, &#39;WindGustDir_NNE&#39;, &#39;WindGustDir_NNW&#39;, &#39;WindGustDir_NW&#39;, &#39;WindGustDir_S&#39;, &#39;WindGustDir_SE&#39;, &#39;WindGustDir_SSE&#39;, &#39;WindGustDir_SSW&#39;, &#39;WindGustDir_SW&#39;, &#39;WindGustDir_W&#39;, &#39;WindGustDir_WNW&#39;, &#39;WindGustDir_WSW&#39;, &#39;WindGustDir_nan&#39;, &#39;WindDir9am_E&#39;, &#39;WindDir9am_ENE&#39;, &#39;WindDir9am_ESE&#39;, &#39;WindDir9am_N&#39;, &#39;WindDir9am_NE&#39;, &#39;WindDir9am_NNE&#39;, &#39;WindDir9am_NNW&#39;, &#39;WindDir9am_NW&#39;, &#39;WindDir9am_S&#39;, &#39;WindDir9am_SE&#39;, &#39;WindDir9am_SSE&#39;, &#39;WindDir9am_SSW&#39;, &#39;WindDir9am_SW&#39;, &#39;WindDir9am_W&#39;, &#39;WindDir9am_WNW&#39;, &#39;WindDir9am_WSW&#39;, &#39;WindDir9am_nan&#39;, &#39;WindDir3pm_E&#39;, &#39;WindDir3pm_ENE&#39;, &#39;WindDir3pm_ESE&#39;, &#39;WindDir3pm_N&#39;, &#39;WindDir3pm_NE&#39;, &#39;WindDir3pm_NNE&#39;, &#39;WindDir3pm_NNW&#39;, &#39;WindDir3pm_NW&#39;, &#39;WindDir3pm_S&#39;, &#39;WindDir3pm_SE&#39;, &#39;WindDir3pm_SSE&#39;, &#39;WindDir3pm_SSW&#39;, &#39;WindDir3pm_SW&#39;, &#39;WindDir3pm_W&#39;, &#39;WindDir3pm_WNW&#39;, &#39;WindDir3pm_WSW&#39;, &#39;WindDir3pm_nan&#39;, &#39;RainToday_No&#39;, &#39;RainToday_Yes&#39;, &#39;RainToday_nan&#39;] . train_inputs.head(10) . Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday Location_Adelaide Location_Albany Location_Albury Location_AliceSprings Location_BadgerysCreek Location_Ballarat Location_Bendigo Location_Brisbane Location_Cairns Location_Canberra Location_Cobar Location_CoffsHarbour Location_Dartmoor Location_Darwin Location_GoldCoast Location_Hobart Location_Katherine Location_Launceston Location_Melbourne Location_MelbourneAirport Location_Mildura Location_Moree Location_MountGambier Location_MountGinini Location_Newcastle Location_Nhil Location_NorahHead Location_NorfolkIsland Location_Nuriootpa Location_PearceRAAF Location_Penrith Location_Perth Location_PerthAirport Location_Portland Location_Richmond Location_Sale Location_SalmonGums Location_Sydney Location_SydneyAirport Location_Townsville Location_Tuggeranong Location_Uluru Location_WaggaWagga Location_Walpole Location_Watsonia Location_Williamtown Location_Witchcliffe Location_Wollongong Location_Woomera WindGustDir_E WindGustDir_ENE WindGustDir_ESE WindGustDir_N WindGustDir_NE WindGustDir_NNE WindGustDir_NNW WindGustDir_NW WindGustDir_S WindGustDir_SE WindGustDir_SSE WindGustDir_SSW WindGustDir_SW WindGustDir_W WindGustDir_WNW WindGustDir_WSW WindGustDir_nan WindDir9am_E WindDir9am_ENE WindDir9am_ESE WindDir9am_N WindDir9am_NE WindDir9am_NNE WindDir9am_NNW WindDir9am_NW WindDir9am_S WindDir9am_SE WindDir9am_SSE WindDir9am_SSW WindDir9am_SW WindDir9am_W WindDir9am_WNW WindDir9am_WSW WindDir9am_nan WindDir3pm_E WindDir3pm_ENE WindDir3pm_ESE WindDir3pm_N WindDir3pm_NE WindDir3pm_NNE WindDir3pm_NNW WindDir3pm_NW WindDir3pm_S WindDir3pm_SE WindDir3pm_SSE WindDir3pm_SSW WindDir3pm_SW WindDir3pm_W WindDir3pm_WNW WindDir3pm_WSW WindDir3pm_nan RainToday_No RainToday_Yes RainToday_nan . 0 Albury | 0.516509 | 0.523629 | 0.001617 | 0.037723 | 0.525852 | W | 0.294574 | W | WNW | 0.153846 | 0.275862 | 0.71 | 0.22 | 0.449587 | 0.4800 | 0.888889 | 0.500352 | 0.508439 | 0.522073 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 1 Albury | 0.375000 | 0.565217 | 0.000000 | 0.037723 | 0.525852 | WNW | 0.294574 | NNW | WSW | 0.030769 | 0.252874 | 0.44 | 0.25 | 0.497521 | 0.4912 | 0.493021 | 0.500352 | 0.514768 | 0.570058 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2 Albury | 0.504717 | 0.576560 | 0.000000 | 0.037723 | 0.525852 | WSW | 0.310078 | W | WSW | 0.146154 | 0.298851 | 0.38 | 0.30 | 0.447934 | 0.5056 | 0.493021 | 0.222222 | 0.594937 | 0.548944 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 3 Albury | 0.417453 | 0.620038 | 0.000000 | 0.037723 | 0.525852 | NE | 0.139535 | SE | E | 0.084615 | 0.103448 | 0.45 | 0.16 | 0.613223 | 0.5712 | 0.493021 | 0.500352 | 0.533755 | 0.612284 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 4 Albury | 0.613208 | 0.701323 | 0.002695 | 0.037723 | 0.525852 | W | 0.271318 | ENE | NW | 0.053846 | 0.229885 | 0.82 | 0.33 | 0.500826 | 0.4624 | 0.777778 | 0.888889 | 0.527426 | 0.673704 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 5 Albury | 0.544811 | 0.652174 | 0.000539 | 0.037723 | 0.525852 | WNW | 0.387597 | W | W | 0.146154 | 0.275862 | 0.55 | 0.23 | 0.474380 | 0.4528 | 0.493021 | 0.500352 | 0.586498 | 0.658349 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 6 Albury | 0.537736 | 0.563327 | 0.000000 | 0.037723 | 0.525852 | W | 0.341085 | SW | W | 0.153846 | 0.275862 | 0.49 | 0.19 | 0.480992 | 0.4976 | 0.111111 | 0.500352 | 0.533755 | 0.575816 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 7 Albury | 0.382075 | 0.595463 | 0.000000 | 0.037723 | 0.525852 | W | 0.224806 | SSE | W | 0.046154 | 0.195402 | 0.48 | 0.19 | 0.543802 | 0.5280 | 0.493021 | 0.500352 | 0.495781 | 0.593090 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 8 Albury | 0.429245 | 0.693762 | 0.000000 | 0.037723 | 0.525852 | NNW | 0.573643 | SE | NW | 0.053846 | 0.321839 | 0.42 | 0.09 | 0.469421 | 0.4240 | 0.493021 | 0.500352 | 0.537975 | 0.683301 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 9 Albury | 0.509434 | 0.659735 | 0.003774 | 0.037723 | 0.525852 | W | 0.170543 | S | SSE | 0.115385 | 0.126437 | 0.58 | 0.27 | 0.438017 | 0.4576 | 0.493021 | 0.500352 | 0.575949 | 0.644914 | Yes | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . X_train = train_inputs[numeric_cols + encoded_cols] X_val = val_inputs[numeric_cols + encoded_cols] X_test = test_inputs[numeric_cols + encoded_cols] . X_test.head(10) . MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustSpeed WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm Location_Adelaide Location_Albany Location_Albury Location_AliceSprings Location_BadgerysCreek Location_Ballarat Location_Bendigo Location_Brisbane Location_Cairns Location_Canberra Location_Cobar Location_CoffsHarbour Location_Dartmoor Location_Darwin Location_GoldCoast Location_Hobart Location_Katherine Location_Launceston Location_Melbourne Location_MelbourneAirport Location_Mildura Location_Moree Location_MountGambier Location_MountGinini Location_Newcastle Location_Nhil Location_NorahHead Location_NorfolkIsland Location_Nuriootpa Location_PearceRAAF Location_Penrith Location_Perth Location_PerthAirport Location_Portland Location_Richmond Location_Sale Location_SalmonGums Location_Sydney Location_SydneyAirport Location_Townsville Location_Tuggeranong Location_Uluru Location_WaggaWagga Location_Walpole Location_Watsonia Location_Williamtown Location_Witchcliffe Location_Wollongong Location_Woomera WindGustDir_E WindGustDir_ENE WindGustDir_ESE WindGustDir_N WindGustDir_NE WindGustDir_NNE WindGustDir_NNW WindGustDir_NW WindGustDir_S WindGustDir_SE WindGustDir_SSE WindGustDir_SSW WindGustDir_SW WindGustDir_W WindGustDir_WNW WindGustDir_WSW WindGustDir_nan WindDir9am_E WindDir9am_ENE WindDir9am_ESE WindDir9am_N WindDir9am_NE WindDir9am_NNE WindDir9am_NNW WindDir9am_NW WindDir9am_S WindDir9am_SE WindDir9am_SSE WindDir9am_SSW WindDir9am_SW WindDir9am_W WindDir9am_WNW WindDir9am_WSW WindDir9am_nan WindDir3pm_E WindDir3pm_ENE WindDir3pm_ESE WindDir3pm_N WindDir3pm_NE WindDir3pm_NNE WindDir3pm_NNW WindDir3pm_NW WindDir3pm_S WindDir3pm_SE WindDir3pm_SSE WindDir3pm_SSW WindDir3pm_SW WindDir3pm_W WindDir3pm_WNW WindDir3pm_WSW WindDir3pm_nan RainToday_No RainToday_Yes RainToday_nan . 2498 0.681604 | 0.801512 | 0.000000 | 0.037723 | 0.525852 | 0.372093 | 0.000000 | 0.080460 | 0.46 | 0.17 | 0.543802 | 0.5136 | 0.777778 | 0.333333 | 0.702532 | 0.808061 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2499 0.693396 | 0.725898 | 0.001078 | 0.037723 | 0.525852 | 0.341085 | 0.069231 | 0.195402 | 0.54 | 0.30 | 0.505785 | 0.5008 | 0.888889 | 0.888889 | 0.675105 | 0.712092 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2500 0.634434 | 0.527410 | 0.005930 | 0.037723 | 0.525852 | 0.325581 | 0.084615 | 0.448276 | 0.62 | 0.67 | 0.553719 | 0.6032 | 0.888889 | 0.888889 | 0.611814 | 0.477927 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 2501 0.608491 | 0.538752 | 0.042049 | 0.037723 | 0.525852 | 0.255814 | 0.069231 | 0.195402 | 0.74 | 0.65 | 0.618182 | 0.6304 | 0.888889 | 0.888889 | 0.556962 | 0.518234 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 2502 0.566038 | 0.523629 | 0.018329 | 0.037723 | 0.525852 | 0.193798 | 0.046154 | 0.103448 | 0.92 | 0.63 | 0.591736 | 0.5888 | 0.888889 | 0.888889 | 0.514768 | 0.529750 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 2503 0.601415 | 0.621928 | 0.000539 | 0.037723 | 0.525852 | 0.255814 | 0.069231 | 0.126437 | 0.76 | 0.52 | 0.563636 | 0.5680 | 0.888889 | 0.888889 | 0.580169 | 0.596929 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2504 0.587264 | 0.620038 | 0.000000 | 0.037723 | 0.525852 | 0.224806 | 0.153846 | 0.229885 | 0.46 | 0.31 | 0.609917 | 0.6176 | 0.493021 | 0.222222 | 0.592827 | 0.614203 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2505 0.537736 | 0.689981 | 0.000000 | 0.037723 | 0.525852 | 0.139535 | 0.084615 | 0.068966 | 0.63 | 0.24 | 0.646281 | 0.6416 | 0.493021 | 0.888889 | 0.561181 | 0.654511 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2506 0.594340 | 0.752363 | 0.000000 | 0.037723 | 0.525852 | 0.170543 | 0.084615 | 0.103448 | 0.52 | 0.24 | 0.629752 | 0.6144 | 0.493021 | 0.333333 | 0.662447 | 0.738964 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2507 0.620283 | 0.790170 | 0.000000 | 0.037723 | 0.525852 | 0.271318 | 0.069231 | 0.195402 | 0.54 | 0.17 | 0.596694 | 0.5680 | 0.493021 | 0.500352 | 0.704641 | 0.798464 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . Training and Visualizing Decision Trees . . useful blog :Visualize a Decision Tree in 4 Ways with Scikit-Learn and Python . Training . from sklearn.tree import DecisionTreeClassifier . model = DecisionTreeClassifier(random_state=42) # random state is provided to get same value each time . %%time model.fit(X_train, train_targets) . CPU times: user 2.93 s, sys: 12.6 ms, total: 2.94 s Wall time: 2.95 s . DecisionTreeClassifier(random_state=42) . Evaluation . from sklearn.metrics import accuracy_score, confusion_matrix . train_preds = model.predict(X_train) . train_preds . array([&#39;No&#39;, &#39;No&#39;, &#39;No&#39;, ..., &#39;No&#39;, &#39;No&#39;, &#39;No&#39;], dtype=object) . pd.value_counts(train_preds) . No 76707 Yes 22281 dtype: int64 . Decision tree also returns probabilities of each prediction . train_probs = model.predict_proba(X_train) . train_probs . array([[1., 0.], [1., 0.], [1., 0.], ..., [1., 0.], [1., 0.], [1., 0.]]) . train_targets . 0 No 1 No 2 No 3 No 4 No .. 144548 No 144549 No 144550 No 144551 No 144552 No Name: RainTomorrow, Length: 98988, dtype: object . accuracy_score(train_preds, train_targets) . 0.9999797955307714 . model.score(X_val, val_targets) # direct prediction on val inputs and compare accuracy #only ~79% . 0.7921188555510418 . val_targets.value_counts() / len(val_targets) . No 0.788289 Yes 0.211711 Name: RainTomorrow, dtype: float64 . It appears that the model has learned the training examples perfect, and doesn&#39;t generalize well to previously unseen examples. This phenomenon is called &quot;overfitting&quot;, and reducing overfitting is one of the most important parts of any machine learning project. . Visualizing Tree . from sklearn.tree import plot_tree, export_text . plt.figure(figsize=(80, 40)) plot_tree(model, feature_names=X_train.columns, max_depth=2, filled=True) . [Text(2232.0, 1902.6000000000001, &#39;Humidity3pm &lt;= 0.715 ngini = 0.349 nsamples = 98988 nvalue = [76705, 22283]&#39;), Text(1116.0, 1359.0, &#39;Rainfall &lt;= 0.004 ngini = 0.248 nsamples = 82418 nvalue = [70439, 11979]&#39;), Text(558.0, 815.4000000000001, &#39;Sunshine &lt;= 0.525 ngini = 0.198 nsamples = 69252 nvalue = [61538, 7714]&#39;), Text(279.0, 271.79999999999995, &#39; n (...) n&#39;), Text(837.0, 271.79999999999995, &#39; n (...) n&#39;), Text(1674.0, 815.4000000000001, &#39;Humidity3pm &lt;= 0.512 ngini = 0.438 nsamples = 13166 nvalue = [8901, 4265]&#39;), Text(1395.0, 271.79999999999995, &#39; n (...) n&#39;), Text(1953.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3348.0, 1359.0, &#39;Humidity3pm &lt;= 0.825 ngini = 0.47 nsamples = 16570 nvalue = [6266, 10304]&#39;), Text(2790.0, 815.4000000000001, &#39;WindGustSpeed &lt;= 0.279 ngini = 0.499 nsamples = 9136 nvalue = [4804, 4332]&#39;), Text(2511.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3069.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3906.0, 815.4000000000001, &#39;Rainfall &lt;= 0.01 ngini = 0.316 nsamples = 7434 nvalue = [1462, 5972]&#39;), Text(3627.0, 271.79999999999995, &#39; n (...) n&#39;), Text(4185.0, 271.79999999999995, &#39; n (...) n&#39;)] . How a Decision Tree is Created . Note the gini value in each box. This is the loss function used by the decision tree to decide which column should be used for splitting the data, and at what point the column should be split. A lower Gini index indicates a better split. A perfect split (only one class on each side) has a Gini index of 0. . For a mathematical discussion of the Gini Index, watch this video: It has the following formula: . . Conceptually speaking, while training the models evaluates all possible splits across all possible columns and picks the best one. Then, it recursively performs an optimal split for the two portions. In practice, however, it&#39;s very inefficient to check all possible splits, so the model uses a heuristic (predefined strategy) combined with some randomization. . Let&#39;s check the depth of the tree that was created. . model.tree_.max_depth . 48 . tree_text = export_text(model, max_depth=10, feature_names=list(X_train.columns)) print(tree_text[:5000]) . | Humidity3pm &lt;= 0.72 | | Rainfall &lt;= 0.00 | | | Sunshine &lt;= 0.52 | | | | Pressure3pm &lt;= 0.58 | | | | | WindGustSpeed &lt;= 0.36 | | | | | | Humidity3pm &lt;= 0.28 | | | | | | | WindDir9am_NE &lt;= 0.50 | | | | | | | | Location_Watsonia &lt;= 0.50 | | | | | | | | | Cloud9am &lt;= 0.83 | | | | | | | | | | WindSpeed3pm &lt;= 0.07 | | | | | | | | | | | Pressure3pm &lt;= 0.46 | | | | | | | | | | | | class: Yes | | | | | | | | | | | Pressure3pm &gt; 0.46 | | | | | | | | | | | | class: No | | | | | | | | | | WindSpeed3pm &gt; 0.07 | | | | | | | | | | | MinTemp &lt;= 0.32 | | | | | | | | | | | | truncated branch of depth 2 | | | | | | | | | | | MinTemp &gt; 0.32 | | | | | | | | | | | | truncated branch of depth 7 | | | | | | | | | Cloud9am &gt; 0.83 | | | | | | | | | | Cloud3pm &lt;= 0.42 | | | | | | | | | | | class: Yes | | | | | | | | | | Cloud3pm &gt; 0.42 | | | | | | | | | | | Rainfall &lt;= 0.00 | | | | | | | | | | | | truncated branch of depth 2 | | | | | | | | | | | Rainfall &gt; 0.00 | | | | | | | | | | | | class: Yes | | | | | | | | Location_Watsonia &gt; 0.50 | | | | | | | | | class: Yes | | | | | | | WindDir9am_NE &gt; 0.50 | | | | | | | | WindGustSpeed &lt;= 0.25 | | | | | | | | | class: No | | | | | | | | WindGustSpeed &gt; 0.25 | | | | | | | | | Pressure9am &lt;= 0.54 | | | | | | | | | | Evaporation &lt;= 0.09 | | | | | | | | | | | Location_AliceSprings &lt;= 0.50 | | | | | | | | | | | | truncated branch of depth 4 | | | | | | | | | | | Location_AliceSprings &gt; 0.50 | | | | | | | | | | | | class: Yes | | | | | | | | | | Evaporation &gt; 0.09 | | | | | | | | | | | WindGustDir_ENE &lt;= 0.50 | | | | | | | | | | | | class: Yes | | | | | | | | | | | WindGustDir_ENE &gt; 0.50 | | | | | | | | | | | | class: No | | | | | | | | | Pressure9am &gt; 0.54 | | | | | | | | | | Humidity3pm &lt;= 0.20 | | | | | | | | | | | class: Yes | | | | | | | | | | Humidity3pm &gt; 0.20 | | | | | | | | | | | Evaporation &lt;= 0.02 | | | | | | | | | | | | class: Yes | | | | | | | | | | | Evaporation &gt; 0.02 | | | | | | | | | | | | class: No | | | | | | Humidity3pm &gt; 0.28 | | | | | | | Sunshine &lt;= 0.05 | | | | | | | | WindGustSpeed &lt;= 0.25 | | | | | | | | | Evaporation &lt;= 0.01 | | | | | | | | | | WindGustSpeed &lt;= 0.23 | | | | | | | | | | | class: Yes | | | | | | | | | | WindGustSpeed &gt; 0.23 | | | | | | | | | | | class: No | | | | | | | | | Evaporation &gt; 0.01 | | | | | | | | | | Evaporation &lt;= 0.07 | | | | | | | | | | | Temp3pm &lt;= 0.34 | | | | | | | | | | | | class: Yes | | | | | | | | | | | Temp3pm &gt; 0.34 | | | | | | | | | | | | truncated branch of depth 11 | | | | | | | | | | Evaporation &gt; 0.07 | | | | | | | | | | | WindSpeed9am &lt;= 0.12 | | | | | | | | | | | | class: Yes | | | | | | | | | | | WindSpeed9am &gt; 0.12 | | | | | | | | | | | | class: No | | | | | | | | WindGustSpeed &gt; 0.25 | | | | | | | | | Pressure9am &lt;= 0.56 | | | | | | | | | | MinTemp &lt;= 0.40 | | | | | | | | | | | WindDir9am_WNW &lt;= 0.50 | | | | | | | | | | | | class: Yes | | | | | | | | | | | WindDir9am_WNW &gt; 0.50 | | | | | | | | | | | | class: No | | | | | | | | | | MinTemp &gt; 0.40 | | | | | | | | | | | Humidity3pm &lt;= 0.66 | | | | | | | | | | | | truncated branch of depth 7 | | | | | | | | | | | Humidity3pm &gt; 0.66 | | | | | | | | | | | | truncated branch of depth 4 | | | | | | | | | Pressure9am &gt; 0.56 | | | | | . Feature Importance . X_train.columns . Index([&#39;MinTemp&#39;, &#39;MaxTemp&#39;, &#39;Rainfall&#39;, &#39;Evaporation&#39;, &#39;Sunshine&#39;, &#39;WindGustSpeed&#39;, &#39;WindSpeed9am&#39;, &#39;WindSpeed3pm&#39;, &#39;Humidity9am&#39;, &#39;Humidity3pm&#39;, ... &#39;WindDir3pm_SSE&#39;, &#39;WindDir3pm_SSW&#39;, &#39;WindDir3pm_SW&#39;, &#39;WindDir3pm_W&#39;, &#39;WindDir3pm_WNW&#39;, &#39;WindDir3pm_WSW&#39;, &#39;WindDir3pm_nan&#39;, &#39;RainToday_No&#39;, &#39;RainToday_Yes&#39;, &#39;RainToday_nan&#39;], dtype=&#39;object&#39;, length=119) . model.feature_importances_ . array([3.48942086e-02, 3.23605486e-02, 5.91385668e-02, 2.49619907e-02, 4.94652143e-02, 5.63334673e-02, 2.80205998e-02, 2.98128801e-02, 4.02182908e-02, 2.61441297e-01, 3.44145027e-02, 6.20573699e-02, 1.36406176e-02, 1.69229866e-02, 3.50001550e-02, 3.04064076e-02, 2.24086587e-03, 2.08018104e-03, 1.27475954e-03, 7.26936324e-04, 1.39779517e-03, 1.15264873e-03, 6.92808159e-04, 1.80675598e-03, 1.08370901e-03, 1.19773895e-03, 8.87119103e-04, 2.15764220e-03, 1.67094731e-03, 7.98919493e-05, 1.10558668e-03, 1.42008656e-03, 4.10087635e-04, 1.09028115e-03, 1.44164766e-03, 9.08284767e-04, 1.05770304e-03, 6.18133455e-04, 1.80387272e-03, 2.10403527e-03, 2.74413333e-04, 7.31599405e-04, 1.35408990e-03, 1.54759332e-03, 1.30917564e-03, 1.07134670e-03, 8.36408023e-04, 1.62662229e-03, 1.00326116e-03, 2.16053455e-03, 8.46802258e-04, 1.88919081e-03, 9.29325203e-04, 1.29545157e-03, 1.27604831e-03, 5.12736888e-04, 1.38458902e-03, 3.97103931e-04, 1.03734689e-03, 1.44437047e-03, 1.75870184e-03, 1.42487857e-03, 2.78109569e-03, 2.00782698e-03, 2.80617652e-04, 1.61509734e-03, 1.64361598e-03, 2.36124112e-03, 3.05457932e-03, 2.33239534e-03, 2.78643875e-03, 2.16695261e-03, 3.41491352e-03, 2.30573542e-03, 2.28270604e-03, 2.34408118e-03, 2.26557332e-03, 2.54592702e-03, 2.75264499e-03, 2.83905192e-03, 2.49480561e-03, 1.54840338e-03, 2.50305095e-03, 2.53945388e-03, 2.28130055e-03, 3.80572180e-03, 2.58535069e-03, 3.10172224e-03, 2.54236791e-03, 2.50297796e-03, 2.06400988e-03, 2.52931192e-03, 2.07840517e-03, 1.77387278e-03, 1.78920555e-03, 2.77709687e-03, 2.42564566e-03, 2.26471887e-03, 1.73346117e-03, 2.23926957e-03, 2.47865244e-03, 2.31917387e-03, 3.21211861e-03, 2.92382975e-03, 2.24399274e-03, 3.68774754e-03, 3.87595982e-03, 3.20326068e-03, 2.53323550e-03, 2.40444844e-03, 2.26790411e-03, 2.19744009e-03, 2.28064147e-03, 2.88545323e-03, 2.05278867e-03, 1.12604304e-03, 2.86325849e-04, 1.32322128e-03, 1.72690480e-03]) . importance_df = pd.DataFrame({ &#39;feature&#39;: X_train.columns, &#39;importance&#39;: model.feature_importances_ }).sort_values(&#39;importance&#39;, ascending=False) . importance_df.head(10) . feature importance . 9 Humidity3pm | 0.261441 | . 11 Pressure3pm | 0.062057 | . 2 Rainfall | 0.059139 | . 5 WindGustSpeed | 0.056333 | . 4 Sunshine | 0.049465 | . 8 Humidity9am | 0.040218 | . 14 Temp9am | 0.035000 | . 0 MinTemp | 0.034894 | . 10 Pressure9am | 0.034415 | . 1 MaxTemp | 0.032361 | . plt.title(&#39;Feature Importance&#39;) sns.barplot(data=importance_df.head(10), x=&#39;importance&#39;, y=&#39;feature&#39;); . Hyperparameter Tuning and Overfitting . ?DecisionTreeClassifier . As we saw in the previous section, our decision tree classifier memorized all training examples, leading to a 100% training accuracy, while the validation accuracy was only marginally better than a dumb baseline model. This phenomenon is called overfitting, and in this section, we&#39;ll look at some strategies for reducing overfitting. The process of reducing overfitting is known as regularlization. . The DecisionTreeClassifier accepts several arguments, some of which can be modified to reduce overfitting. . These arguments are called hyperparameters because they must be configured manually (as opposed to the parameters within the model which are learned from the data. We&#39;ll explore a couple of hyperparameters: . max_depth | max_leaf_nodes | . max_depth . By reducing the maximum depth of the decision tree, we can prevent the tree from memorizing all training examples, which may lead to better generalization . model = DecisionTreeClassifier(max_depth=3, random_state=42) . model.fit(X_train, train_targets) . DecisionTreeClassifier(max_depth=3, random_state=42) . model.score(X_train, train_targets) . 0.8291308037337859 . model.score(X_val, val_targets) . 0.8334397307178921 . model.classes_ . array([&#39;No&#39;, &#39;Yes&#39;], dtype=object) . Great, while the training accuracy of the model has gone down, the validation accuracy of the model has increased significantly. . plt.figure(figsize=(80, 40)) plot_tree(model, feature_names=X_train.columns, filled=True, rounded=True, class_names=model.classes_) . [Text(2232.0, 1902.6000000000001, &#39;Humidity3pm &lt;= 0.715 ngini = 0.349 nsamples = 98988 nvalue = [76705, 22283] nclass = No&#39;), Text(1116.0, 1359.0, &#39;Rainfall &lt;= 0.004 ngini = 0.248 nsamples = 82418 nvalue = [70439, 11979] nclass = No&#39;), Text(558.0, 815.4000000000001, &#39;Sunshine &lt;= 0.525 ngini = 0.198 nsamples = 69252 nvalue = [61538, 7714] nclass = No&#39;), Text(279.0, 271.79999999999995, &#39;gini = 0.363 nsamples = 12620 nvalue = [9618, 3002] nclass = No&#39;), Text(837.0, 271.79999999999995, &#39;gini = 0.153 nsamples = 56632 nvalue = [51920, 4712] nclass = No&#39;), Text(1674.0, 815.4000000000001, &#39;Humidity3pm &lt;= 0.512 ngini = 0.438 nsamples = 13166 nvalue = [8901, 4265] nclass = No&#39;), Text(1395.0, 271.79999999999995, &#39;gini = 0.293 nsamples = 4299 nvalue = [3531, 768] nclass = No&#39;), Text(1953.0, 271.79999999999995, &#39;gini = 0.478 nsamples = 8867 nvalue = [5370, 3497] nclass = No&#39;), Text(3348.0, 1359.0, &#39;Humidity3pm &lt;= 0.825 ngini = 0.47 nsamples = 16570 nvalue = [6266, 10304] nclass = Yes&#39;), Text(2790.0, 815.4000000000001, &#39;WindGustSpeed &lt;= 0.279 ngini = 0.499 nsamples = 9136 nvalue = [4804, 4332] nclass = No&#39;), Text(2511.0, 271.79999999999995, &#39;gini = 0.472 nsamples = 5583 nvalue = [3457, 2126] nclass = No&#39;), Text(3069.0, 271.79999999999995, &#39;gini = 0.471 nsamples = 3553 nvalue = [1347, 2206] nclass = Yes&#39;), Text(3906.0, 815.4000000000001, &#39;Rainfall &lt;= 0.01 ngini = 0.316 nsamples = 7434 nvalue = [1462, 5972] nclass = Yes&#39;), Text(3627.0, 271.79999999999995, &#39;gini = 0.391 nsamples = 4360 nvalue = [1161, 3199] nclass = Yes&#39;), Text(4185.0, 271.79999999999995, &#39;gini = 0.177 nsamples = 3074 nvalue = [301, 2773] nclass = Yes&#39;)] . print(export_text(model, feature_names=list(X_train.columns))) . | Humidity3pm &lt;= 0.72 | | Rainfall &lt;= 0.00 | | | Sunshine &lt;= 0.52 | | | | class: No | | | Sunshine &gt; 0.52 | | | | class: No | | Rainfall &gt; 0.00 | | | Humidity3pm &lt;= 0.51 | | | | class: No | | | Humidity3pm &gt; 0.51 | | | | class: No | Humidity3pm &gt; 0.72 | | Humidity3pm &lt;= 0.82 | | | WindGustSpeed &lt;= 0.28 | | | | class: No | | | WindGustSpeed &gt; 0.28 | | | | class: Yes | | Humidity3pm &gt; 0.82 | | | Rainfall &lt;= 0.01 | | | | class: Yes | | | Rainfall &gt; 0.01 | | | | class: Yes . def max_depth_error(md): model = DecisionTreeClassifier(max_depth=md, random_state=42) model.fit(X_train, train_targets) train_error = 1 - model.score(X_train, train_targets) val_error = 1 - model.score(X_val, val_targets) return {&#39;Max Depth&#39;: md, &#39;Training Error&#39;: train_error, &#39;Validation Error&#39;: val_error} . %%time errors_df = pd.DataFrame([max_depth_error(md) for md in range(1, 21)]) . CPU times: user 26.4 s, sys: 225 ms, total: 26.6 s Wall time: 26.7 s . errors_df . Max Depth Training Error Validation Error . 0 1 | 0.184315 | 0.177935 | . 1 2 | 0.179547 | 0.172712 | . 2 3 | 0.170869 | 0.166560 | . 3 4 | 0.165707 | 0.164355 | . 4 5 | 0.160676 | 0.159074 | . 5 6 | 0.156271 | 0.157275 | . 6 7 | 0.153312 | 0.154605 | . 7 8 | 0.147806 | 0.158029 | . 8 9 | 0.140906 | 0.156578 | . 9 10 | 0.132945 | 0.157333 | . 10 11 | 0.123227 | 0.159248 | . 11 12 | 0.113489 | 0.160815 | . 12 13 | 0.101750 | 0.163833 | . 13 14 | 0.089981 | 0.167373 | . 14 15 | 0.078999 | 0.171261 | . 15 16 | 0.068180 | 0.174279 | . 16 17 | 0.058138 | 0.176890 | . 17 18 | 0.048733 | 0.181243 | . 18 19 | 0.040025 | 0.187569 | . 19 20 | 0.032539 | 0.190297 | . plt.figure() plt.plot(errors_df[&#39;Max Depth&#39;], errors_df[&#39;Training Error&#39;]) plt.plot(errors_df[&#39;Max Depth&#39;], errors_df[&#39;Validation Error&#39;]) plt.title(&quot;Training vs Validation Error&quot;) plt.xticks(range(0,21,2)) plt.xlabel(&#39;Max. Depth&#39;) plt.ylabel(&#39;Prediction Error ie 1-Accuracy&#39;) plt.legend([&#39;Training&#39;, &#39;Validation&#39;]) . &lt;matplotlib.legend.Legend at 0x7f1fcb8fd3a0&gt; . . So for us max depth of 7 results in lowest validation error . model = DecisionTreeClassifier(max_depth=7, random_state=42).fit(X_train, train_targets) model.score(X_val, val_targets), model.score(X_train, train_targets) . (0.8453949277465034, 0.8466884874934335) . max_leaf_nodes . Another way to control the size of complexity of a decision tree is to limit the number of leaf nodes. This allows branches of the tree to have varying depths. . model = DecisionTreeClassifier(max_leaf_nodes = 128, random_state = 42) . model.fit(X_train, train_targets) . DecisionTreeClassifier(max_leaf_nodes=128, random_state=42) . model.score(X_train, train_targets) . 0.8480421869317493 . model.score(X_val, val_targets) . 0.8442342290058615 . model.tree_.max_depth . 12 . Notice that the model was able to achieve a greater depth of 12 for certain paths while keeping other paths shorter. . model_text = export_text(model, feature_names = list(X_train.columns)) print(model_text[:3000]) . | Humidity3pm &lt;= 0.72 | | Rainfall &lt;= 0.00 | | | Sunshine &lt;= 0.52 | | | | Pressure3pm &lt;= 0.58 | | | | | WindGustSpeed &lt;= 0.36 | | | | | | Humidity3pm &lt;= 0.28 | | | | | | | class: No | | | | | | Humidity3pm &gt; 0.28 | | | | | | | Sunshine &lt;= 0.05 | | | | | | | | class: Yes | | | | | | | Sunshine &gt; 0.05 | | | | | | | | Pressure3pm &lt;= 0.43 | | | | | | | | | class: Yes | | | | | | | | Pressure3pm &gt; 0.43 | | | | | | | | | Humidity3pm &lt;= 0.57 | | | | | | | | | | WindDir9am_NE &lt;= 0.50 | | | | | | | | | | | WindDir9am_NNE &lt;= 0.50 | | | | | | | | | | | | class: No | | | | | | | | | | | WindDir9am_NNE &gt; 0.50 | | | | | | | | | | | | class: No | | | | | | | | | | WindDir9am_NE &gt; 0.50 | | | | | | | | | | | class: Yes | | | | | | | | | Humidity3pm &gt; 0.57 | | | | | | | | | | MaxTemp &lt;= 0.53 | | | | | | | | | | | class: No | | | | | | | | | | MaxTemp &gt; 0.53 | | | | | | | | | | | Temp3pm &lt;= 0.67 | | | | | | | | | | | | class: No | | | | | | | | | | | Temp3pm &gt; 0.67 | | | | | | | | | | | | class: No | | | | | WindGustSpeed &gt; 0.36 | | | | | | Humidity3pm &lt;= 0.45 | | | | | | | Sunshine &lt;= 0.39 | | | | | | | | class: No | | | | | | | Sunshine &gt; 0.39 | | | | | | | | class: No | | | | | | Humidity3pm &gt; 0.45 | | | | | | | Pressure3pm &lt;= 0.49 | | | | | | | | class: Yes | | | | | | | Pressure3pm &gt; 0.49 | | | | | | | | class: Yes | | | | Pressure3pm &gt; 0.58 | | | | | Pressure3pm &lt;= 0.70 | | | | | | Sunshine &lt;= 0.32 | | | | | | | WindDir9am_N &lt;= 0.50 | | | | | | | | Humidity3pm &lt;= 0.67 | | | | | | | | | class: No | | | | | | | | Humidity3pm &gt; 0.67 | | | | | | | | | class: No | | | | | | | WindDir9am_N &gt; 0.50 | | | | | | | | class: No | | | | | | Sunshine &gt; 0.32 | | | | | | | WindGustSpeed &lt;= 0.33 | | | | | | | | class: No | | | | | | | WindGustSpeed &gt; 0.33 | | | | | | | | class: No | | | | | Pressure3pm &gt; 0.70 | | | | | | Location_CoffsHarbour &lt;= 0.50 | | | | | | | class: No | | | | | | Location_CoffsHarbour &gt; 0.50 | | | | | | | class: No | | | Sunshine &gt; 0.52 | | | . Random Forest with Ausstralia Rain Dataset . While tuning the hyperparameters of a single decision tree may lead to some improvements, a much more effective strategy is to combine the results of several decision trees trained with slightly different parameters. This is called a random forest model. . The key idea here is that each decision tree in the forest will make different kinds of errors, and upon averaging, many of their errors will cancel out. . A random forest works by averaging/combining the results of several decision trees: . . . We&#39;ll use the RandomForestClassifier class from sklearn.ensemble. . from sklearn.ensemble import RandomForestClassifier . model = RandomForestClassifier(n_jobs = -1, random_state=42) # n_jobs= -1 to train in parallel . %%time model.fit(X_train, train_targets) . CPU times: user 38.8 s, sys: 156 ms, total: 39 s Wall time: 4.13 s . RandomForestClassifier(n_jobs=-1, random_state=42) . model.score(X_train, train_targets) . 0.9999494888269285 . model.score(X_val, val_targets) . 0.8566537055307295 . Once again, the training accuracy is almost 100%, but this time the validation accuracy is much better. In fact, it is better than the best single decision tree we had trained so far. Do you see the power of random forests? . This general technique of combining the results of many models is called &quot;ensembling&quot;, it works because most errors of individual models cancel out on averaging. Here&#39;s what it looks like visually: . . We can also look at the probabilities for the predictions. The probability of a class is simply the fraction of trees which that predicted the given class. . train_probs = model.predict_proba(X_train) . train_preds . array([&#39;No&#39;, &#39;No&#39;, &#39;No&#39;, ..., &#39;No&#39;, &#39;No&#39;, &#39;No&#39;], dtype=object) . train_probs . array([[0.93, 0.07], [1. , 0. ], [0.99, 0.01], ..., [0.99, 0.01], [1. , 0. ], [0.96, 0.04]]) . model.estimators_[0] . DecisionTreeClassifier(max_features=&#39;auto&#39;, random_state=1608637542) . len(model.estimators_) . 100 . plt.figure(figsize=(80,40)) plot_tree(model.estimators_[0], max_depth=2, feature_names=X_train.columns, filled=True, class_names=model.classes_) . [Text(2232.0, 1902.6000000000001, &#39;Sunshine &lt;= 0.403 ngini = 0.347 nsamples = 62607 nvalue = [76887, 22101] nclass = No&#39;), Text(1116.0, 1359.0, &#39;Pressure9am &lt;= 0.609 ngini = 0.499 nsamples = 11288 nvalue = [9272, 8542] nclass = No&#39;), Text(558.0, 815.4000000000001, &#39;Cloud9am &lt;= 0.833 ngini = 0.475 nsamples = 6067 nvalue = [3702, 5808] nclass = Yes&#39;), Text(279.0, 271.79999999999995, &#39; n (...) n&#39;), Text(837.0, 271.79999999999995, &#39; n (...) n&#39;), Text(1674.0, 815.4000000000001, &#39;WindGustDir_NNE &lt;= 0.5 ngini = 0.442 nsamples = 5221 nvalue = [5570, 2734] nclass = No&#39;), Text(1395.0, 271.79999999999995, &#39; n (...) n&#39;), Text(1953.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3348.0, 1359.0, &#39;RainToday_Yes &lt;= 0.5 ngini = 0.278 nsamples = 51319 nvalue = [67615, 13559] nclass = No&#39;), Text(2790.0, 815.4000000000001, &#39;Pressure9am &lt;= 0.521 ngini = 0.207 nsamples = 41960 nvalue = [58514, 7796] nclass = No&#39;), Text(2511.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3069.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3906.0, 815.4000000000001, &#39;Pressure9am &lt;= 0.614 ngini = 0.475 nsamples = 9359 nvalue = [9101, 5763] nclass = No&#39;), Text(3627.0, 271.79999999999995, &#39; n (...) n&#39;), Text(4185.0, 271.79999999999995, &#39; n (...) n&#39;)] . plt.figure(figsize=(80,40)) plot_tree(model.estimators_[40], max_depth=2, feature_names=X_train.columns, filled=True, class_names=model.classes_) . [Text(2232.0, 1902.6000000000001, &#39;Cloud9am &lt;= 0.722 ngini = 0.35 nsamples = 62556 nvalue = [76638, 22350] nclass = No&#39;), Text(1116.0, 1359.0, &#39;RainToday_No &lt;= 0.5 ngini = 0.291 nsamples = 48000 nvalue = [62502, 13407] nclass = No&#39;), Text(558.0, 815.4000000000001, &#39;Evaporation &lt;= 0.038 ngini = 0.483 nsamples = 9005 nvalue = [8394, 5804] nclass = No&#39;), Text(279.0, 271.79999999999995, &#39; n (...) n&#39;), Text(837.0, 271.79999999999995, &#39; n (...) n&#39;), Text(1674.0, 815.4000000000001, &#39;Pressure9am &lt;= 0.517 ngini = 0.216 nsamples = 38995 nvalue = [54108, 7603] nclass = No&#39;), Text(1395.0, 271.79999999999995, &#39; n (...) n&#39;), Text(1953.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3348.0, 1359.0, &#39;Humidity3pm &lt;= 0.755 ngini = 0.475 nsamples = 14556 nvalue = [14136, 8943] nclass = No&#39;), Text(2790.0, 815.4000000000001, &#39;Rainfall &lt;= 0.004 ngini = 0.388 nsamples = 10894 nvalue = [12707, 4538] nclass = No&#39;), Text(2511.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3069.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3906.0, 815.4000000000001, &#39;Temp9am &lt;= 0.37 ngini = 0.37 nsamples = 3662 nvalue = [1429, 4405] nclass = Yes&#39;), Text(3627.0, 271.79999999999995, &#39; n (...) n&#39;), Text(4185.0, 271.79999999999995, &#39; n (...) n&#39;)] . Random forest also assign importance to each feature, by combining the importance values from individual trees . imortance_df = pd.DataFrame({ &#39;feature&#39;: X_train.columns, &#39;importance&#39;: model.feature_importances_ }).sort_values(&#39;importance&#39;, ascending=False) . importance_df.head(10) . feature importance . 9 Humidity3pm | 0.261441 | . 11 Pressure3pm | 0.062057 | . 2 Rainfall | 0.059139 | . 5 WindGustSpeed | 0.056333 | . 4 Sunshine | 0.049465 | . 8 Humidity9am | 0.040218 | . 14 Temp9am | 0.035000 | . 0 MinTemp | 0.034894 | . 10 Pressure9am | 0.034415 | . 1 MaxTemp | 0.032361 | . plt.title(&#39;importance of features&#39;) sns.barplot(data=importance_df.head(10), x=&#39;importance&#39;, y=&#39;feature&#39;) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;importance of features&#39;}, xlabel=&#39;importance&#39;, ylabel=&#39;feature&#39;&gt; . Hyperparameter Tuning with Random Forests . Docs of RF Hyperparameters . ?RandomForestClassifier . base_model = RandomForestClassifier(random_state=42, n_jobs=-1).fit(X_train, train_targets) . base_train_acc = base_model.score(X_train, train_targets) base_train_acc . 0.9999494888269285 . base_val_acc = base_model.score(X_val, val_targets) base_val_acc . 0.8566537055307295 . base_accs = base_train_acc, base_val_acc . n_estimators . This argument controls the number of decision trees in the random forest. The default value is 100. For larger datasets, it helps to have a greater number of estimators. As a general rule, try to have as few estimators as needed. . 10 estimators . model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=10) . model.fit(X_train, train_targets) . RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state=42) . model.score(X_train, train_targets), model.score(X_val, val_targets) . (0.986958015112943, 0.8485868492832686) . base_accs . (0.9999494888269285, 0.8566537055307295) . 500 estimators . model = RandomForestClassifier(random_state=42, n_jobs=-1, n_estimators=500) . model.fit(X_train, train_targets) . RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42) . model.score(X_train, train_targets), model.score(X_val, val_targets) . (0.9999797955307714, 0.8577563693343393) . base_accs . (0.9999494888269285, 0.8566537055307295) . max_depth and max_leaf_nodes . These arguments are passed directly to each decision tree, and control the maximum depth and max. no leaf nodes of each tree respectively. By default, no maximum depth is specified, which is why each tree has a training accuracy of 100%. You can specify a max_depth to reduce overfitting. . . Let&#39;s define a helper function test_params to make it easy to test hyperparameters. . def test_params(**params): model = RandomForestClassifier(random_state=42, n_jobs=-1, **params).fit(X_train, train_targets) return model.score(X_train, train_targets), model.score(X_val, val_targets) . test_params(max_depth=5, max_leaf_nodes=1024, n_estimators=1000) . (0.8231704853113508, 0.8279264116998433) . test_params(max_depth=26) . (0.9814826039519942, 0.8572340549010504) . test_params(max_leaf_nodes=2**5) . (0.8314341132258456, 0.833904010214149) . test_params(max_leaf_nodes=2**20) . (0.9999494888269285, 0.8556671116011839) . base_accs . (0.9999494888269285, 0.8566537055307295) . max_features . Instead of picking all features (columns) for every split, we can specify that only a fraction of features be chosen randomly to figure out a split. . . Notice that the default value auto causes only $ sqrt{n}$ out of total features ( $n$ ) to be chosen randomly at each split. This is the reason each decision tree in the forest is different. While it may seem counterintuitive, choosing all features for every split of every tree will lead to identical trees, so the random forest will not generalize well. . test_params(max_features=&#39;log2&#39;) . (0.9999595910615429, 0.8558992513493123) . test_params(max_features=3) . (0.9999494888269285, 0.8543323080494458) . test_params(max_features=20) . (0.9999595910615429, 0.8565956705936975) . base_accs . (0.9999494888269285, 0.8566537055307295) . min_samples_split and min_sample_leaf . By default, the decision tree classifier tries to split every node that has 2 or more. You can increase the values of these arguments to change this behavior and reduce overfitting, especially for very large datasets. . test_params(min_samples_split=3, min_samples_leaf=2) . (0.9625005051117307, 0.8565956705936975) . test_params(min_samples_split=100, min_samples_leaf=60) . (0.8495676243585081, 0.8451047530613429) . base_accs . (0.9999494888269285, 0.8566537055307295) . min_impurity_decrease . This argument is used to control the threshold for splitting nodes. A node will be split if this split induces a decrease of the impurity (Gini index) greater than or equal to this value. It&#39;s default value is 0, and you can increase it to reduce overfitting. . test_params(min_impurity_decrease=1e-7) . (0.9996060128500425, 0.8561313910974406) . test_params(min_impurity_decrease=1e-2) . (0.774891906089627, 0.7882885497069235) . base_accs . (0.9999494888269285, 0.8566537055307295) . bootstrap, max_samples . By default, a random forest doesn&#39;t use the entire dataset for training each decision tree. Instead it applies a technique called bootstrapping. For each tree, rows from the dataset are picked one by one randomly, with replacement i.e. some rows may not show up at all, while some rows may show up multiple times. . . Bootstrapping helps the random forest generalize better, because each decision tree only sees a fraction of th training set, and some rows randomly get higher weightage than others. . test_params(bootstrap=False) . (0.9999797955307714, 0.8567697754047937) . base_accs . (0.9999494888269285, 0.8566537055307295) . When bootstrapping is enabled, you can also control the number or fraction of rows to be considered for each bootstrap using max_samples. This can further generalize the model. . . test_params(max_samples=0.9) . (0.9997676486038711, 0.8565376356566653) . base_accs . (0.9999494888269285, 0.8566537055307295) . Learn more about bootstrapping here: https://towardsdatascience.com/what-is-out-of-bag-oob-score-in-random-forest-a7fa23d710 . class_weight . model.classes_ . array([&#39;No&#39;, &#39;Yes&#39;], dtype=object) . test_params(class_weight=&#39;balanced&#39;) . (0.9999494888269285, 0.8543903429864779) . test_params(class_weight={&#39;No&#39;: 1, &#39;Yes&#39;: 2}) . (0.9999595910615429, 0.8558412164122802) . base_accs . (0.9999494888269285, 0.8566537055307295) . Putting it together . model = RandomForestClassifier(n_jobs=-1, random_state=42, n_estimators=500, max_features=7, max_depth=30, class_weight={&#39;No&#39;: 1, &#39;Yes&#39;: 1.5}) . model.fit(X_train, train_targets) . RandomForestClassifier(class_weight={&#39;No&#39;: 1, &#39;Yes&#39;: 1.5}, max_depth=30, max_features=7, n_estimators=500, n_jobs=-1, random_state=42) . model.score(X_train, train_targets), model.score(X_val, val_targets) . (0.9920192346547057, 0.8563054959085369) . base_accs . (0.9999494888269285, 0.8566537055307295) . model.score(X_test, test_targets) . 0.8451913451913452 . Making Predictions on New Inputs . def predict_input(model, single_input): input_df = pd.DataFrame([single_input]) input_df[numeric_cols] = imputer.transform(input_df[numeric_cols]) input_df[numeric_cols] = scaler.transform(input_df[numeric_cols]) input_df[encoded_cols] = encoder.transform(input_df[categorical_cols]) X_input = input_df[numeric_cols + encoded_cols] pred = model.predict(X_input)[0] prob = model.predict_proba(X_input)[0][list(model.classes_).index(pred)] return pred, prob . new_input = {&#39;Date&#39;: &#39;2021-06-19&#39;, &#39;Location&#39;: &#39;Launceston&#39;, &#39;MinTemp&#39;: 23.2, &#39;MaxTemp&#39;: 33.2, &#39;Rainfall&#39;: 10.2, &#39;Evaporation&#39;: 4.2, &#39;Sunshine&#39;: np.nan, &#39;WindGustDir&#39;: &#39;NNW&#39;, &#39;WindGustSpeed&#39;: 52.0, &#39;WindDir9am&#39;: &#39;NW&#39;, &#39;WindDir3pm&#39;: &#39;NNE&#39;, &#39;WindSpeed9am&#39;: 13.0, &#39;WindSpeed3pm&#39;: 20.0, &#39;Humidity9am&#39;: 89.0, &#39;Humidity3pm&#39;: 58.0, &#39;Pressure9am&#39;: 1004.8, &#39;Pressure3pm&#39;: 1001.5, &#39;Cloud9am&#39;: 8.0, &#39;Cloud3pm&#39;: 5.0, &#39;Temp9am&#39;: 25.7, &#39;Temp3pm&#39;: 33.0, &#39;RainToday&#39;: &#39;Yes&#39;} . predict_input(model, new_input) . (&#39;Yes&#39;, 0.7608595348304202) . raw_df.Location.unique() . array([&#39;Albury&#39;, &#39;BadgerysCreek&#39;, &#39;Cobar&#39;, &#39;CoffsHarbour&#39;, &#39;Moree&#39;, &#39;Newcastle&#39;, &#39;NorahHead&#39;, &#39;NorfolkIsland&#39;, &#39;Penrith&#39;, &#39;Richmond&#39;, &#39;Sydney&#39;, &#39;SydneyAirport&#39;, &#39;WaggaWagga&#39;, &#39;Williamtown&#39;, &#39;Wollongong&#39;, &#39;Canberra&#39;, &#39;Tuggeranong&#39;, &#39;MountGinini&#39;, &#39;Ballarat&#39;, &#39;Bendigo&#39;, &#39;Sale&#39;, &#39;MelbourneAirport&#39;, &#39;Melbourne&#39;, &#39;Mildura&#39;, &#39;Nhil&#39;, &#39;Portland&#39;, &#39;Watsonia&#39;, &#39;Dartmoor&#39;, &#39;Brisbane&#39;, &#39;Cairns&#39;, &#39;GoldCoast&#39;, &#39;Townsville&#39;, &#39;Adelaide&#39;, &#39;MountGambier&#39;, &#39;Nuriootpa&#39;, &#39;Woomera&#39;, &#39;Albany&#39;, &#39;Witchcliffe&#39;, &#39;PearceRAAF&#39;, &#39;PerthAirport&#39;, &#39;Perth&#39;, &#39;SalmonGums&#39;, &#39;Walpole&#39;, &#39;Hobart&#39;, &#39;Launceston&#39;, &#39;AliceSprings&#39;, &#39;Darwin&#39;, &#39;Katherine&#39;, &#39;Uluru&#39;], dtype=object) . Saving and Loading Trained Models . import joblib . aussie_rain = { &#39;model&#39;: model, &#39;imputer&#39;: imputer, &#39;scaler&#39;: scaler, &#39;encoder&#39;: encoder, &#39;input_cols&#39;: input_cols, &#39;target_col&#39;: target_cols, &#39;numeric_cols&#39;: numeric_cols, &#39;categorical_cols&#39;: categorical_cols, &#39;encoded_cols&#39;: encoded_cols } . joblib.dump(aussie_rain, &#39;aussie_rain.joblib&#39;) . [&#39;aussie_rain.joblib&#39;] . aussie_rain2 = joblib.load(&#39;aussie_rain.joblib&#39;) . test_preds2 = aussie_rain2[&#39;model&#39;].predict(X_test) accuracy_score(test_targets, test_preds2) . 0.8451913451913452 .",
            "url": "https://mr-siddy.github.io/ML-blog/ml/2021/05/17/Decision-Trees-Random-Forests.html",
            "relUrl": "/ml/2021/05/17/Decision-Trees-Random-Forests.html",
            "date": " • May 17, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "Decision Trees using Ausstralia Rain Dataset",
            "content": "import opendatasets as od import numpy as np import pandas as pd import matplotlib import matplotlib.pyplot as plt import seaborn as sns import os %matplotlib inline pd.set_option(&#39;display.max_columns&#39;, None) pd.set_option(&#39;display.max_rows&#39;, 150) sns.set_style(&#39;darkgrid&#39;) matplotlib.rcParams[&#39;font.size&#39;] = 14 matplotlib.rcParams[&#39;figure.figsize&#39;] = (10, 6) matplotlib.rcParams[&#39;figure.facecolor&#39;] = &#39;#00000000&#39; . os.listdir(&#39;weather-dataset-rattle-package&#39;) . [&#39;weatherAUS.csv&#39;] . raw_df = pd.read_csv(&#39;weather-dataset-rattle-package/weatherAUS.csv&#39;) . raw_df.head(10) . Date Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday RainTomorrow . 0 2008-12-01 | Albury | 13.4 | 22.9 | 0.6 | NaN | NaN | W | 44.0 | W | WNW | 20.0 | 24.0 | 71.0 | 22.0 | 1007.7 | 1007.1 | 8.0 | NaN | 16.9 | 21.8 | No | No | . 1 2008-12-02 | Albury | 7.4 | 25.1 | 0.0 | NaN | NaN | WNW | 44.0 | NNW | WSW | 4.0 | 22.0 | 44.0 | 25.0 | 1010.6 | 1007.8 | NaN | NaN | 17.2 | 24.3 | No | No | . 2 2008-12-03 | Albury | 12.9 | 25.7 | 0.0 | NaN | NaN | WSW | 46.0 | W | WSW | 19.0 | 26.0 | 38.0 | 30.0 | 1007.6 | 1008.7 | NaN | 2.0 | 21.0 | 23.2 | No | No | . 3 2008-12-04 | Albury | 9.2 | 28.0 | 0.0 | NaN | NaN | NE | 24.0 | SE | E | 11.0 | 9.0 | 45.0 | 16.0 | 1017.6 | 1012.8 | NaN | NaN | 18.1 | 26.5 | No | No | . 4 2008-12-05 | Albury | 17.5 | 32.3 | 1.0 | NaN | NaN | W | 41.0 | ENE | NW | 7.0 | 20.0 | 82.0 | 33.0 | 1010.8 | 1006.0 | 7.0 | 8.0 | 17.8 | 29.7 | No | No | . 5 2008-12-06 | Albury | 14.6 | 29.7 | 0.2 | NaN | NaN | WNW | 56.0 | W | W | 19.0 | 24.0 | 55.0 | 23.0 | 1009.2 | 1005.4 | NaN | NaN | 20.6 | 28.9 | No | No | . 6 2008-12-07 | Albury | 14.3 | 25.0 | 0.0 | NaN | NaN | W | 50.0 | SW | W | 20.0 | 24.0 | 49.0 | 19.0 | 1009.6 | 1008.2 | 1.0 | NaN | 18.1 | 24.6 | No | No | . 7 2008-12-08 | Albury | 7.7 | 26.7 | 0.0 | NaN | NaN | W | 35.0 | SSE | W | 6.0 | 17.0 | 48.0 | 19.0 | 1013.4 | 1010.1 | NaN | NaN | 16.3 | 25.5 | No | No | . 8 2008-12-09 | Albury | 9.7 | 31.9 | 0.0 | NaN | NaN | NNW | 80.0 | SE | NW | 7.0 | 28.0 | 42.0 | 9.0 | 1008.9 | 1003.6 | NaN | NaN | 18.3 | 30.2 | No | Yes | . 9 2008-12-10 | Albury | 13.1 | 30.1 | 1.4 | NaN | NaN | W | 28.0 | S | SSE | 15.0 | 11.0 | 58.0 | 27.0 | 1007.0 | 1005.7 | NaN | NaN | 20.1 | 28.2 | Yes | No | . raw_df.shape . (145460, 23) . raw_df.info() # to check column types of dataset . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 145460 entries, 0 to 145459 Data columns (total 23 columns): # Column Non-Null Count Dtype -- -- 0 Date 145460 non-null object 1 Location 145460 non-null object 2 MinTemp 143975 non-null float64 3 MaxTemp 144199 non-null float64 4 Rainfall 142199 non-null float64 5 Evaporation 82670 non-null float64 6 Sunshine 75625 non-null float64 7 WindGustDir 135134 non-null object 8 WindGustSpeed 135197 non-null float64 9 WindDir9am 134894 non-null object 10 WindDir3pm 141232 non-null object 11 WindSpeed9am 143693 non-null float64 12 WindSpeed3pm 142398 non-null float64 13 Humidity9am 142806 non-null float64 14 Humidity3pm 140953 non-null float64 15 Pressure9am 130395 non-null float64 16 Pressure3pm 130432 non-null float64 17 Cloud9am 89572 non-null float64 18 Cloud3pm 86102 non-null float64 19 Temp9am 143693 non-null float64 20 Temp3pm 141851 non-null float64 21 RainToday 142199 non-null object 22 RainTomorrow 142193 non-null object dtypes: float64(16), object(7) memory usage: 25.5+ MB . raw_df.dropna(subset=[&#39;RainTomorrow&#39;], inplace=True) . raw_df.head(2) . Date Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday RainTomorrow . 0 2008-12-01 | Albury | 13.4 | 22.9 | 0.6 | NaN | NaN | W | 44.0 | W | WNW | 20.0 | 24.0 | 71.0 | 22.0 | 1007.7 | 1007.1 | 8.0 | NaN | 16.9 | 21.8 | No | No | . 1 2008-12-02 | Albury | 7.4 | 25.1 | 0.0 | NaN | NaN | WNW | 44.0 | NNW | WSW | 4.0 | 22.0 | 44.0 | 25.0 | 1010.6 | 1007.8 | NaN | NaN | 17.2 | 24.3 | No | No | . raw_df.shape # shape has become 142193 . (142193, 23) . Training Validation and Test Sets . plt.title(&quot;no.of Rows per Year&quot;) sns.countplot(x=pd.to_datetime(raw_df.Date).dt.year); . year = pd.to_datetime(raw_df.Date).dt.year train_df = raw_df[year&lt;2015] val_df = raw_df[year==2015] test_df = raw_df[year&gt;2015] print(train_df.shape, val_df.shape, test_df.shape) . (98988, 23) (17231, 23) (25974, 23) . Input and Target Columns . input_cols = list(train_df.columns)[1:-1] target_cols = &#39;RainTomorrow&#39; . target_cols . &#39;RainTomorrow&#39; . input_cols . [&#39;Location&#39;, &#39;MinTemp&#39;, &#39;MaxTemp&#39;, &#39;Rainfall&#39;, &#39;Evaporation&#39;, &#39;Sunshine&#39;, &#39;WindGustDir&#39;, &#39;WindGustSpeed&#39;, &#39;WindDir9am&#39;, &#39;WindDir3pm&#39;, &#39;WindSpeed9am&#39;, &#39;WindSpeed3pm&#39;, &#39;Humidity9am&#39;, &#39;Humidity3pm&#39;, &#39;Pressure9am&#39;, &#39;Pressure3pm&#39;, &#39;Cloud9am&#39;, &#39;Cloud3pm&#39;, &#39;Temp9am&#39;, &#39;Temp3pm&#39;, &#39;RainToday&#39;] . train_inputs = train_df[input_cols].copy() train_targets = train_df[target_cols].copy() val_inputs = val_df[input_cols].copy() val_targets = val_df[target_cols].copy() test_inputs = test_df[input_cols].copy() test_targets = test_df[target_cols].copy() . numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist() categorical_cols = train_inputs.select_dtypes(&#39;object&#39;).columns.tolist() . print(numeric_cols) . [&#39;MinTemp&#39;, &#39;MaxTemp&#39;, &#39;Rainfall&#39;, &#39;Evaporation&#39;, &#39;Sunshine&#39;, &#39;WindGustSpeed&#39;, &#39;WindSpeed9am&#39;, &#39;WindSpeed3pm&#39;, &#39;Humidity9am&#39;, &#39;Humidity3pm&#39;, &#39;Pressure9am&#39;, &#39;Pressure3pm&#39;, &#39;Cloud9am&#39;, &#39;Cloud3pm&#39;, &#39;Temp9am&#39;, &#39;Temp3pm&#39;] . print(categorical_cols) . [&#39;Location&#39;, &#39;WindGustDir&#39;, &#39;WindDir9am&#39;, &#39;WindDir3pm&#39;, &#39;RainToday&#39;] . Imputing Missing Numeric Values . train_inputs[numeric_cols].isna().sum().sort_values(ascending=False) . Sunshine 40696 Evaporation 37110 Cloud3pm 36766 Cloud9am 35764 Pressure9am 9345 Pressure3pm 9309 WindGustSpeed 6902 Humidity9am 1265 Humidity3pm 1186 WindSpeed3pm 1140 WindSpeed9am 1133 Rainfall 1000 Temp9am 783 Temp3pm 663 MinTemp 434 MaxTemp 198 dtype: int64 . from sklearn.impute import SimpleImputer . imputer = SimpleImputer(strategy = &#39;mean&#39;).fit(raw_df[numeric_cols]) # imputer will figureout the avg for each of cols . train_inputs[numeric_cols] = imputer.transform(train_inputs[numeric_cols]) # fill empty data val_inputs[numeric_cols] = imputer.transform(val_inputs[numeric_cols]) test_inputs[numeric_cols] = imputer.transform(test_inputs[numeric_cols]) . train_inputs[numeric_cols].isna().sum() . MinTemp 0 MaxTemp 0 Rainfall 0 Evaporation 0 Sunshine 0 WindGustSpeed 0 WindSpeed9am 0 WindSpeed3pm 0 Humidity9am 0 Humidity3pm 0 Pressure9am 0 Pressure3pm 0 Cloud9am 0 Cloud3pm 0 Temp9am 0 Temp3pm 0 dtype: int64 . Scaling Numeric Features . from sklearn.preprocessing import MinMaxScaler . val_inputs.describe().loc[[&#39;min&#39;, &#39;max&#39;]] . MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustSpeed WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm . min -8.2 | -3.2 | 0.0 | 0.0 | 0.0 | 7.0 | 0.0 | 0.0 | 4.0 | 0.0 | 988.1 | 982.2 | 0.0 | 0.0 | -6.2 | -4.0 | . max 31.9 | 45.4 | 247.2 | 70.4 | 14.5 | 135.0 | 87.0 | 74.0 | 100.0 | 100.0 | 1039.3 | 1037.3 | 8.0 | 8.0 | 37.5 | 42.8 | . scaler = MinMaxScaler().fit(raw_df[numeric_cols]) . train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols]) val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols]) test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols]) . val_inputs.describe().loc[[&#39;min&#39;, &#39;max&#39;]] . MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustSpeed WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm . min 0.007075 | 0.030246 | 0.000000 | 0.000000 | 0.0 | 0.007752 | 0.000000 | 0.000000 | 0.04 | 0.0 | 0.125620 | 0.0816 | 0.000000 | 0.000000 | 0.021097 | 0.026871 | . max 0.952830 | 0.948960 | 0.666307 | 0.485517 | 1.0 | 1.000000 | 0.669231 | 0.850575 | 1.00 | 1.0 | 0.971901 | 0.9632 | 0.888889 | 0.888889 | 0.943038 | 0.925144 | . Encoding Categorical Data . from sklearn.preprocessing import OneHotEncoder . train_df[categorical_cols].fillna(&#39;Unkown&#39;) val_df[categorical_cols].fillna(&#39;Unkown&#39;) test_df[categorical_cols].fillna(&#39;Unknown&#39;) . Location WindGustDir WindDir9am WindDir3pm RainToday . 2498 Albury | ENE | Unknown | ESE | No | . 2499 Albury | SSE | SSE | SE | No | . 2500 Albury | ENE | ESE | ENE | Yes | . 2501 Albury | SSE | SE | SSE | Yes | . 2502 Albury | ENE | SE | SSE | Yes | . ... ... | ... | ... | ... | ... | . 145454 Uluru | E | ESE | E | No | . 145455 Uluru | E | SE | ENE | No | . 145456 Uluru | NNW | SE | N | No | . 145457 Uluru | N | SE | WNW | No | . 145458 Uluru | SE | SSE | N | No | . 25974 rows × 5 columns . encoder = OneHotEncoder(sparse=False, handle_unknown=&#39;ignore&#39;).fit(raw_df[categorical_cols]) . encoded_cols = list(encoder.get_feature_names(categorical_cols)) . train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols]) val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols]) test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols]) . print(encoded_cols) . [&#39;Location_Adelaide&#39;, &#39;Location_Albany&#39;, &#39;Location_Albury&#39;, &#39;Location_AliceSprings&#39;, &#39;Location_BadgerysCreek&#39;, &#39;Location_Ballarat&#39;, &#39;Location_Bendigo&#39;, &#39;Location_Brisbane&#39;, &#39;Location_Cairns&#39;, &#39;Location_Canberra&#39;, &#39;Location_Cobar&#39;, &#39;Location_CoffsHarbour&#39;, &#39;Location_Dartmoor&#39;, &#39;Location_Darwin&#39;, &#39;Location_GoldCoast&#39;, &#39;Location_Hobart&#39;, &#39;Location_Katherine&#39;, &#39;Location_Launceston&#39;, &#39;Location_Melbourne&#39;, &#39;Location_MelbourneAirport&#39;, &#39;Location_Mildura&#39;, &#39;Location_Moree&#39;, &#39;Location_MountGambier&#39;, &#39;Location_MountGinini&#39;, &#39;Location_Newcastle&#39;, &#39;Location_Nhil&#39;, &#39;Location_NorahHead&#39;, &#39;Location_NorfolkIsland&#39;, &#39;Location_Nuriootpa&#39;, &#39;Location_PearceRAAF&#39;, &#39;Location_Penrith&#39;, &#39;Location_Perth&#39;, &#39;Location_PerthAirport&#39;, &#39;Location_Portland&#39;, &#39;Location_Richmond&#39;, &#39;Location_Sale&#39;, &#39;Location_SalmonGums&#39;, &#39;Location_Sydney&#39;, &#39;Location_SydneyAirport&#39;, &#39;Location_Townsville&#39;, &#39;Location_Tuggeranong&#39;, &#39;Location_Uluru&#39;, &#39;Location_WaggaWagga&#39;, &#39;Location_Walpole&#39;, &#39;Location_Watsonia&#39;, &#39;Location_Williamtown&#39;, &#39;Location_Witchcliffe&#39;, &#39;Location_Wollongong&#39;, &#39;Location_Woomera&#39;, &#39;WindGustDir_E&#39;, &#39;WindGustDir_ENE&#39;, &#39;WindGustDir_ESE&#39;, &#39;WindGustDir_N&#39;, &#39;WindGustDir_NE&#39;, &#39;WindGustDir_NNE&#39;, &#39;WindGustDir_NNW&#39;, &#39;WindGustDir_NW&#39;, &#39;WindGustDir_S&#39;, &#39;WindGustDir_SE&#39;, &#39;WindGustDir_SSE&#39;, &#39;WindGustDir_SSW&#39;, &#39;WindGustDir_SW&#39;, &#39;WindGustDir_W&#39;, &#39;WindGustDir_WNW&#39;, &#39;WindGustDir_WSW&#39;, &#39;WindGustDir_nan&#39;, &#39;WindDir9am_E&#39;, &#39;WindDir9am_ENE&#39;, &#39;WindDir9am_ESE&#39;, &#39;WindDir9am_N&#39;, &#39;WindDir9am_NE&#39;, &#39;WindDir9am_NNE&#39;, &#39;WindDir9am_NNW&#39;, &#39;WindDir9am_NW&#39;, &#39;WindDir9am_S&#39;, &#39;WindDir9am_SE&#39;, &#39;WindDir9am_SSE&#39;, &#39;WindDir9am_SSW&#39;, &#39;WindDir9am_SW&#39;, &#39;WindDir9am_W&#39;, &#39;WindDir9am_WNW&#39;, &#39;WindDir9am_WSW&#39;, &#39;WindDir9am_nan&#39;, &#39;WindDir3pm_E&#39;, &#39;WindDir3pm_ENE&#39;, &#39;WindDir3pm_ESE&#39;, &#39;WindDir3pm_N&#39;, &#39;WindDir3pm_NE&#39;, &#39;WindDir3pm_NNE&#39;, &#39;WindDir3pm_NNW&#39;, &#39;WindDir3pm_NW&#39;, &#39;WindDir3pm_S&#39;, &#39;WindDir3pm_SE&#39;, &#39;WindDir3pm_SSE&#39;, &#39;WindDir3pm_SSW&#39;, &#39;WindDir3pm_SW&#39;, &#39;WindDir3pm_W&#39;, &#39;WindDir3pm_WNW&#39;, &#39;WindDir3pm_WSW&#39;, &#39;WindDir3pm_nan&#39;, &#39;RainToday_No&#39;, &#39;RainToday_Yes&#39;, &#39;RainToday_nan&#39;] . train_inputs.head(10) . Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday Location_Adelaide Location_Albany Location_Albury Location_AliceSprings Location_BadgerysCreek Location_Ballarat Location_Bendigo Location_Brisbane Location_Cairns Location_Canberra Location_Cobar Location_CoffsHarbour Location_Dartmoor Location_Darwin Location_GoldCoast Location_Hobart Location_Katherine Location_Launceston Location_Melbourne Location_MelbourneAirport Location_Mildura Location_Moree Location_MountGambier Location_MountGinini Location_Newcastle Location_Nhil Location_NorahHead Location_NorfolkIsland Location_Nuriootpa Location_PearceRAAF Location_Penrith Location_Perth Location_PerthAirport Location_Portland Location_Richmond Location_Sale Location_SalmonGums Location_Sydney Location_SydneyAirport Location_Townsville Location_Tuggeranong Location_Uluru Location_WaggaWagga Location_Walpole Location_Watsonia Location_Williamtown Location_Witchcliffe Location_Wollongong Location_Woomera WindGustDir_E WindGustDir_ENE WindGustDir_ESE WindGustDir_N WindGustDir_NE WindGustDir_NNE WindGustDir_NNW WindGustDir_NW WindGustDir_S WindGustDir_SE WindGustDir_SSE WindGustDir_SSW WindGustDir_SW WindGustDir_W WindGustDir_WNW WindGustDir_WSW WindGustDir_nan WindDir9am_E WindDir9am_ENE WindDir9am_ESE WindDir9am_N WindDir9am_NE WindDir9am_NNE WindDir9am_NNW WindDir9am_NW WindDir9am_S WindDir9am_SE WindDir9am_SSE WindDir9am_SSW WindDir9am_SW WindDir9am_W WindDir9am_WNW WindDir9am_WSW WindDir9am_nan WindDir3pm_E WindDir3pm_ENE WindDir3pm_ESE WindDir3pm_N WindDir3pm_NE WindDir3pm_NNE WindDir3pm_NNW WindDir3pm_NW WindDir3pm_S WindDir3pm_SE WindDir3pm_SSE WindDir3pm_SSW WindDir3pm_SW WindDir3pm_W WindDir3pm_WNW WindDir3pm_WSW WindDir3pm_nan RainToday_No RainToday_Yes RainToday_nan . 0 Albury | 0.516509 | 0.523629 | 0.001617 | 0.037723 | 0.525852 | W | 0.294574 | W | WNW | 0.153846 | 0.275862 | 0.71 | 0.22 | 0.449587 | 0.4800 | 0.888889 | 0.500352 | 0.508439 | 0.522073 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 1 Albury | 0.375000 | 0.565217 | 0.000000 | 0.037723 | 0.525852 | WNW | 0.294574 | NNW | WSW | 0.030769 | 0.252874 | 0.44 | 0.25 | 0.497521 | 0.4912 | 0.493021 | 0.500352 | 0.514768 | 0.570058 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2 Albury | 0.504717 | 0.576560 | 0.000000 | 0.037723 | 0.525852 | WSW | 0.310078 | W | WSW | 0.146154 | 0.298851 | 0.38 | 0.30 | 0.447934 | 0.5056 | 0.493021 | 0.222222 | 0.594937 | 0.548944 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 3 Albury | 0.417453 | 0.620038 | 0.000000 | 0.037723 | 0.525852 | NE | 0.139535 | SE | E | 0.084615 | 0.103448 | 0.45 | 0.16 | 0.613223 | 0.5712 | 0.493021 | 0.500352 | 0.533755 | 0.612284 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 4 Albury | 0.613208 | 0.701323 | 0.002695 | 0.037723 | 0.525852 | W | 0.271318 | ENE | NW | 0.053846 | 0.229885 | 0.82 | 0.33 | 0.500826 | 0.4624 | 0.777778 | 0.888889 | 0.527426 | 0.673704 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 5 Albury | 0.544811 | 0.652174 | 0.000539 | 0.037723 | 0.525852 | WNW | 0.387597 | W | W | 0.146154 | 0.275862 | 0.55 | 0.23 | 0.474380 | 0.4528 | 0.493021 | 0.500352 | 0.586498 | 0.658349 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 6 Albury | 0.537736 | 0.563327 | 0.000000 | 0.037723 | 0.525852 | W | 0.341085 | SW | W | 0.153846 | 0.275862 | 0.49 | 0.19 | 0.480992 | 0.4976 | 0.111111 | 0.500352 | 0.533755 | 0.575816 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 7 Albury | 0.382075 | 0.595463 | 0.000000 | 0.037723 | 0.525852 | W | 0.224806 | SSE | W | 0.046154 | 0.195402 | 0.48 | 0.19 | 0.543802 | 0.5280 | 0.493021 | 0.500352 | 0.495781 | 0.593090 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 8 Albury | 0.429245 | 0.693762 | 0.000000 | 0.037723 | 0.525852 | NNW | 0.573643 | SE | NW | 0.053846 | 0.321839 | 0.42 | 0.09 | 0.469421 | 0.4240 | 0.493021 | 0.500352 | 0.537975 | 0.683301 | No | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 9 Albury | 0.509434 | 0.659735 | 0.003774 | 0.037723 | 0.525852 | W | 0.170543 | S | SSE | 0.115385 | 0.126437 | 0.58 | 0.27 | 0.438017 | 0.4576 | 0.493021 | 0.500352 | 0.575949 | 0.644914 | Yes | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . X_train = train_inputs[numeric_cols + encoded_cols] X_val = val_inputs[numeric_cols + encoded_cols] X_test = test_inputs[numeric_cols + encoded_cols] . X_test.head(10) . MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustSpeed WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm Location_Adelaide Location_Albany Location_Albury Location_AliceSprings Location_BadgerysCreek Location_Ballarat Location_Bendigo Location_Brisbane Location_Cairns Location_Canberra Location_Cobar Location_CoffsHarbour Location_Dartmoor Location_Darwin Location_GoldCoast Location_Hobart Location_Katherine Location_Launceston Location_Melbourne Location_MelbourneAirport Location_Mildura Location_Moree Location_MountGambier Location_MountGinini Location_Newcastle Location_Nhil Location_NorahHead Location_NorfolkIsland Location_Nuriootpa Location_PearceRAAF Location_Penrith Location_Perth Location_PerthAirport Location_Portland Location_Richmond Location_Sale Location_SalmonGums Location_Sydney Location_SydneyAirport Location_Townsville Location_Tuggeranong Location_Uluru Location_WaggaWagga Location_Walpole Location_Watsonia Location_Williamtown Location_Witchcliffe Location_Wollongong Location_Woomera WindGustDir_E WindGustDir_ENE WindGustDir_ESE WindGustDir_N WindGustDir_NE WindGustDir_NNE WindGustDir_NNW WindGustDir_NW WindGustDir_S WindGustDir_SE WindGustDir_SSE WindGustDir_SSW WindGustDir_SW WindGustDir_W WindGustDir_WNW WindGustDir_WSW WindGustDir_nan WindDir9am_E WindDir9am_ENE WindDir9am_ESE WindDir9am_N WindDir9am_NE WindDir9am_NNE WindDir9am_NNW WindDir9am_NW WindDir9am_S WindDir9am_SE WindDir9am_SSE WindDir9am_SSW WindDir9am_SW WindDir9am_W WindDir9am_WNW WindDir9am_WSW WindDir9am_nan WindDir3pm_E WindDir3pm_ENE WindDir3pm_ESE WindDir3pm_N WindDir3pm_NE WindDir3pm_NNE WindDir3pm_NNW WindDir3pm_NW WindDir3pm_S WindDir3pm_SE WindDir3pm_SSE WindDir3pm_SSW WindDir3pm_SW WindDir3pm_W WindDir3pm_WNW WindDir3pm_WSW WindDir3pm_nan RainToday_No RainToday_Yes RainToday_nan . 2498 0.681604 | 0.801512 | 0.000000 | 0.037723 | 0.525852 | 0.372093 | 0.000000 | 0.080460 | 0.46 | 0.17 | 0.543802 | 0.5136 | 0.777778 | 0.333333 | 0.702532 | 0.808061 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2499 0.693396 | 0.725898 | 0.001078 | 0.037723 | 0.525852 | 0.341085 | 0.069231 | 0.195402 | 0.54 | 0.30 | 0.505785 | 0.5008 | 0.888889 | 0.888889 | 0.675105 | 0.712092 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2500 0.634434 | 0.527410 | 0.005930 | 0.037723 | 0.525852 | 0.325581 | 0.084615 | 0.448276 | 0.62 | 0.67 | 0.553719 | 0.6032 | 0.888889 | 0.888889 | 0.611814 | 0.477927 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 2501 0.608491 | 0.538752 | 0.042049 | 0.037723 | 0.525852 | 0.255814 | 0.069231 | 0.195402 | 0.74 | 0.65 | 0.618182 | 0.6304 | 0.888889 | 0.888889 | 0.556962 | 0.518234 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 2502 0.566038 | 0.523629 | 0.018329 | 0.037723 | 0.525852 | 0.193798 | 0.046154 | 0.103448 | 0.92 | 0.63 | 0.591736 | 0.5888 | 0.888889 | 0.888889 | 0.514768 | 0.529750 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | . 2503 0.601415 | 0.621928 | 0.000539 | 0.037723 | 0.525852 | 0.255814 | 0.069231 | 0.126437 | 0.76 | 0.52 | 0.563636 | 0.5680 | 0.888889 | 0.888889 | 0.580169 | 0.596929 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2504 0.587264 | 0.620038 | 0.000000 | 0.037723 | 0.525852 | 0.224806 | 0.153846 | 0.229885 | 0.46 | 0.31 | 0.609917 | 0.6176 | 0.493021 | 0.222222 | 0.592827 | 0.614203 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2505 0.537736 | 0.689981 | 0.000000 | 0.037723 | 0.525852 | 0.139535 | 0.084615 | 0.068966 | 0.63 | 0.24 | 0.646281 | 0.6416 | 0.493021 | 0.888889 | 0.561181 | 0.654511 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2506 0.594340 | 0.752363 | 0.000000 | 0.037723 | 0.525852 | 0.170543 | 0.084615 | 0.103448 | 0.52 | 0.24 | 0.629752 | 0.6144 | 0.493021 | 0.333333 | 0.662447 | 0.738964 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 2507 0.620283 | 0.790170 | 0.000000 | 0.037723 | 0.525852 | 0.271318 | 0.069231 | 0.195402 | 0.54 | 0.17 | 0.596694 | 0.5680 | 0.493021 | 0.500352 | 0.704641 | 0.798464 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . Training and Visualizing Decision Trees . . useful blog :Visualize a Decision Tree in 4 Ways with Scikit-Learn and Python . Training . from sklearn.tree import DecisionTreeClassifier . model = DecisionTreeClassifier(random_state=42) # random state is provided to get same value each time . %%time model.fit(X_train, train_targets) . CPU times: user 1.9 s, sys: 9.74 ms, total: 1.91 s Wall time: 1.92 s . DecisionTreeClassifier(random_state=42) . Evaluation . from sklearn.metrics import accuracy_score, confusion_matrix . train_preds = model.predict(X_train) . train_preds . array([&#39;No&#39;, &#39;No&#39;, &#39;No&#39;, ..., &#39;No&#39;, &#39;No&#39;, &#39;No&#39;], dtype=object) . pd.value_counts(train_preds) . No 76707 Yes 22281 dtype: int64 . Decision tree also returns probabilities of each prediction . train_probs = model.predict_proba(X_train) . train_probs . array([[1., 0.], [1., 0.], [1., 0.], ..., [1., 0.], [1., 0.], [1., 0.]]) . train_targets . 0 No 1 No 2 No 3 No 4 No .. 144548 No 144549 No 144550 No 144551 No 144552 No Name: RainTomorrow, Length: 98988, dtype: object . accuracy_score(train_preds, train_targets) . 0.9999797955307714 . model.score(X_val, val_targets) # direct prediction on val inputs and compare accuracy #only ~79% . 0.7921188555510418 . val_targets.value_counts() / len(val_targets) . No 0.788289 Yes 0.211711 Name: RainTomorrow, dtype: float64 . It appears that the model has learned the training examples perfect, and doesn&#39;t generalize well to previously unseen examples. This phenomenon is called &quot;overfitting&quot;, and reducing overfitting is one of the most important parts of any machine learning project. . Visualizing Tree . from sklearn.tree import plot_tree, export_text . plt.figure(figsize=(80, 40)) plot_tree(model, feature_names=X_train.columns, max_depth=2, filled=True) . [Text(2232.0, 1902.6000000000001, &#39;Humidity3pm &lt;= 0.715 ngini = 0.349 nsamples = 98988 nvalue = [76705, 22283]&#39;), Text(1116.0, 1359.0, &#39;Rainfall &lt;= 0.004 ngini = 0.248 nsamples = 82418 nvalue = [70439, 11979]&#39;), Text(558.0, 815.4000000000001, &#39;Sunshine &lt;= 0.525 ngini = 0.198 nsamples = 69252 nvalue = [61538, 7714]&#39;), Text(279.0, 271.79999999999995, &#39; n (...) n&#39;), Text(837.0, 271.79999999999995, &#39; n (...) n&#39;), Text(1674.0, 815.4000000000001, &#39;Humidity3pm &lt;= 0.512 ngini = 0.438 nsamples = 13166 nvalue = [8901, 4265]&#39;), Text(1395.0, 271.79999999999995, &#39; n (...) n&#39;), Text(1953.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3348.0, 1359.0, &#39;Humidity3pm &lt;= 0.825 ngini = 0.47 nsamples = 16570 nvalue = [6266, 10304]&#39;), Text(2790.0, 815.4000000000001, &#39;WindGustSpeed &lt;= 0.279 ngini = 0.499 nsamples = 9136 nvalue = [4804, 4332]&#39;), Text(2511.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3069.0, 271.79999999999995, &#39; n (...) n&#39;), Text(3906.0, 815.4000000000001, &#39;Rainfall &lt;= 0.01 ngini = 0.316 nsamples = 7434 nvalue = [1462, 5972]&#39;), Text(3627.0, 271.79999999999995, &#39; n (...) n&#39;), Text(4185.0, 271.79999999999995, &#39; n (...) n&#39;)] . How a Decision Tree is Created . Note the gini value in each box. This is the loss function used by the decision tree to decide which column should be used for splitting the data, and at what point the column should be split. A lower Gini index indicates a better split. A perfect split (only one class on each side) has a Gini index of 0. . For a mathematical discussion of the Gini Index, watch this video: It has the following formula: . . Conceptually speaking, while training the models evaluates all possible splits across all possible columns and picks the best one. Then, it recursively performs an optimal split for the two portions. In practice, however, it&#39;s very inefficient to check all possible splits, so the model uses a heuristic (predefined strategy) combined with some randomization. . Let&#39;s check the depth of the tree that was created. . model.tree_.max_depth . 48 . tree_text = export_text(model, max_depth=10, feature_names=list(X_train.columns)) print(tree_text[:5000]) . | Humidity3pm &lt;= 0.72 | | Rainfall &lt;= 0.00 | | | Sunshine &lt;= 0.52 | | | | Pressure3pm &lt;= 0.58 | | | | | WindGustSpeed &lt;= 0.36 | | | | | | Humidity3pm &lt;= 0.28 | | | | | | | WindDir9am_NE &lt;= 0.50 | | | | | | | | Location_Watsonia &lt;= 0.50 | | | | | | | | | Cloud9am &lt;= 0.83 | | | | | | | | | | WindSpeed3pm &lt;= 0.07 | | | | | | | | | | | Pressure3pm &lt;= 0.46 | | | | | | | | | | | | class: Yes | | | | | | | | | | | Pressure3pm &gt; 0.46 | | | | | | | | | | | | class: No | | | | | | | | | | WindSpeed3pm &gt; 0.07 | | | | | | | | | | | MinTemp &lt;= 0.32 | | | | | | | | | | | | truncated branch of depth 2 | | | | | | | | | | | MinTemp &gt; 0.32 | | | | | | | | | | | | truncated branch of depth 7 | | | | | | | | | Cloud9am &gt; 0.83 | | | | | | | | | | Cloud3pm &lt;= 0.42 | | | | | | | | | | | class: Yes | | | | | | | | | | Cloud3pm &gt; 0.42 | | | | | | | | | | | Rainfall &lt;= 0.00 | | | | | | | | | | | | truncated branch of depth 2 | | | | | | | | | | | Rainfall &gt; 0.00 | | | | | | | | | | | | class: Yes | | | | | | | | Location_Watsonia &gt; 0.50 | | | | | | | | | class: Yes | | | | | | | WindDir9am_NE &gt; 0.50 | | | | | | | | WindGustSpeed &lt;= 0.25 | | | | | | | | | class: No | | | | | | | | WindGustSpeed &gt; 0.25 | | | | | | | | | Pressure9am &lt;= 0.54 | | | | | | | | | | Evaporation &lt;= 0.09 | | | | | | | | | | | Location_AliceSprings &lt;= 0.50 | | | | | | | | | | | | truncated branch of depth 4 | | | | | | | | | | | Location_AliceSprings &gt; 0.50 | | | | | | | | | | | | class: Yes | | | | | | | | | | Evaporation &gt; 0.09 | | | | | | | | | | | WindGustDir_ENE &lt;= 0.50 | | | | | | | | | | | | class: Yes | | | | | | | | | | | WindGustDir_ENE &gt; 0.50 | | | | | | | | | | | | class: No | | | | | | | | | Pressure9am &gt; 0.54 | | | | | | | | | | Humidity3pm &lt;= 0.20 | | | | | | | | | | | class: Yes | | | | | | | | | | Humidity3pm &gt; 0.20 | | | | | | | | | | | Evaporation &lt;= 0.02 | | | | | | | | | | | | class: Yes | | | | | | | | | | | Evaporation &gt; 0.02 | | | | | | | | | | | | class: No | | | | | | Humidity3pm &gt; 0.28 | | | | | | | Sunshine &lt;= 0.05 | | | | | | | | WindGustSpeed &lt;= 0.25 | | | | | | | | | Evaporation &lt;= 0.01 | | | | | | | | | | WindGustSpeed &lt;= 0.23 | | | | | | | | | | | class: Yes | | | | | | | | | | WindGustSpeed &gt; 0.23 | | | | | | | | | | | class: No | | | | | | | | | Evaporation &gt; 0.01 | | | | | | | | | | Evaporation &lt;= 0.07 | | | | | | | | | | | Temp3pm &lt;= 0.34 | | | | | | | | | | | | class: Yes | | | | | | | | | | | Temp3pm &gt; 0.34 | | | | | | | | | | | | truncated branch of depth 11 | | | | | | | | | | Evaporation &gt; 0.07 | | | | | | | | | | | WindSpeed9am &lt;= 0.12 | | | | | | | | | | | | class: Yes | | | | | | | | | | | WindSpeed9am &gt; 0.12 | | | | | | | | | | | | class: No | | | | | | | | WindGustSpeed &gt; 0.25 | | | | | | | | | Pressure9am &lt;= 0.56 | | | | | | | | | | MinTemp &lt;= 0.40 | | | | | | | | | | | WindDir9am_WNW &lt;= 0.50 | | | | | | | | | | | | class: Yes | | | | | | | | | | | WindDir9am_WNW &gt; 0.50 | | | | | | | | | | | | class: No | | | | | | | | | | MinTemp &gt; 0.40 | | | | | | | | | | | Humidity3pm &lt;= 0.66 | | | | | | | | | | | | truncated branch of depth 7 | | | | | | | | | | | Humidity3pm &gt; 0.66 | | | | | | | | | | | | truncated branch of depth 4 | | | | | | | | | Pressure9am &gt; 0.56 | | | | | . Feature Importance . X_train.columns . Index([&#39;MinTemp&#39;, &#39;MaxTemp&#39;, &#39;Rainfall&#39;, &#39;Evaporation&#39;, &#39;Sunshine&#39;, &#39;WindGustSpeed&#39;, &#39;WindSpeed9am&#39;, &#39;WindSpeed3pm&#39;, &#39;Humidity9am&#39;, &#39;Humidity3pm&#39;, ... &#39;WindDir3pm_SSE&#39;, &#39;WindDir3pm_SSW&#39;, &#39;WindDir3pm_SW&#39;, &#39;WindDir3pm_W&#39;, &#39;WindDir3pm_WNW&#39;, &#39;WindDir3pm_WSW&#39;, &#39;WindDir3pm_nan&#39;, &#39;RainToday_No&#39;, &#39;RainToday_Yes&#39;, &#39;RainToday_nan&#39;], dtype=&#39;object&#39;, length=119) . model.feature_importances_ . array([3.48942086e-02, 3.23605486e-02, 5.91385668e-02, 2.49619907e-02, 4.94652143e-02, 5.63334673e-02, 2.80205998e-02, 2.98128801e-02, 4.02182908e-02, 2.61441297e-01, 3.44145027e-02, 6.20573699e-02, 1.36406176e-02, 1.69229866e-02, 3.50001550e-02, 3.04064076e-02, 2.24086587e-03, 2.08018104e-03, 1.27475954e-03, 7.26936324e-04, 1.39779517e-03, 1.15264873e-03, 6.92808159e-04, 1.80675598e-03, 1.08370901e-03, 1.19773895e-03, 8.87119103e-04, 2.15764220e-03, 1.67094731e-03, 7.98919493e-05, 1.10558668e-03, 1.42008656e-03, 4.10087635e-04, 1.09028115e-03, 1.44164766e-03, 9.08284767e-04, 1.05770304e-03, 6.18133455e-04, 1.80387272e-03, 2.10403527e-03, 2.74413333e-04, 7.31599405e-04, 1.35408990e-03, 1.54759332e-03, 1.30917564e-03, 1.07134670e-03, 8.36408023e-04, 1.62662229e-03, 1.00326116e-03, 2.16053455e-03, 8.46802258e-04, 1.88919081e-03, 9.29325203e-04, 1.29545157e-03, 1.27604831e-03, 5.12736888e-04, 1.38458902e-03, 3.97103931e-04, 1.03734689e-03, 1.44437047e-03, 1.75870184e-03, 1.42487857e-03, 2.78109569e-03, 2.00782698e-03, 2.80617652e-04, 1.61509734e-03, 1.64361598e-03, 2.36124112e-03, 3.05457932e-03, 2.33239534e-03, 2.78643875e-03, 2.16695261e-03, 3.41491352e-03, 2.30573542e-03, 2.28270604e-03, 2.34408118e-03, 2.26557332e-03, 2.54592702e-03, 2.75264499e-03, 2.83905192e-03, 2.49480561e-03, 1.54840338e-03, 2.50305095e-03, 2.53945388e-03, 2.28130055e-03, 3.80572180e-03, 2.58535069e-03, 3.10172224e-03, 2.54236791e-03, 2.50297796e-03, 2.06400988e-03, 2.52931192e-03, 2.07840517e-03, 1.77387278e-03, 1.78920555e-03, 2.77709687e-03, 2.42564566e-03, 2.26471887e-03, 1.73346117e-03, 2.23926957e-03, 2.47865244e-03, 2.31917387e-03, 3.21211861e-03, 2.92382975e-03, 2.24399274e-03, 3.68774754e-03, 3.87595982e-03, 3.20326068e-03, 2.53323550e-03, 2.40444844e-03, 2.26790411e-03, 2.19744009e-03, 2.28064147e-03, 2.88545323e-03, 2.05278867e-03, 1.12604304e-03, 2.86325849e-04, 1.32322128e-03, 1.72690480e-03]) . importance_df = pd.DataFrame({ &#39;feature&#39;: X_train.columns, &#39;importance&#39;: model.feature_importances_ }).sort_values(&#39;importance&#39;, ascending=False) . importance_df.head(10) . feature importance . 9 Humidity3pm | 0.261441 | . 11 Pressure3pm | 0.062057 | . 2 Rainfall | 0.059139 | . 5 WindGustSpeed | 0.056333 | . 4 Sunshine | 0.049465 | . 8 Humidity9am | 0.040218 | . 14 Temp9am | 0.035000 | . 0 MinTemp | 0.034894 | . 10 Pressure9am | 0.034415 | . 1 MaxTemp | 0.032361 | . plt.title(&#39;Feature Importance&#39;) sns.barplot(data=importance_df.head(10), x=&#39;importance&#39;, y=&#39;feature&#39;); . Hyperparameter Tuning and Overfitting . ?DecisionTreeClassifier . As we saw in the previous section, our decision tree classifier memorized all training examples, leading to a 100% training accuracy, while the validation accuracy was only marginally better than a dumb baseline model. This phenomenon is called overfitting, and in this section, we&#39;ll look at some strategies for reducing overfitting. The process of reducing overfitting is known as regularlization. . The DecisionTreeClassifier accepts several arguments, some of which can be modified to reduce overfitting. . These arguments are called hyperparameters because they must be configured manually (as opposed to the parameters within the model which are learned from the data. We&#39;ll explore a couple of hyperparameters: . max_depth | max_leaf_nodes | . max_depth . By reducing the maximum depth of the decision tree, we can prevent the tree from memorizing all training examples, which may lead to better generalization . model = DecisionTreeClassifier(max_depth=3, random_state=42) . model.fit(X_train, train_targets) . DecisionTreeClassifier(max_depth=3, random_state=42) . model.score(X_train, train_targets) . 0.8291308037337859 . model.score(X_val, val_targets) . 0.8334397307178921 . model.classes_ . array([&#39;No&#39;, &#39;Yes&#39;], dtype=object) . Great, while the training accuracy of the model has gone down, the validation accuracy of the model has increased significantly. . plt.figure(figsize=(80, 40)) plot_tree(model, feature_names=X_train.columns, filled=True, rounded=True, class_names=model.classes_) . [Text(2232.0, 1902.6000000000001, &#39;Humidity3pm &lt;= 0.715 ngini = 0.349 nsamples = 98988 nvalue = [76705, 22283] nclass = No&#39;), Text(1116.0, 1359.0, &#39;Rainfall &lt;= 0.004 ngini = 0.248 nsamples = 82418 nvalue = [70439, 11979] nclass = No&#39;), Text(558.0, 815.4000000000001, &#39;Sunshine &lt;= 0.525 ngini = 0.198 nsamples = 69252 nvalue = [61538, 7714] nclass = No&#39;), Text(279.0, 271.79999999999995, &#39;gini = 0.363 nsamples = 12620 nvalue = [9618, 3002] nclass = No&#39;), Text(837.0, 271.79999999999995, &#39;gini = 0.153 nsamples = 56632 nvalue = [51920, 4712] nclass = No&#39;), Text(1674.0, 815.4000000000001, &#39;Humidity3pm &lt;= 0.512 ngini = 0.438 nsamples = 13166 nvalue = [8901, 4265] nclass = No&#39;), Text(1395.0, 271.79999999999995, &#39;gini = 0.293 nsamples = 4299 nvalue = [3531, 768] nclass = No&#39;), Text(1953.0, 271.79999999999995, &#39;gini = 0.478 nsamples = 8867 nvalue = [5370, 3497] nclass = No&#39;), Text(3348.0, 1359.0, &#39;Humidity3pm &lt;= 0.825 ngini = 0.47 nsamples = 16570 nvalue = [6266, 10304] nclass = Yes&#39;), Text(2790.0, 815.4000000000001, &#39;WindGustSpeed &lt;= 0.279 ngini = 0.499 nsamples = 9136 nvalue = [4804, 4332] nclass = No&#39;), Text(2511.0, 271.79999999999995, &#39;gini = 0.472 nsamples = 5583 nvalue = [3457, 2126] nclass = No&#39;), Text(3069.0, 271.79999999999995, &#39;gini = 0.471 nsamples = 3553 nvalue = [1347, 2206] nclass = Yes&#39;), Text(3906.0, 815.4000000000001, &#39;Rainfall &lt;= 0.01 ngini = 0.316 nsamples = 7434 nvalue = [1462, 5972] nclass = Yes&#39;), Text(3627.0, 271.79999999999995, &#39;gini = 0.391 nsamples = 4360 nvalue = [1161, 3199] nclass = Yes&#39;), Text(4185.0, 271.79999999999995, &#39;gini = 0.177 nsamples = 3074 nvalue = [301, 2773] nclass = Yes&#39;)] . print(export_text(model, feature_names=list(X_train.columns))) . | Humidity3pm &lt;= 0.72 | | Rainfall &lt;= 0.00 | | | Sunshine &lt;= 0.52 | | | | class: No | | | Sunshine &gt; 0.52 | | | | class: No | | Rainfall &gt; 0.00 | | | Humidity3pm &lt;= 0.51 | | | | class: No | | | Humidity3pm &gt; 0.51 | | | | class: No | Humidity3pm &gt; 0.72 | | Humidity3pm &lt;= 0.82 | | | WindGustSpeed &lt;= 0.28 | | | | class: No | | | WindGustSpeed &gt; 0.28 | | | | class: Yes | | Humidity3pm &gt; 0.82 | | | Rainfall &lt;= 0.01 | | | | class: Yes | | | Rainfall &gt; 0.01 | | | | class: Yes . def max_depth_error(md): model = DecisionTreeClassifier(max_depth=md, random_state=42) model.fit(X_train, train_targets) train_error = 1 - model.score(X_train, train_targets) val_error = 1 - model.score(X_val, val_targets) return {&#39;Max Depth&#39;: md, &#39;Training Error&#39;: train_error, &#39;Validation Error&#39;: val_error} . %%time errors_df = pd.DataFrame([max_depth_error(md) for md in range(1, 21)]) . CPU times: user 30.3 s, sys: 203 ms, total: 30.5 s Wall time: 30.5 s . errors_df . Max Depth Training Error Validation Error . 0 1 | 0.184315 | 0.177935 | . 1 2 | 0.179547 | 0.172712 | . 2 3 | 0.170869 | 0.166560 | . 3 4 | 0.165707 | 0.164355 | . 4 5 | 0.160676 | 0.159074 | . 5 6 | 0.156271 | 0.157275 | . 6 7 | 0.153312 | 0.154605 | . 7 8 | 0.147806 | 0.158029 | . 8 9 | 0.140906 | 0.156578 | . 9 10 | 0.132945 | 0.157333 | . 10 11 | 0.123227 | 0.159248 | . 11 12 | 0.113489 | 0.160815 | . 12 13 | 0.101750 | 0.163833 | . 13 14 | 0.089981 | 0.167373 | . 14 15 | 0.078999 | 0.171261 | . 15 16 | 0.068180 | 0.174279 | . 16 17 | 0.058138 | 0.176890 | . 17 18 | 0.048733 | 0.181243 | . 18 19 | 0.040025 | 0.187569 | . 19 20 | 0.032539 | 0.190297 | . plt.figure() plt.plot(errors_df[&#39;Max Depth&#39;], errors_df[&#39;Training Error&#39;]) plt.plot(errors_df[&#39;Max Depth&#39;], errors_df[&#39;Validation Error&#39;]) plt.title(&quot;Training vs Validation Error&quot;) plt.xticks(range(0,21,2)) plt.xlabel(&#39;Max. Depth&#39;) plt.ylabel(&#39;Prediction Error ie 1-Accuracy&#39;) plt.legend([&#39;Training&#39;, &#39;Validation&#39;]) . &lt;matplotlib.legend.Legend at 0x7f037824ffa0&gt; . . So for us max depth of 7 results in lowest validation error . model = DecisionTreeClassifier(max_depth=7, random_state=42).fit(X_train, train_targets) model.score(X_val, val_targets), model.score(X_train, train_targets) . (0.8453949277465034, 0.8466884874934335) . max_leaf_nodes . Another way to control the size of complexity of a decision tree is to limit the number of leaf nodes. This allows branches of the tree to have varying depths. . model = DecisionTreeClassifier(max_leaf_nodes = 128, random_state = 42) . model.fit(X_train, train_targets) . DecisionTreeClassifier(max_leaf_nodes=128, random_state=42) . model.score(X_train, train_targets) . 0.8480421869317493 . model.score(X_val, val_targets) . 0.8442342290058615 . model.tree_.max_depth . 12 . Notice that the model was able to achieve a greater depth of 12 for certain paths while keeping other paths shorter. . model_text = export_text(model, feature_names = list(X_train.columns)) print(model_text[:3000]) . | Humidity3pm &lt;= 0.72 | | Rainfall &lt;= 0.00 | | | Sunshine &lt;= 0.52 | | | | Pressure3pm &lt;= 0.58 | | | | | WindGustSpeed &lt;= 0.36 | | | | | | Humidity3pm &lt;= 0.28 | | | | | | | class: No | | | | | | Humidity3pm &gt; 0.28 | | | | | | | Sunshine &lt;= 0.05 | | | | | | | | class: Yes | | | | | | | Sunshine &gt; 0.05 | | | | | | | | Pressure3pm &lt;= 0.43 | | | | | | | | | class: Yes | | | | | | | | Pressure3pm &gt; 0.43 | | | | | | | | | Humidity3pm &lt;= 0.57 | | | | | | | | | | WindDir9am_NE &lt;= 0.50 | | | | | | | | | | | WindDir9am_NNE &lt;= 0.50 | | | | | | | | | | | | class: No | | | | | | | | | | | WindDir9am_NNE &gt; 0.50 | | | | | | | | | | | | class: No | | | | | | | | | | WindDir9am_NE &gt; 0.50 | | | | | | | | | | | class: Yes | | | | | | | | | Humidity3pm &gt; 0.57 | | | | | | | | | | MaxTemp &lt;= 0.53 | | | | | | | | | | | class: No | | | | | | | | | | MaxTemp &gt; 0.53 | | | | | | | | | | | Temp3pm &lt;= 0.67 | | | | | | | | | | | | class: No | | | | | | | | | | | Temp3pm &gt; 0.67 | | | | | | | | | | | | class: No | | | | | WindGustSpeed &gt; 0.36 | | | | | | Humidity3pm &lt;= 0.45 | | | | | | | Sunshine &lt;= 0.39 | | | | | | | | class: No | | | | | | | Sunshine &gt; 0.39 | | | | | | | | class: No | | | | | | Humidity3pm &gt; 0.45 | | | | | | | Pressure3pm &lt;= 0.49 | | | | | | | | class: Yes | | | | | | | Pressure3pm &gt; 0.49 | | | | | | | | class: Yes | | | | Pressure3pm &gt; 0.58 | | | | | Pressure3pm &lt;= 0.70 | | | | | | Sunshine &lt;= 0.32 | | | | | | | WindDir9am_N &lt;= 0.50 | | | | | | | | Humidity3pm &lt;= 0.67 | | | | | | | | | class: No | | | | | | | | Humidity3pm &gt; 0.67 | | | | | | | | | class: No | | | | | | | WindDir9am_N &gt; 0.50 | | | | | | | | class: No | | | | | | Sunshine &gt; 0.32 | | | | | | | WindGustSpeed &lt;= 0.33 | | | | | | | | class: No | | | | | | | WindGustSpeed &gt; 0.33 | | | | | | | | class: No | | | | | Pressure3pm &gt; 0.70 | | | | | | Location_CoffsHarbour &lt;= 0.50 | | | | | | | class: No | | | | | | Location_CoffsHarbour &gt; 0.50 | | | | | | | class: No | | | Sunshine &gt; 0.52 | | | .",
            "url": "https://mr-siddy.github.io/ML-blog/ml/2021/05/16/Decision-Trees-AussRain.html",
            "relUrl": "/ml/2021/05/16/Decision-Trees-AussRain.html",
            "date": " • May 16, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "k-Means Clustering on Mall Customer Segmentation Dataset",
            "content": "Importing Dependencies . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from sklearn.cluster import KMeans . EDA on Mall Customer Segmentation Dataset . import os data_dir = &#39;/media/siddy/D Drive/Datasets/&#39; print(os.listdir(data_dir)) . [&#39;Clustering&#39;, &#39;song-popularity-prediction&#39;] . file_path = os.path.join(data_dir + &#39;Clustering&#39;, &quot;Mall_Customers.csv&quot;) . print(file_path) . /media/siddy/D Drive/Datasets/Clustering/Mall_Customers.csv . df = pd.read_csv(f&#39;{file_path}&#39;) . df.head(10) . CustomerID Gender Age Annual Income (k$) Spending Score (1-100) . 0 1 | Male | 19 | 15 | 39 | . 1 2 | Male | 21 | 15 | 81 | . 2 3 | Female | 20 | 16 | 6 | . 3 4 | Female | 23 | 16 | 77 | . 4 5 | Female | 31 | 17 | 40 | . 5 6 | Female | 22 | 17 | 76 | . 6 7 | Female | 35 | 18 | 6 | . 7 8 | Female | 23 | 18 | 94 | . 8 9 | Male | 64 | 19 | 3 | . 9 10 | Female | 30 | 19 | 72 | . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 200 entries, 0 to 199 Data columns (total 5 columns): # Column Non-Null Count Dtype -- -- 0 CustomerID 200 non-null int64 1 Gender 200 non-null object 2 Age 200 non-null int64 3 Annual Income (k$) 200 non-null int64 4 Spending Score (1-100) 200 non-null int64 dtypes: int64(4), object(1) memory usage: 7.9+ KB . df.isnull().sum() . CustomerID 0 Gender 0 Age 0 Annual Income (k$) 0 Spending Score (1-100) 0 dtype: int64 . features = df.iloc[:, [3,4]].values . features . array([[ 15, 39], [ 15, 81], [ 16, 6], [ 16, 77], [ 17, 40], [ 17, 76], [ 18, 6], [ 18, 94], [ 19, 3], [ 19, 72], [ 19, 14], [ 19, 99], [ 20, 15], [ 20, 77], [ 20, 13], [ 20, 79], [ 21, 35], [ 21, 66], [ 23, 29], [ 23, 98], [ 24, 35], [ 24, 73], [ 25, 5], [ 25, 73], [ 28, 14], [ 28, 82], [ 28, 32], [ 28, 61], [ 29, 31], [ 29, 87], [ 30, 4], [ 30, 73], [ 33, 4], [ 33, 92], [ 33, 14], [ 33, 81], [ 34, 17], [ 34, 73], [ 37, 26], [ 37, 75], [ 38, 35], [ 38, 92], [ 39, 36], [ 39, 61], [ 39, 28], [ 39, 65], [ 40, 55], [ 40, 47], [ 40, 42], [ 40, 42], [ 42, 52], [ 42, 60], [ 43, 54], [ 43, 60], [ 43, 45], [ 43, 41], [ 44, 50], [ 44, 46], [ 46, 51], [ 46, 46], [ 46, 56], [ 46, 55], [ 47, 52], [ 47, 59], [ 48, 51], [ 48, 59], [ 48, 50], [ 48, 48], [ 48, 59], [ 48, 47], [ 49, 55], [ 49, 42], [ 50, 49], [ 50, 56], [ 54, 47], [ 54, 54], [ 54, 53], [ 54, 48], [ 54, 52], [ 54, 42], [ 54, 51], [ 54, 55], [ 54, 41], [ 54, 44], [ 54, 57], [ 54, 46], [ 57, 58], [ 57, 55], [ 58, 60], [ 58, 46], [ 59, 55], [ 59, 41], [ 60, 49], [ 60, 40], [ 60, 42], [ 60, 52], [ 60, 47], [ 60, 50], [ 61, 42], [ 61, 49], [ 62, 41], [ 62, 48], [ 62, 59], [ 62, 55], [ 62, 56], [ 62, 42], [ 63, 50], [ 63, 46], [ 63, 43], [ 63, 48], [ 63, 52], [ 63, 54], [ 64, 42], [ 64, 46], [ 65, 48], [ 65, 50], [ 65, 43], [ 65, 59], [ 67, 43], [ 67, 57], [ 67, 56], [ 67, 40], [ 69, 58], [ 69, 91], [ 70, 29], [ 70, 77], [ 71, 35], [ 71, 95], [ 71, 11], [ 71, 75], [ 71, 9], [ 71, 75], [ 72, 34], [ 72, 71], [ 73, 5], [ 73, 88], [ 73, 7], [ 73, 73], [ 74, 10], [ 74, 72], [ 75, 5], [ 75, 93], [ 76, 40], [ 76, 87], [ 77, 12], [ 77, 97], [ 77, 36], [ 77, 74], [ 78, 22], [ 78, 90], [ 78, 17], [ 78, 88], [ 78, 20], [ 78, 76], [ 78, 16], [ 78, 89], [ 78, 1], [ 78, 78], [ 78, 1], [ 78, 73], [ 79, 35], [ 79, 83], [ 81, 5], [ 81, 93], [ 85, 26], [ 85, 75], [ 86, 20], [ 86, 95], [ 87, 27], [ 87, 63], [ 87, 13], [ 87, 75], [ 87, 10], [ 87, 92], [ 88, 13], [ 88, 86], [ 88, 15], [ 88, 69], [ 93, 14], [ 93, 90], [ 97, 32], [ 97, 86], [ 98, 15], [ 98, 88], [ 99, 39], [ 99, 97], [101, 24], [101, 68], [103, 17], [103, 85], [103, 23], [103, 69], [113, 8], [113, 91], [120, 16], [120, 79], [126, 28], [126, 74], [137, 18], [137, 83]]) . WCSS - Within Cluster Sum of Squares . wcss = [] for i in range(1, 11): kmeans = KMeans(n_clusters = i, init = &#39;k-means++&#39;, random_state = 42) kmeans.fit(features) wcss.append(kmeans.inertia_) . sns.set() plt.plot(range(1, 11), wcss) plt.title(&#39;ELBOW point graph&#39;) plt.xlabel(&#39;No of clusters&#39;) plt.ylabel(&#39;WCSS&#39;) plt.show() . optimum number of clusters = 5 . k-Means Clustering . kmeans = KMeans(n_clusters = 5, init = &#39;k-means++&#39;, random_state=0) #return a label for each datapoint based on their clusters y = kmeans.fit_predict(features) print(y) . [4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 3 4 1 4 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 0 2 1 2 0 2 0 2 1 2 0 2 0 2 0 2 0 2 1 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2 0 2] . len(y) . 200 . Visualizing Clusters . plt.figure(figsize=(8,8)) # features[y==0(cluster no),0(column of features)], s= size of dot plt.scatter(features[y==0,0], features[y==0,1], s=50, c=&#39;green&#39;, label=&#39;Cluster 1&#39;) plt.scatter(features[y==1,0], features[y==1,1], s=50, c=&#39;blue&#39;, label=&#39;Cluster 2&#39;) plt.scatter(features[y==2,0], features[y==2,1], s=50, c=&#39;red&#39;, label=&#39;Cluster 3&#39;) plt.scatter(features[y==3,0], features[y==3,1], s=50, c=&#39;orange&#39;, label=&#39;Cluster 4&#39;) plt.scatter(features[y==4,0], features[y==4,1], s=50, c=&#39;magenta&#39;, label=&#39;Cluster 5&#39;) # plot the centroids plt.scatter(kmeans.cluster_centers_[:, 0],kmeans.cluster_centers_[:, 1], s=100, c=&#39;black&#39;, label=&#39;centroids&#39;) plt.title(&#39;Customer Groups&#39;) plt.xlabel(&#39;Annual Income&#39;) plt.ylabel(&#39;Spending Score&#39;) plt.show() .",
            "url": "https://mr-siddy.github.io/ML-blog/clustering/2021/05/15/k-1-means.html",
            "relUrl": "/clustering/2021/05/15/k-1-means.html",
            "date": " • May 15, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "Biot Savard Law using Plotly",
            "content": "import plotly import numpy as np import matplotlib.pyplot as plt from scipy.integrate import quad import plotly.graph_objects as go from plotly.offline import plot from IPython.core.display import display,HTML import sympy as smp from sympy.vector import cross . phi = np.linspace(0, 2*np.pi, 100) def l(phi): return (1+3/4 * np.sin(3*phi)) * np.array([np.cos(phi), np.sin(phi), np.zeros(len(phi))]) . lx, ly, lz = l(phi) . plt.figure(figsize=(7,7)) plt.plot(lx,ly) plt.xlabel(&#39;$x/R$&#39;, fontsize=25) plt.ylabel(&#39;$y/R$&#39;, fontsize=25) plt.show() . solve integrand using sympy . t, x, y, z = smp.symbols(&#39;t, x, y, z&#39;) . l = (1+(3/4)*smp.sin(3*t))*smp.Matrix([smp.cos(t), smp.sin(t), 0]) r = smp.Matrix([x,y,z]) sep=r-l . l . $ displaystyle left[ begin{matrix} left(0.75 sin{ left(3 t right)} + 1 right) cos{ left(t right)} left(0.75 sin{ left(3 t right)} + 1 right) sin{ left(t right)} 0 end{matrix} right]$ r . $ displaystyle left[ begin{matrix}x y z end{matrix} right]$ sep . $ displaystyle left[ begin{matrix}x - left(0.75 sin{ left(3 t right)} + 1 right) cos{ left(t right)} y - left(0.75 sin{ left(3 t right)} + 1 right) sin{ left(t right)} z end{matrix} right]$ Define integrand . integrand = smp.diff(l,t).cross(sep) / sep.norm()**3 . Get x, y z components of the integrand . integrand . $ displaystyle left[ begin{matrix} frac{z left( left(0.75 sin{ left(3 t right)} + 1 right) cos{ left(t right)} + 2.25 sin{ left(t right)} cos{ left(3 t right)} right)}{ left( left|{z} right|^{2} + left|{x - left(0.75 sin{ left(3 t right)} + 1 right) cos{ left(t right)}} right|^{2} + left|{y - left(0.75 sin{ left(3 t right)} + 1 right) sin{ left(t right)}} right|^{2} right)^{ frac{3}{2}}} - frac{z left(- left(0.75 sin{ left(3 t right)} + 1 right) sin{ left(t right)} + 2.25 cos{ left(t right)} cos{ left(3 t right)} right)}{ left( left|{z} right|^{2} + left|{x - left(0.75 sin{ left(3 t right)} + 1 right) cos{ left(t right)}} right|^{2} + left|{y - left(0.75 sin{ left(3 t right)} + 1 right) sin{ left(t right)}} right|^{2} right)^{ frac{3}{2}}} frac{- left(x - left(0.75 sin{ left(3 t right)} + 1 right) cos{ left(t right)} right) left( left(0.75 sin{ left(3 t right)} + 1 right) cos{ left(t right)} + 2.25 sin{ left(t right)} cos{ left(3 t right)} right) + left(y - left(0.75 sin{ left(3 t right)} + 1 right) sin{ left(t right)} right) left(- left(0.75 sin{ left(3 t right)} + 1 right) sin{ left(t right)} + 2.25 cos{ left(t right)} cos{ left(3 t right)} right)}{ left( left|{z} right|^{2} + left|{x - left(0.75 sin{ left(3 t right)} + 1 right) cos{ left(t right)}} right|^{2} + left|{y - left(0.75 sin{ left(3 t right)} + 1 right) sin{ left(t right)}} right|^{2} right)^{ frac{3}{2}}} end{matrix} right]$ dBxdt = smp.lambdify([t,x,y,z], integrand[0]) dBydt = smp.lambdify([t,x,y,z], integrand[1]) dBzdt = smp.lambdify([t,x,y,z], integrand[2]) . dBxdt(np.pi, 1, 1, 1) . -0.0680413817439772 . quad(dBxdt, 0, 2*np.pi, args=(1,1,1)) # gives value and error . (0.367215052854198, 6.916483780662426e-09) . Get the magnetic field by performing the integral over each component . def B(x,y,z): return np.array([quad(dBxdt, 0, 2*np.pi, args=(x,y,z))[0], quad(dBydt, 0, 2*np.pi, args=(x,y,z))[0], quad(dBzdt, 0, 2*np.pi, args=(x,y,z))[0]]) . B(0.5,0.5,0) . array([ 0. , 0. , 10.87779227]) . B(0.5,0.5,1) . array([0.19069963, 0.52786431, 1.52524645]) . Set up a meshgrid to solve for the field in some 3D volume . x = np.linspace(-2,2,20) xv,yv,zv = np.meshgrid(x,x,x) . B_field = np.vectorize(B, signature=&#39;(),(),()-&gt;(n)&#39;)(xv,yv,zv) Bx = B_field[:,:,:,0] By = B_field[:,:,:,1] Bz = B_field[:,:,:,2] . use plotly for 3D intractive plot . xv.ravel() . array([-2., -2., -2., ..., 2., 2., 2.]) . data = go.Cone(x=xv.ravel(), y=yv.ravel(), z=zv.ravel(), u=Bx.ravel(), v=By.ravel(), w=Bz.ravel(), colorscale=&#39;Inferno&#39;, colorbar=dict(title=&#39;$x^2$&#39;), sizemode=&quot;absolute&quot;, sizeref=20) layout = go.Layout(title=r&#39;Biot Savard Law &#39;, scene=dict(xaxis_title=r&#39;x&#39;, yaxis_title=r&#39;y&#39;, zaxis_title=r&#39;z&#39;, aspectratio=dict(x=1, y=1, z=1), camera_eye=dict(x=1.2, y=1.2, z=1.2))) fig = go.Figure(data = data, layout=layout) fig.add_scatter3d(x=lx, y=ly, z=lz, mode=&#39;lines&#39;, line = dict(color=&#39;green&#39;, width=10)) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/05/14/Biot-Savart-Law.html",
            "relUrl": "/2021/05/14/Biot-Savart-Law.html",
            "date": " • May 14, 2021"
        }
        
    
  
    
        ,"post19": {
            "title": "Car Price Prediction using Random Forest Regressor",
            "content": "Problem Statement: . A Chinese automobile company Geely Auto aspires to enter the US market by setting up their manufacturing unit there and producing cars locally to give competition to their US and European counterparts. Which variables are significant in predicting the price of a car . Dataset link :- . https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho . Data Preprocessing . import pandas as pd . df = pd.read_csv(&#39;car data.csv&#39;) . df.head() . Car_Name Year Selling_Price Present_Price Kms_Driven Fuel_Type Seller_Type Transmission Owner . 0 ritz | 2014 | 3.35 | 5.59 | 27000 | Petrol | Dealer | Manual | 0 | . 1 sx4 | 2013 | 4.75 | 9.54 | 43000 | Diesel | Dealer | Manual | 0 | . 2 ciaz | 2017 | 7.25 | 9.85 | 6900 | Petrol | Dealer | Manual | 0 | . 3 wagon r | 2011 | 2.85 | 4.15 | 5200 | Petrol | Dealer | Manual | 0 | . 4 swift | 2014 | 4.60 | 6.87 | 42450 | Diesel | Dealer | Manual | 0 | . df.shape . (301, 9) . print(df[&quot;Seller_Type&quot;].unique()) print(df[&quot;Transmission&quot;].unique()) print(df[&quot;Owner&quot;].unique()) . [&#39;Dealer&#39; &#39;Individual&#39;] [&#39;Manual&#39; &#39;Automatic&#39;] [0 1 3] . df.isnull().sum() . Car_Name 0 Year 0 Selling_Price 0 Present_Price 0 Kms_Driven 0 Fuel_Type 0 Seller_Type 0 Transmission 0 Owner 0 dtype: int64 . df.describe() . Year Selling_Price Present_Price Kms_Driven Owner . count 301.000000 | 301.000000 | 301.000000 | 301.000000 | 301.000000 | . mean 2013.627907 | 4.661296 | 7.628472 | 36947.205980 | 0.043189 | . std 2.891554 | 5.082812 | 8.644115 | 38886.883882 | 0.247915 | . min 2003.000000 | 0.100000 | 0.320000 | 500.000000 | 0.000000 | . 25% 2012.000000 | 0.900000 | 1.200000 | 15000.000000 | 0.000000 | . 50% 2014.000000 | 3.600000 | 6.400000 | 32000.000000 | 0.000000 | . 75% 2016.000000 | 6.000000 | 9.900000 | 48767.000000 | 0.000000 | . max 2018.000000 | 35.000000 | 92.600000 | 500000.000000 | 3.000000 | . final_dataset=df[[&#39;Year&#39;, &#39;Selling_Price&#39;, &#39;Present_Price&#39;, &#39;Kms_Driven&#39;, &#39;Fuel_Type&#39;, &#39;Seller_Type&#39;, &#39;Transmission&#39;, &#39;Owner&#39;]] . final_dataset[&#39;Current_Year&#39;]=2021 . final_dataset[&#39;no_year&#39;]=final_dataset[&#39;Current_Year&#39;]-final_dataset[&#39;Year&#39;] . final_dataset.head() . Year Selling_Price Present_Price Kms_Driven Fuel_Type Seller_Type Transmission Owner Current_Year no_year . 0 2014 | 3.35 | 5.59 | 27000 | Petrol | Dealer | Manual | 0 | 2021 | 7 | . 1 2013 | 4.75 | 9.54 | 43000 | Diesel | Dealer | Manual | 0 | 2021 | 8 | . 2 2017 | 7.25 | 9.85 | 6900 | Petrol | Dealer | Manual | 0 | 2021 | 4 | . 3 2011 | 2.85 | 4.15 | 5200 | Petrol | Dealer | Manual | 0 | 2021 | 10 | . 4 2014 | 4.60 | 6.87 | 42450 | Diesel | Dealer | Manual | 0 | 2021 | 7 | . final_dataset.drop([&#39;Year&#39;],axis=1,inplace=True) . final_dataset.drop([&#39;Current_Year&#39;],axis=1,inplace=True) . final_dataset=pd.get_dummies(final_dataset,drop_first=True) . final_dataset.head() . Selling_Price Present_Price Kms_Driven Owner no_year Fuel_Type_Diesel Fuel_Type_Petrol Seller_Type_Individual Transmission_Manual . 0 3.35 | 5.59 | 27000 | 0 | 7 | 0 | 1 | 0 | 1 | . 1 4.75 | 9.54 | 43000 | 0 | 8 | 1 | 0 | 0 | 1 | . 2 7.25 | 9.85 | 6900 | 0 | 4 | 0 | 1 | 0 | 1 | . 3 2.85 | 4.15 | 5200 | 0 | 10 | 0 | 1 | 0 | 1 | . 4 4.60 | 6.87 | 42450 | 0 | 7 | 1 | 0 | 0 | 1 | . final_dataset.corr() . Selling_Price Present_Price Kms_Driven Owner no_year Fuel_Type_Diesel Fuel_Type_Petrol Seller_Type_Individual Transmission_Manual . Selling_Price 1.000000 | 0.878983 | 0.029187 | -0.088344 | -0.236141 | 0.552339 | -0.540571 | -0.550724 | -0.367128 | . Present_Price 0.878983 | 1.000000 | 0.203647 | 0.008057 | 0.047584 | 0.473306 | -0.465244 | -0.512030 | -0.348715 | . Kms_Driven 0.029187 | 0.203647 | 1.000000 | 0.089216 | 0.524342 | 0.172515 | -0.172874 | -0.101419 | -0.162510 | . Owner -0.088344 | 0.008057 | 0.089216 | 1.000000 | 0.182104 | -0.053469 | 0.055687 | 0.124269 | -0.050316 | . no_year -0.236141 | 0.047584 | 0.524342 | 0.182104 | 1.000000 | -0.064315 | 0.059959 | 0.039896 | -0.000394 | . Fuel_Type_Diesel 0.552339 | 0.473306 | 0.172515 | -0.053469 | -0.064315 | 1.000000 | -0.979648 | -0.350467 | -0.098643 | . Fuel_Type_Petrol -0.540571 | -0.465244 | -0.172874 | 0.055687 | 0.059959 | -0.979648 | 1.000000 | 0.358321 | 0.091013 | . Seller_Type_Individual -0.550724 | -0.512030 | -0.101419 | 0.124269 | 0.039896 | -0.350467 | 0.358321 | 1.000000 | 0.063240 | . Transmission_Manual -0.367128 | -0.348715 | -0.162510 | -0.050316 | -0.000394 | -0.098643 | 0.091013 | 0.063240 | 1.000000 | . Data-Visualisation . import seaborn as sns . sns.pairplot(final_dataset) . &lt;seaborn.axisgrid.PairGrid at 0x21f6bf7bb48&gt; . import matplotlib.pyplot as plt %matplotlib inline . corrmat = final_dataset.corr() top_corr_features=corrmat.index plt.figure(figsize=(20,20)) #plot heat map g = sns.heatmap(final_dataset[top_corr_features].corr(),annot=True, cmap=&#39;RdYlGn&#39;) . final_dataset.head() . Selling_Price Present_Price Kms_Driven Owner no_year Fuel_Type_Diesel Fuel_Type_Petrol Seller_Type_Individual Transmission_Manual . 0 3.35 | 5.59 | 27000 | 0 | 7 | 0 | 1 | 0 | 1 | . 1 4.75 | 9.54 | 43000 | 0 | 8 | 1 | 0 | 0 | 1 | . 2 7.25 | 9.85 | 6900 | 0 | 4 | 0 | 1 | 0 | 1 | . 3 2.85 | 4.15 | 5200 | 0 | 10 | 0 | 1 | 0 | 1 | . 4 4.60 | 6.87 | 42450 | 0 | 7 | 1 | 0 | 0 | 1 | . X=final_dataset.iloc[:,1:] y=final_dataset.iloc[:,0] . X.head() . Present_Price Kms_Driven Owner no_year Fuel_Type_Diesel Fuel_Type_Petrol Seller_Type_Individual Transmission_Manual . 0 5.59 | 27000 | 0 | 7 | 0 | 1 | 0 | 1 | . 1 9.54 | 43000 | 0 | 8 | 1 | 0 | 0 | 1 | . 2 9.85 | 6900 | 0 | 4 | 0 | 1 | 0 | 1 | . 3 4.15 | 5200 | 0 | 10 | 0 | 1 | 0 | 1 | . 4 6.87 | 42450 | 0 | 7 | 1 | 0 | 0 | 1 | . y.head() . 0 3.35 1 4.75 2 7.25 3 2.85 4 4.60 Name: Selling_Price, dtype: float64 . from sklearn.ensemble import ExtraTreesRegressor model=ExtraTreesRegressor() model.fit(X,y) . ExtraTreesRegressor() . print(model.feature_importances_) . [3.83348531e-01 4.08560046e-02 3.73461245e-04 7.61985654e-02 2.28609393e-01 1.08920232e-02 1.22151396e-01 1.37570626e-01] . feat_importances = pd.Series(model.feature_importances_, index=X.columns) feat_importances.nlargest(5).plot(kind=&#39;barh&#39;) plt.show() . Train Test Split . from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2) . X_train . Present_Price Kms_Driven Owner no_year Fuel_Type_Diesel Fuel_Type_Petrol Seller_Type_Individual Transmission_Manual . 174 0.72 | 38600 | 0 | 6 | 0 | 1 | 1 | 1 | . 144 0.99 | 25000 | 0 | 7 | 0 | 1 | 1 | 1 | . 212 13.60 | 22671 | 0 | 5 | 0 | 1 | 0 | 1 | . 196 0.52 | 500000 | 0 | 13 | 0 | 1 | 1 | 0 | . 243 7.60 | 7000 | 0 | 5 | 0 | 1 | 0 | 1 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 181 0.48 | 50000 | 0 | 5 | 0 | 1 | 1 | 1 | . 191 0.57 | 25000 | 1 | 9 | 0 | 1 | 1 | 1 | . 23 3.46 | 45280 | 0 | 7 | 0 | 1 | 0 | 1 | . 159 0.51 | 4000 | 0 | 4 | 0 | 1 | 1 | 0 | . 70 6.76 | 71000 | 0 | 7 | 1 | 0 | 0 | 1 | . 240 rows × 8 columns . X_train.shape . (240, 8) . ML model preparation . from sklearn.ensemble import RandomForestRegressor rf_random = RandomForestRegressor() . import numpy as np n_estimators=[int(x) for x in np.linspace(start = 100, stop = 1200, num =12 )] print(n_estimators) . [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200] . #Randomized Search CV # Number of trees in random forest n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)] # Number of features to consider at every split max_features = [&#39;auto&#39;, &#39;sqrt&#39;] # Maximum number of levels in tree max_depth = [int(x) for x in np.linspace(5, 30, num = 6)] # max_depth.append(None) # Minimum number of samples required to split a node min_samples_split = [2, 5, 10, 15, 100] # Minimum number of samples required at each leaf node min_samples_leaf = [1, 2, 5, 10] . random_grid = {&#39;n_estimators&#39;: n_estimators, &#39;max_features&#39;: max_features, &#39;max_depth&#39;: max_depth, &#39;min_samples_split&#39;: min_samples_split, &#39;min_samples_leaf&#39;: min_samples_leaf} print(random_grid) . {&#39;n_estimators&#39;: [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200], &#39;max_features&#39;: [&#39;auto&#39;, &#39;sqrt&#39;], &#39;max_depth&#39;: [5, 10, 15, 20, 25, 30], &#39;min_samples_split&#39;: [2, 5, 10, 15, 100], &#39;min_samples_leaf&#39;: [1, 2, 5, 10]} . # First create the base model to tune rf = RandomForestRegressor() . from sklearn.model_selection import RandomizedSearchCV . # Random search of parameters, using 3 fold cross validation, # search across 100 different combinations rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring=&#39;neg_mean_squared_error&#39;, n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1) . rf_random.fit(X_train,y_train) . Fitting 5 folds for each of 10 candidates, totalling 50 fits [CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time= 0.7s [CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time= 0.8s [CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time= 0.8s [CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time= 0.7s [CV] END max_depth=10, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=900; total time= 0.8s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time= 1.0s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time= 1.0s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time= 1.0s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time= 0.9s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=1100; total time= 0.9s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=100, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time= 0.3s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time= 0.3s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time= 0.3s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time= 0.3s [CV] END max_depth=15, max_features=auto, min_samples_leaf=5, min_samples_split=5, n_estimators=400; total time= 0.3s [CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time= 0.6s [CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time= 0.6s [CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time= 0.6s [CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time= 0.6s [CV] END max_depth=20, max_features=auto, min_samples_leaf=10, min_samples_split=5, n_estimators=700; total time= 0.6s [CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 0.9s [CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 0.9s [CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 0.9s [CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 0.9s [CV] END max_depth=25, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1000; total time= 0.9s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time= 0.9s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time= 0.9s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time= 0.9s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time= 0.9s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=10, min_samples_split=15, n_estimators=1100; total time= 0.9s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time= 0.2s [CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=15, n_estimators=300; total time= 0.2s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time= 0.6s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time= 0.6s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time= 0.5s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time= 0.5s [CV] END max_depth=5, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=700; total time= 0.5s [CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time= 0.6s [CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time= 0.6s [CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time= 0.6s [CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time= 0.6s [CV] END max_depth=20, max_features=auto, min_samples_leaf=1, min_samples_split=15, n_estimators=700; total time= 0.6s . RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=1, param_distributions={&#39;max_depth&#39;: [5, 10, 15, 20, 25, 30], &#39;max_features&#39;: [&#39;auto&#39;, &#39;sqrt&#39;], &#39;min_samples_leaf&#39;: [1, 2, 5, 10], &#39;min_samples_split&#39;: [2, 5, 10, 15, 100], &#39;n_estimators&#39;: [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200]}, random_state=42, scoring=&#39;neg_mean_squared_error&#39;, verbose=2) . Predictiong the Results . predictions = rf_random.predict(X_test) . predictions . array([ 0.42823578, 6.54336523, 4.51053508, 0.51499616, 5.25339526, 0.41187859, 3.59500812, 7.08705453, 1.1462021 , 21.3181618 , 0.24429459, 4.46844221, 10.77746653, 2.19624475, 2.87045466, 2.78251651, 5.56248702, 4.71332205, 0.64855331, 0.48048546, 1.16921385, 4.98697281, 0.86404259, 0.56195234, 0.26471753, 4.16548545, 4.66760447, 5.54659743, 6.3007795 , 0.54582494, 1.15449372, 7.65211645, 3.23066131, 4.9624319 , 0.54126424, 5.68049317, 3.02435804, 1.14775612, 8.57444514, 4.96809414, 0.63048064, 12.89946909, 13.48483701, 5.83942354, 0.57111473, 2.54267514, 7.08720208, 5.10635913, 5.07656358, 7.00626737, 5.68402798, 5.82973362, 3.03374272, 5.81018912, 21.1221698 , 2.4988902 , 2.56008469, 21.03405001, 5.37708202, 0.62723892, 0.4913718 ]) . sns.distplot(y_test-predictions) . C: Users mrsid anaconda3 envs carprediction lib site-packages seaborn distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms). warnings.warn(msg, FutureWarning) . &lt;AxesSubplot:xlabel=&#39;Selling_Price&#39;, ylabel=&#39;Density&#39;&gt; . plt.scatter(y_test,predictions) . &lt;matplotlib.collections.PathCollection at 0x21f0eb52748&gt; . import pickle . file = open(&#39;random_forest_regression_model.pkl&#39;, &#39;wb&#39;) # dump information pickle.dump(rf_random, file) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/05/03/car-price-prediction.html",
            "relUrl": "/2021/05/03/car-price-prediction.html",
            "date": " • May 3, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "Image Processing with MRI_images",
            "content": "Libraries . import matplotlib.pyplot as plt import pydicom from skimage import img_as_float from skimage.metrics import peak_signal_noise_ratio from skimage import io from scipy import ndimage as nd # contains gaussian filter . Denoising filters . Gaussian filter . dataset = pydicom.dcmread(&quot;/media/siddy/D Drive/Image Processing/images/MRI_images/CT_small.dcm&quot;) img = dataset.pixel_array plt.imshow(img, cmap=plt.cm.bone) plt.show() . #plt.imsave(&quot;/media/siddy/D Drive/Image Processing/images/MRI_images/dcm_to_tiff.tif&quot;, img, cmap=&#39;gray&#39;) . noisy_img = img_as_float(io.imread(&quot;/media/siddy/D Drive/Image Processing/images/MRI_images/MRI_noisy.tif&quot;)) plt.imshow(noisy_img, cmap = &#39;gray&#39;) plt.title(&#39;Noisy MRI image&quot;&#39;) plt.show() . clean_img = img_as_float(io.imread(&quot;/media/siddy/D Drive/Image Processing/images/MRI_images/MRI_clean.tif&quot;)) . print(noisy_img.shape, clean_img.shape) . (940, 934) (940, 934) . gaussian_img = nd.gaussian_filter(noisy_img, sigma=5) # heigher the sigma better the denoising, image gets blurry plt.imshow(gaussian_img, cmap=&#39;gray&#39;) plt.title(&#39;Gaussian Smoothened image&#39;) plt.show() . . Peak Signal to Noise Ratio . noise_psnr = peak_signal_noise_ratio(clean_img, noisy_img) gaussian_psnr = peak_signal_noise_ratio(clean_img, gaussian_img) print(&quot;PSNR of input noisy image = &quot;, noise_psnr) print(&quot;PSNR of gaussian cleaned image =&quot;, gaussian_psnr) . PSNR of input noisy image = 17.03789982624248 PSNR of gaussian cleaned image = 17.112001291081445 . Bilateral, TV(Total Variation) and Wavelet . from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral, denoise_wavelet, estimate_sigma) from skimage import img_as_float . sigma_est = estimate_sigma(noisy_img, multichannel=True, average_sigmas=True) print(sigma_est) . 0.011082816474057382 . denoise_bilateral = denoise_bilateral(noisy_img, sigma_spatial=15, multichannel=False) # sigma_spatial controls the amount of denoising bilateral_psnr = peak_signal_noise_ratio(clean_img, denoise_bilateral) print(&quot;PSNR of bilateral cleaned image = &quot;, bilateral_psnr) plt.imshow(denoise_bilateral, cmap=&#39;gray&#39;) plt.title(&quot;Denoise using Bilateral Filter&quot;) plt.show() . PSNR of bilateral cleaned image = 16.225197089561874 . denoise_TV = denoise_tv_chambolle(noisy_img, weight=0.3, multichannel=False) TV_cleaned_psnr = peak_signal_noise_ratio(clean_img, denoise_TV) print(&quot;PSNR of TV_cleaned image = &quot;, TV_cleaned_psnr) plt.imshow(denoise_TV, cmap=&#39;gray&#39;) plt.title(&quot;TV_Cleaned image&quot;) plt.show() . PSNR of TV_cleaned image = 17.19161931394431 . wavelet_smoothed = denoise_wavelet(noisy_img, multichannel= False, method=&#39;BayesShrink&#39;, mode=&#39;soft&#39;, rescale_sigma=True) wavelet_cleaned_psnr = peak_signal_noise_ratio(clean_img, wavelet_smoothed) print(&quot;PSNR of wavelet_cleaned image= &quot;, wavelet_cleaned_psnr) plt.imshow(wavelet_smoothed, cmap=&#39;gray&#39;) plt.title(&quot;wavelet smothed image&quot;) plt.show() . PSNR of wavelet_cleaned image= 17.0525032515753 . Shift invariant wavelet denoising https://scikit-image.org/docs/dev/auto_examples/filters/plot_cycle_spinning.html . Anisotropic Diffusion . import cv2 from medpy.filter.smoothing import anisotropic_diffusion # niter= number of iterations #kappa = Conduction coefficient (20 to 100) #gamma = speed of diffusion (&lt;=0.25) #Option: Perona Malik equation 1 or 2. A value of 3 is for Turkey&#39;s biweight function . noisy_img = img_as_float(io.imread(&quot;/media/siddy/D Drive/Image Processing/images/MRI_images/MRI_noisy.tif&quot;, as_gray=True)) . img_aniso_filtered = anisotropic_diffusion(noisy_img, niter=50, kappa= 50, gamma=0.2, option=2) . /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/medpy/filter/smoothing.py:155: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result. deltas[i][slicer] = numpy.diff(out, axis=i) /home/siddy/anaconda3/envs/torch/lib/python3.8/site-packages/medpy/filter/smoothing.py:164: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result. matrices[i][slicer] = numpy.diff(matrices[i], axis=i) . anisotropic_cleaned_psnr = peak_signal_noise_ratio(clean_img, img_aniso_filtered) print(&quot;PSNR of input noisy image = &quot;, noise_psnr) . PSNR of input noisy image = 17.03789982624248 . &lt;ipython-input-18-f16d8ead5ed0&gt;:1: UserWarning: Inputs have mismatched dtype. Setting data_range based on im_true. anisotropic_cleaned_psnr = peak_signal_noise_ratio(clean_img, img_aniso_filtered) . plt.imshow(img_aniso_filtered, cmap=&#39;gray&#39;) plt.title(&quot;Anisotropic image&quot;) plt.show() . Non-Local Means (NLM) . from skimage.restoration import denoise_nl_means, estimate_sigma from skimage import img_as_ubyte, img_as_float import numpy as np . sigma_est = np.mean(estimate_sigma(noisy_img, multichannel=False)) . NLM_skimg_denoise_img = denoise_nl_means(noisy_img, h=1.15*sigma_est, fast_mode=True, patch_size=0, patch_distance=5, multichannel=False) . NLM_skimg_cleaned_psnr = peak_signal_noise_ratio(clean_img, NLM_skimg_denoise_img) print(&quot;PSNR of input noisy image =&quot;, NLM_skimg_cleaned_psnr) . PSNR of input noisy image = 17.261562408895422 . plt.imshow(NLM_skimg_denoise_img, cmap=&#39;gray&#39;) plt.title(&#39;NLM Cleaned Image&#39;) plt.show() . fastNlMeansDenoising(InputArray src, OutputArray dst, float h=3, int templateWindowSize=7, intsearchWindowSize=21) NLM_CV2_denoise_img = cv2.fastNlMeansDenoising(noisy_img, None, 3, 7, 21) plt.imshow(&quot;images/MRI_images/NLM_CV2_denoised.tif&quot;, NLM_CV2_denoise_img, cmap=&#39;gray&#39;) plt.show() . BM3D Block-matching and 3D filtering . import bm3d . noisy_img = img_as_float(io.imread(&quot;/media/siddy/D Drive/Image Processing/images/MRI_images/MRI_noisy.tif&quot;, as_gray=True)) . BM3D_denoised_image = bm3d.bm3d(noisy_img, sigma_psd=0.2, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING) #BM3D_denoised_image = bm3d.bm3d(noisy_img, sigma_psd=0.2, stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING) #try stage_arg=bm3d.BM3DStages.HARD_THRESHOLDING BM3D_cleaned_psnr = peak_signal_noise_ratio(clean_img, BM3D_denoised_image) print(&quot;PSNR of cleaned image = &quot;, BM3D_cleaned_psnr) plt.imshow(BM3D_denoised_image, cmap=&#39;gray&#39;) plt.title(&#39;BMED Cleaned image&#39;) plt.show() . MRF . Code from following github. It works but too slow and not as good as the above filters. https://github.com/ychemli/Image-denoising-with-MRF/blob/master/ICM_denoising.py Very slow... and not so great http://www.cs.toronto.edu/~fleet/courses/2503/fall11/Handouts/mrf.pdf . import cv2 potential fonction corresponding to a gaussian markovian model (quadratic function) def pot(fi, fj): return float((fi-fj))**2 #ICM : Iterated conditional mode algorithme def ICM(img, iter, beta): NoisyIm = cv2.imread(img, 0) height, width = NoisyIm.shape sigma2 = 5 beta is the regularization parameter iter is the Number of iterations : each new image is used as the new restored image for iter in range(iter): print(&quot;iteration {} n&quot;.format(iter+1)) for i in range(height-1): print(&quot;line {}/{} ok n&quot;.format(i+1, height)) for j in range(width-1): We work in 4-connexity here xmin = 0 min = float((NoisyIm[i][j]*NoisyIm[i][j]))/(2.0*sigma2) + beta*(pot(NoisyIm[i][j-1],0)+pot(NoisyIm[i][j+1],0)+pot(NoisyIm[i-1][j], 0)+pot(NoisyIm[i+1][j], 0)) Every shade of gray is tested to find the a local minimum of the energie corresponding to a Gibbs distribution for x in range(256): proba = float(((NoisyIm[i][j]-x)*(NoisyIm[i][j]-x)))/(2.0*sigma2) + beta*(pot(NoisyIm[i][j-1],x) + pot(NoisyIm[i][j+1],x) + pot(NoisyIm[i-1][j], x) + pot(NoisyIm[i+1][j], x)) if(min&gt;proba): min = proba xmin = x NoisyIm [i][j] = xmin cv2.imwrite(&quot;iter_&quot; + str(iter+1) + &quot;_denoised_&quot; + img, NoisyIm) if __name__ == &#39;__main__&#39;: ICM(&#39;/media/siddy/D Drive/Image Processing/images/MRI_images/BM3D_denoised.tif&#39;, 10, 1) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/28/DenoisingMRI.html",
            "relUrl": "/2021/04/28/DenoisingMRI.html",
            "date": " • Apr 28, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "Multicollinearity in Linear Regression",
            "content": "import pandas as pd . Using Advertising Dataset, link :- . https://www.kaggle.com/bumba5341/advertisingcsv . import statsmodels.api as sm df_adv = pd.read_csv(&#39;Advertising.csv&#39;, index_col=0) df_adv.head() . TV radio newspaper sales . 1 230.1 | 37.8 | 69.2 | 22.1 | . 2 44.5 | 39.3 | 45.1 | 10.4 | . 3 17.2 | 45.9 | 69.3 | 9.3 | . 4 151.5 | 41.3 | 58.5 | 18.5 | . 5 180.8 | 10.8 | 58.4 | 12.9 | . X = df_adv[[&#39;TV&#39;,&#39;radio&#39;,&#39;newspaper&#39;]] y = df_adv[&#39;sales&#39;] print(X,y) . TV radio newspaper 1 230.1 37.8 69.2 2 44.5 39.3 45.1 3 17.2 45.9 69.3 4 151.5 41.3 58.5 5 180.8 10.8 58.4 .. ... ... ... 196 38.2 3.7 13.8 197 94.2 4.9 8.1 198 177.0 9.3 6.4 199 283.6 42.0 66.2 200 232.1 8.6 8.7 [200 rows x 3 columns] 1 22.1 2 10.4 3 9.3 4 18.5 5 12.9 ... 196 7.6 197 9.7 198 12.8 199 25.5 200 13.4 Name: sales, Length: 200, dtype: float64 . fit a Oridinirary least square model with intercept on TV and Radio . X = sm.add_constant(X) . X . const TV radio newspaper . 1 1.0 | 230.1 | 37.8 | 69.2 | . 2 1.0 | 44.5 | 39.3 | 45.1 | . 3 1.0 | 17.2 | 45.9 | 69.3 | . 4 1.0 | 151.5 | 41.3 | 58.5 | . 5 1.0 | 180.8 | 10.8 | 58.4 | . ... ... | ... | ... | ... | . 196 1.0 | 38.2 | 3.7 | 13.8 | . 197 1.0 | 94.2 | 4.9 | 8.1 | . 198 1.0 | 177.0 | 9.3 | 6.4 | . 199 1.0 | 283.6 | 42.0 | 66.2 | . 200 1.0 | 232.1 | 8.6 | 8.7 | . 200 rows × 4 columns . model = sm.OLS(y, X).fit() . model.summary() # const indicates B0 value . OLS Regression Results Dep. Variable: sales | R-squared: 0.897 | . Model: OLS | Adj. R-squared: 0.896 | . Method: Least Squares | F-statistic: 570.3 | . Date: Tue, 27 Apr 2021 | Prob (F-statistic): 1.58e-96 | . Time: 19:40:31 | Log-Likelihood: -386.18 | . No. Observations: 200 | AIC: 780.4 | . Df Residuals: 196 | BIC: 793.6 | . Df Model: 3 | | . Covariance Type: nonrobust | | . | coef std err t P&gt;|t| [0.025 0.975] . const 2.9389 | 0.312 | 9.422 | 0.000 | 2.324 | 3.554 | . TV 0.0458 | 0.001 | 32.809 | 0.000 | 0.043 | 0.049 | . radio 0.1885 | 0.009 | 21.893 | 0.000 | 0.172 | 0.206 | . newspaper -0.0010 | 0.006 | -0.177 | 0.860 | -0.013 | 0.011 | . Omnibus: 60.414 | Durbin-Watson: 2.084 | . Prob(Omnibus): 0.000 | Jarque-Bera (JB): 151.241 | . Skew: -1.327 | Prob(JB): 1.44e-33 | . Kurtosis: 6.332 | Cond. No. 454. | . Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. import matplotlib.pyplot as plt import seaborn as sns X.iloc[:,1:].corr() . TV radio newspaper . TV 1.000000 | 0.054809 | 0.056648 | . radio 0.054809 | 1.000000 | 0.354104 | . newspaper 0.056648 | 0.354104 | 1.000000 | . plt.imshow(X,cmap=&#39;autumn&#39;) plt.show() . sns.heatmap(X,linewidth = 0.5 , cmap = &#39;coolwarm&#39;) plt.show() . Using Salary DataSet, link :- . https://github.com/mr-siddy/Machine-Learning/blob/master/Linear%20Regression/Salary_Data.csv . df_salary = pd.read_csv(&#39;Salary_Data.csv&#39;) df_salary.head() . YearsExperience Age Salary . 0 1.1 | 21.0 | 39343 | . 1 1.3 | 21.5 | 46205 | . 2 1.5 | 21.7 | 37731 | . 3 2.0 | 22.0 | 43525 | . 4 2.2 | 22.2 | 39891 | . X = df_salary[[&#39;YearsExperience&#39;,&#39;Age&#39;]] y = df_salary[&#39;Salary&#39;] . fit OLS model on y and X . X = sm.add_constant(X) model = sm.OLS(y,X).fit() . model.summary() # here observe R2, const, stderr and P&gt;|t| --&gt; high correlation . OLS Regression Results Dep. Variable: Salary | R-squared: 0.960 | . Model: OLS | Adj. R-squared: 0.957 | . Method: Least Squares | F-statistic: 323.9 | . Date: Tue, 27 Apr 2021 | Prob (F-statistic): 1.35e-19 | . Time: 19:58:08 | Log-Likelihood: -300.35 | . No. Observations: 30 | AIC: 606.7 | . Df Residuals: 27 | BIC: 610.9 | . Df Model: 2 | | . Covariance Type: nonrobust | | . | coef std err t P&gt;|t| [0.025 0.975] . const -6661.9872 | 2.28e+04 | -0.292 | 0.773 | -5.35e+04 | 4.02e+04 | . YearsExperience 6153.3533 | 2337.092 | 2.633 | 0.014 | 1358.037 | 1.09e+04 | . Age 1836.0136 | 1285.034 | 1.429 | 0.165 | -800.659 | 4472.686 | . Omnibus: 2.695 | Durbin-Watson: 1.711 | . Prob(Omnibus): 0.260 | Jarque-Bera (JB): 1.975 | . Skew: 0.456 | Prob(JB): 0.372 | . Kurtosis: 2.135 | Cond. No. 626. | . Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified. X.iloc[:,1:].corr() . YearsExperience Age . YearsExperience 1.000000 | 0.987258 | . Age 0.987258 | 1.000000 | . sns.heatmap(X, cmap=&#39;summer&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x21443500808&gt; . How to Resolve . we check the P value and drop the feature which has higher p value . drop_age = X.drop(&#39;Age&#39;, axis=1) . model = sm.OLS(y,drop_age).fit() model.summary() . OLS Regression Results Dep. Variable: Salary | R-squared: 0.957 | . Model: OLS | Adj. R-squared: 0.955 | . Method: Least Squares | F-statistic: 622.5 | . Date: Tue, 27 Apr 2021 | Prob (F-statistic): 1.14e-20 | . Time: 20:07:01 | Log-Likelihood: -301.44 | . No. Observations: 30 | AIC: 606.9 | . Df Residuals: 28 | BIC: 609.7 | . Df Model: 1 | | . Covariance Type: nonrobust | | . | coef std err t P&gt;|t| [0.025 0.975] . const 2.579e+04 | 2273.053 | 11.347 | 0.000 | 2.11e+04 | 3.04e+04 | . YearsExperience 9449.9623 | 378.755 | 24.950 | 0.000 | 8674.119 | 1.02e+04 | . Omnibus: 2.140 | Durbin-Watson: 1.648 | . Prob(Omnibus): 0.343 | Jarque-Bera (JB): 1.569 | . Skew: 0.363 | Prob(JB): 0.456 | . Kurtosis: 2.147 | Cond. No. 13.2 | . Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/27/Multico-LR.html",
            "relUrl": "/2021/04/27/Multico-LR.html",
            "date": " • Apr 27, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "Multiple Linear Regrassion using 50_Startups dataset",
            "content": "dataset link :- https://www.kaggle.com/farhanmd29/50-startups . Import Libraries and Creating Dataframe . import numpy as np import matplotlib.pyplot as plt import pandas as pd . dataset = pd.read_csv(&quot;50_Startups.csv&quot;,&quot;,&quot;) dataset.head() . R&amp;D Spend Administration Marketing Spend State Profit . 0 165349.20 | 136897.80 | 471784.10 | New York | 192261.83 | . 1 162597.70 | 151377.59 | 443898.53 | California | 191792.06 | . 2 153441.51 | 101145.55 | 407934.54 | Florida | 191050.39 | . 3 144372.41 | 118671.85 | 383199.62 | New York | 182901.99 | . 4 142107.34 | 91391.77 | 366168.42 | Florida | 166187.94 | . X = dataset.iloc[:, :-1] y = dataset.iloc[:,4] . print(X.head(),&quot; n&quot;) print(y.head()) . R&amp;D Spend Administration Marketing Spend State 0 165349.20 136897.80 471784.10 New York 1 162597.70 151377.59 443898.53 California 2 153441.51 101145.55 407934.54 Florida 3 144372.41 118671.85 383199.62 New York 4 142107.34 91391.77 366168.42 Florida 0 192261.83 1 191792.06 2 191050.39 3 182901.99 4 166187.94 Name: Profit, dtype: float64 . Data Preprocessing . states=pd.get_dummies(X[&#39;State&#39;],drop_first=True) #get_dummies helps to create dummy variables wrt no of categorial fratures # drop_first = True helps us to create dummy variable trap . X = X.drop(&#39;State&#39;,axis=1) . X . R&amp;D Spend Administration Marketing Spend . 0 165349.20 | 136897.80 | 471784.10 | . 1 162597.70 | 151377.59 | 443898.53 | . 2 153441.51 | 101145.55 | 407934.54 | . 3 144372.41 | 118671.85 | 383199.62 | . 4 142107.34 | 91391.77 | 366168.42 | . 5 131876.90 | 99814.71 | 362861.36 | . 6 134615.46 | 147198.87 | 127716.82 | . 7 130298.13 | 145530.06 | 323876.68 | . 8 120542.52 | 148718.95 | 311613.29 | . 9 123334.88 | 108679.17 | 304981.62 | . 10 101913.08 | 110594.11 | 229160.95 | . 11 100671.96 | 91790.61 | 249744.55 | . 12 93863.75 | 127320.38 | 249839.44 | . 13 91992.39 | 135495.07 | 252664.93 | . 14 119943.24 | 156547.42 | 256512.92 | . 15 114523.61 | 122616.84 | 261776.23 | . 16 78013.11 | 121597.55 | 264346.06 | . 17 94657.16 | 145077.58 | 282574.31 | . 18 91749.16 | 114175.79 | 294919.57 | . 19 86419.70 | 153514.11 | 0.00 | . 20 76253.86 | 113867.30 | 298664.47 | . 21 78389.47 | 153773.43 | 299737.29 | . 22 73994.56 | 122782.75 | 303319.26 | . 23 67532.53 | 105751.03 | 304768.73 | . 24 77044.01 | 99281.34 | 140574.81 | . 25 64664.71 | 139553.16 | 137962.62 | . 26 75328.87 | 144135.98 | 134050.07 | . 27 72107.60 | 127864.55 | 353183.81 | . 28 66051.52 | 182645.56 | 118148.20 | . 29 65605.48 | 153032.06 | 107138.38 | . 30 61994.48 | 115641.28 | 91131.24 | . 31 61136.38 | 152701.92 | 88218.23 | . 32 63408.86 | 129219.61 | 46085.25 | . 33 55493.95 | 103057.49 | 214634.81 | . 34 46426.07 | 157693.92 | 210797.67 | . 35 46014.02 | 85047.44 | 205517.64 | . 36 28663.76 | 127056.21 | 201126.82 | . 37 44069.95 | 51283.14 | 197029.42 | . 38 20229.59 | 65947.93 | 185265.10 | . 39 38558.51 | 82982.09 | 174999.30 | . 40 28754.33 | 118546.05 | 172795.67 | . 41 27892.92 | 84710.77 | 164470.71 | . 42 23640.93 | 96189.63 | 148001.11 | . 43 15505.73 | 127382.30 | 35534.17 | . 44 22177.74 | 154806.14 | 28334.72 | . 45 1000.23 | 124153.04 | 1903.93 | . 46 1315.46 | 115816.21 | 297114.46 | . 47 0.00 | 135426.92 | 0.00 | . 48 542.05 | 51743.15 | 0.00 | . 49 0.00 | 116983.80 | 45173.06 | . print(states.head()) . Florida New York 0 0 1 1 0 0 2 1 0 3 0 1 4 1 0 . X=pd.concat([X,states],axis=1) . print(X.head()) # Now we will apply y=b0+b1x1+b2x2+....... . R&amp;D Spend Administration Marketing Spend Florida New York 0 165349.20 136897.80 471784.10 0 1 1 162597.70 151377.59 443898.53 0 0 2 153441.51 101145.55 407934.54 1 0 3 144372.41 118671.85 383199.62 0 1 4 142107.34 91391.77 366168.42 1 0 . Train_test_split . from sklearn.model_selection import train_test_split . X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=0) . y_test . 28 103282.38 11 144259.40 10 146121.95 41 77798.83 2 191050.39 27 105008.31 38 81229.06 31 97483.56 22 110352.25 4 166187.94 Name: Profit, dtype: float64 . Applying Linear Regression . from sklearn.linear_model import LinearRegression . regressor = LinearRegression() regressor.fit(X_train, y_train) . LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) . y_pred = regressor.predict(X_test) . y_pred . array([103015.20159796, 132582.27760816, 132447.73845174, 71976.09851258, 178537.48221055, 116161.24230165, 67851.69209676, 98791.73374687, 113969.43533012, 167921.0656955 ]) . from sklearn.metrics import r2_score # r2 = 1-(sum_of_residual/sum_of_mean) also model is good if r2 --&gt; 1 score= r2_score(y_test,y_pred) . score . 0.9347068473282423 .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/26/multiple-linear-regression.html",
            "relUrl": "/2021/04/26/multiple-linear-regression.html",
            "date": " • Apr 26, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "Simple, Ridge and Lasso Linear Regression",
            "content": "import pandas as pd import numpy as np import matplotlib.pyplot as plt from sklearn import linear_model import seaborn as sns . from sklearn.datasets import load_boston . df = load_boston() . df . {&#39;data&#39;: array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02, 4.9800e+00], [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02, 9.1400e+00], [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02, 4.0300e+00], ..., [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02, 5.6400e+00], [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02, 6.4800e+00], [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02, 7.8800e+00]]), &#39;target&#39;: array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. , 18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6, 15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2, 13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7, 21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9, 35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5, 19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. , 20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2, 23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8, 33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4, 21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. , 20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6, 23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4, 15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4, 17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7, 25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4, 23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. , 32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3, 34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4, 20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. , 26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3, 31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1, 22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6, 42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. , 36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4, 32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. , 20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1, 20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2, 22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1, 21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6, 19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7, 32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1, 18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8, 16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8, 13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3, 8.8, 7.2, 10.5, 7.4, 10.2, 11.5, 15.1, 23.2, 9.7, 13.8, 12.7, 13.1, 12.5, 8.5, 5. , 6.3, 5.6, 7.2, 12.1, 8.3, 8.5, 5. , 11.9, 27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3, 7. , 7.2, 7.5, 10.4, 8.8, 8.4, 16.7, 14.2, 20.8, 13.4, 11.7, 8.3, 10.2, 10.9, 11. , 9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4, 9.6, 8.7, 8.4, 12.8, 10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4, 15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7, 19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2, 29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8, 20.6, 21.2, 19.1, 20.6, 15.2, 7. , 8.1, 13.6, 20.1, 21.8, 24.5, 23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), &#39;feature_names&#39;: array([&#39;CRIM&#39;, &#39;ZN&#39;, &#39;INDUS&#39;, &#39;CHAS&#39;, &#39;NOX&#39;, &#39;RM&#39;, &#39;AGE&#39;, &#39;DIS&#39;, &#39;RAD&#39;, &#39;TAX&#39;, &#39;PTRATIO&#39;, &#39;B&#39;, &#39;LSTAT&#39;], dtype=&#39;&lt;U7&#39;), &#39;DESCR&#39;: &#34;.. _boston_dataset: n nBoston house prices dataset n n n**Data Set Characteristics:** n n :Number of Instances: 506 n n :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target. n n :Attribute Information (in order): n - CRIM per capita crime rate by town n - ZN proportion of residential land zoned for lots over 25,000 sq.ft. n - INDUS proportion of non-retail business acres per town n - CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) n - NOX nitric oxides concentration (parts per 10 million) n - RM average number of rooms per dwelling n - AGE proportion of owner-occupied units built prior to 1940 n - DIS weighted distances to five Boston employment centres n - RAD index of accessibility to radial highways n - TAX full-value property-tax rate per $10,000 n - PTRATIO pupil-teacher ratio by town n - B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town n - LSTAT % lower status of the population n - MEDV Median value of owner-occupied homes in $1000&#39;s n n :Missing Attribute Values: None n n :Creator: Harrison, D. and Rubinfeld, D.L. n nThis is a copy of UCI ML housing dataset. nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/ n n nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. n nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. &#39;Hedonic nprices and the demand for clean air&#39;, J. Environ. Economics &amp; Management, nvol.5, 81-102, 1978. Used in Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics n...&#39;, Wiley, 1980. N.B. Various transformations are used in the table on npages 244-261 of the latter. n nThe Boston house-price data has been used in many machine learning papers that address regression nproblems. n n.. topic:: References n n - Belsley, Kuh &amp; Welsch, &#39;Regression diagnostics: Identifying Influential Data and Sources of Collinearity&#39;, Wiley, 1980. 244-261. n - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann. n&#34;, &#39;filename&#39;: &#39;C: Users mrsid anaconda3 lib site-packages sklearn datasets data boston_house_prices.csv&#39;} . dataset= pd.DataFrame(df.data) print(dataset.head()) . 0 1 2 3 4 5 6 7 8 9 10 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 11 12 0 396.90 4.98 1 396.90 9.14 2 392.83 4.03 3 394.63 2.94 4 396.90 5.33 . dataset.head() . 0 1 2 3 4 5 6 7 8 9 10 11 12 . 0 0.00632 | 18.0 | 2.31 | 0.0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1.0 | 296.0 | 15.3 | 396.90 | 4.98 | . 1 0.02731 | 0.0 | 7.07 | 0.0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2.0 | 242.0 | 17.8 | 396.90 | 9.14 | . 2 0.02729 | 0.0 | 7.07 | 0.0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2.0 | 242.0 | 17.8 | 392.83 | 4.03 | . 3 0.03237 | 0.0 | 2.18 | 0.0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3.0 | 222.0 | 18.7 | 394.63 | 2.94 | . 4 0.06905 | 0.0 | 2.18 | 0.0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3.0 | 222.0 | 18.7 | 396.90 | 5.33 | . dataset.columns=df.feature_names . dataset.head() . CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT . 0 0.00632 | 18.0 | 2.31 | 0.0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1.0 | 296.0 | 15.3 | 396.90 | 4.98 | . 1 0.02731 | 0.0 | 7.07 | 0.0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2.0 | 242.0 | 17.8 | 396.90 | 9.14 | . 2 0.02729 | 0.0 | 7.07 | 0.0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2.0 | 242.0 | 17.8 | 392.83 | 4.03 | . 3 0.03237 | 0.0 | 2.18 | 0.0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3.0 | 222.0 | 18.7 | 394.63 | 2.94 | . 4 0.06905 | 0.0 | 2.18 | 0.0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3.0 | 222.0 | 18.7 | 396.90 | 5.33 | . df.target.shape . (506,) . dataset[&quot;price&quot;]=df.target . dataset.head() . CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT price . 0 0.00632 | 18.0 | 2.31 | 0.0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1.0 | 296.0 | 15.3 | 396.90 | 4.98 | 24.0 | . 1 0.02731 | 0.0 | 7.07 | 0.0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2.0 | 242.0 | 17.8 | 396.90 | 9.14 | 21.6 | . 2 0.02729 | 0.0 | 7.07 | 0.0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2.0 | 242.0 | 17.8 | 392.83 | 4.03 | 34.7 | . 3 0.03237 | 0.0 | 2.18 | 0.0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3.0 | 222.0 | 18.7 | 394.63 | 2.94 | 33.4 | . 4 0.06905 | 0.0 | 2.18 | 0.0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3.0 | 222.0 | 18.7 | 396.90 | 5.33 | 36.2 | . X=dataset.iloc[:,:-1] # independent fratures y=dataset.iloc[:,-1] # dependent frature . Linear Regression . from sklearn.model_selection import cross_val_score from sklearn.linear_model import LinearRegression lin_regressor = LinearRegression() mse = cross_val_score(lin_regressor,X,y,scoring=&#39;neg_mean_squared_error&#39;,cv=5) #cv=crossvalidation mean_mse = np.mean(mse) print(mean_mse) # this value should be nearer to zero . -37.13180746769922 . Ridge Regression . from sklearn.linear_model import Ridge from sklearn.model_selection import GridSearchCV ridge=Ridge() parameters = {&#39;alpha&#39;:[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]} ridge_regressor=GridSearchCV(ridge,parameters,scoring = &#39;neg_mean_squared_error&#39;,cv=5) ridge_regressor.fit(X,y) . GridSearchCV(cv=5, error_score=nan, estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=None, solver=&#39;auto&#39;, tol=0.001), iid=&#39;deprecated&#39;, n_jobs=None, param_grid={&#39;alpha&#39;: [1e-15, 1e-10, 1e-08, 0.001, 0.01, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}, pre_dispatch=&#39;2*n_jobs&#39;, refit=True, return_train_score=False, scoring=&#39;neg_mean_squared_error&#39;, verbose=0) . print(ridge_regressor.best_params_) print(ridge_regressor.best_score_) . {&#39;alpha&#39;: 100} -29.905701947540365 . Lasso Regression . from sklearn.linear_model import Lasso from sklearn.model_selection import GridSearchCV lasso=Lasso() parameters = {&#39;alpha&#39;:[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]} Lasso_regressor=GridSearchCV(lasso,parameters,scoring = &#39;neg_mean_squared_error&#39;,cv=5) Lasso_regressor.fit(X,y) print(Lasso_regressor.best_params_) print(Lasso_regressor.best_score_) . {&#39;alpha&#39;: 1} -35.531580220694856 . C: Users mrsid anaconda3 lib site-packages sklearn linear_model _coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4430.746729651311, tolerance: 3.9191485420792076 positive) C: Users mrsid anaconda3 lib site-packages sklearn linear_model _coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4397.459304778431, tolerance: 3.3071316790123455 positive) C: Users mrsid anaconda3 lib site-packages sklearn linear_model _coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3796.653037433508, tolerance: 2.813643886419753 positive) C: Users mrsid anaconda3 lib site-packages sklearn linear_model _coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2564.292735790545, tolerance: 3.3071762123456794 positive) C: Users mrsid anaconda3 lib site-packages sklearn linear_model _coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4294.252997826028, tolerance: 3.4809104444444445 positive) . from sklearn.model_selection import train_test_split X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0) . prediction_lasso=Lasso_regressor.predict(X_test) prediction_ridge=ridge_regressor.predict(X_test) . Plotting of results . import seaborn as sns sns.distplot(y_test-prediction_lasso) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x20e4370d588&gt; . sns.distplot(y_test-prediction_ridge) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x20e437ebf48&gt; . sns.distplot(y_test-mean_mse) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x20e438e2e48&gt; .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/26/Regression-on-Boston-Housing-Dataset.html",
            "relUrl": "/2021/04/26/Regression-on-Boston-Housing-Dataset.html",
            "date": " • Apr 26, 2021"
        }
        
    
  
    
        ,"post24": {
            "title": "EDA with Python and Applying Logistic Regression",
            "content": "Import Libraries . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline . The Data . train = pd.read_csv(&#39;titanic_train.csv&#39;) . train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . Missing Data . train.isnull() # if True indicates a null value # but it is not a good way as data set can be vast . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 False | False | False | False | False | False | False | False | False | False | True | False | . 1 False | False | False | False | False | False | False | False | False | False | False | False | . 2 False | False | False | False | False | False | False | False | False | False | True | False | . 3 False | False | False | False | False | False | False | False | False | False | False | False | . 4 False | False | False | False | False | False | False | False | False | False | True | False | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 False | False | False | False | False | False | False | False | False | False | True | False | . 887 False | False | False | False | False | False | False | False | False | False | False | False | . 888 False | False | False | False | False | True | False | False | False | False | True | False | . 889 False | False | False | False | False | False | False | False | False | False | False | False | . 890 False | False | False | False | False | False | False | False | False | False | True | False | . 891 rows × 12 columns . sns.heatmap(train.isnull(),yticklabels = False, cbar =False, cmap=&#39;viridis&#39;) # so most of the null values are present in age and cabin . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a91cd84c8&gt; . sns.set_style(&#39;whitegrid&#39;) sns.countplot(x=&#39;Survived&#39;,data=train) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a91d397c8&gt; . sns.set_style(&#39;whitegrid&#39;) sns.countplot(x=&#39;Survived&#39;,hue=&#39;Sex&#39;,data=train, palette=&#39;RdBu_r&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92b67d88&gt; . sns.set_style(&#39;whitegrid&#39;) sns.countplot(x=&#39;Survived&#39;,hue=&#39;Pclass&#39;,data=train, palette=&#39;rainbow&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92c2ee88&gt; . sns.distplot(train[&#39;Age&#39;].dropna(), kde=False, color=&#39;darkred&#39;, bins=40) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92ca32c8&gt; . train[&#39;Age&#39;].hist(bins=30, color=&#39;blue&#39;,alpha=0.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92daeb88&gt; . sns.countplot(x=&#39;SibSp&#39;, data=train) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92e6f2c8&gt; . train[&#39;Fare&#39;].hist(bins=30,color=&#39;green&#39;,alpha=0.4) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92ed4e48&gt; . Data Cleaning . plt.figure(figsize=(12,7)) sns.boxplot(x=&#39;Pclass&#39;,y=&#39;Age&#39;,data=train,palette=&#39;winter&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92c2e5c8&gt; . we can see the wealthrer passengers in the higher classes tend to older, which makes sense, we&#39;ll use these average age values to impute based on pcalss for age . def impute_age(cols): Age = cols[0] Pclass = cols[1] if pd.isnull(Age): if Pclass == 1: return 37 elif Pclass == 2: return 29 else: return 24 else: return Age . train[&#39;Age&#39;] = train [[&#39;Age&#39;,&#39;Pclass&#39;]].apply(impute_age,axis=1 ) # now check heatmap again . sns.heatmap(train.isnull(),yticklabels = False, cbar =False, cmap=&#39;viridis&#39;) # so most of the null values are present in age and cabin . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a931ec508&gt; . we have to apply a lot of feature engineering to handle Cabin coz of a lot of Nan values hence we&#39;ll drop it for now . train.drop(&#39;Cabin&#39;,axis=1,inplace=True) . sns.heatmap(train.isnull(),yticklabels = False, cbar =False, cmap=&#39;viridis&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a93031ac8&gt; . train.dropna(inplace=True) . sns.heatmap(train.isnull(),yticklabels = False, cbar =False, cmap=&#39;viridis&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a930b6148&gt; . train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | S | . Converting Categorical Features . we&#39;ll need to convert categorical features to dummy variables using pandas, otherwise our machine learning algorithm wont be able to directly take in those features as inputs . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 889 entries, 0 to 890 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 889 non-null int64 1 Survived 889 non-null int64 2 Pclass 889 non-null int64 3 Name 889 non-null object 4 Sex 889 non-null object 5 Age 889 non-null float64 6 SibSp 889 non-null int64 7 Parch 889 non-null int64 8 Ticket 889 non-null object 9 Fare 889 non-null float64 10 Embarked 889 non-null object dtypes: float64(2), int64(5), object(4) memory usage: 83.3+ KB . pd.get_dummies(train[&#39;Embarked&#39;],drop_first=True).head() . Q S . 0 0 | 1 | . 1 0 | 0 | . 2 0 | 1 | . 3 0 | 1 | . 4 0 | 1 | . sex = pd.get_dummies(train[&#39;Sex&#39;],drop_first=True) embark = pd.get_dummies(train[&#39;Embarked&#39;],drop_first=True) . train.drop([&#39;Sex&#39;,&#39;Embarked&#39;,&#39;Name&#39;,&#39;Ticket&#39;],axis=1,inplace=True) . train.head() . PassengerId Survived Pclass Age SibSp Parch Fare . 0 1 | 0 | 3 | 22.0 | 1 | 0 | 7.2500 | . 1 2 | 1 | 1 | 38.0 | 1 | 0 | 71.2833 | . 2 3 | 1 | 3 | 26.0 | 0 | 0 | 7.9250 | . 3 4 | 1 | 1 | 35.0 | 1 | 0 | 53.1000 | . 4 5 | 0 | 3 | 35.0 | 0 | 0 | 8.0500 | . train = pd.concat([train,sex,embark],axis=1) . train.head() . PassengerId Survived Pclass Age SibSp Parch Fare male Q S . 0 1 | 0 | 3 | 22.0 | 1 | 0 | 7.2500 | 1 | 0 | 1 | . 1 2 | 1 | 1 | 38.0 | 1 | 0 | 71.2833 | 0 | 0 | 0 | . 2 3 | 1 | 3 | 26.0 | 0 | 0 | 7.9250 | 0 | 0 | 1 | . 3 4 | 1 | 1 | 35.0 | 1 | 0 | 53.1000 | 0 | 0 | 1 | . 4 5 | 0 | 3 | 35.0 | 0 | 0 | 8.0500 | 1 | 0 | 1 | . Building a Logistic Regression Model . Train Test Split . train.drop(&#39;Survived&#39;,axis=1).head() . PassengerId Pclass Age SibSp Parch Fare male Q S . 0 1 | 3 | 22.0 | 1 | 0 | 7.2500 | 1 | 0 | 1 | . 1 2 | 1 | 38.0 | 1 | 0 | 71.2833 | 0 | 0 | 0 | . 2 3 | 3 | 26.0 | 0 | 0 | 7.9250 | 0 | 0 | 1 | . 3 4 | 1 | 35.0 | 1 | 0 | 53.1000 | 0 | 0 | 1 | . 4 5 | 3 | 35.0 | 0 | 0 | 8.0500 | 1 | 0 | 1 | . train[&#39;Survived&#39;].head() . 0 0 1 1 2 1 3 1 4 0 Name: Survived, dtype: int64 . from sklearn.model_selection import train_test_split . X_train,X_test,y_train,y_test = train_test_split(train.drop(&#39;Survived&#39;,axis=1),train[&#39;Survived&#39;],test_size=0.30,random_state=101) . Training and Predicting . from sklearn.linear_model import LogisticRegression . logmodel = LogisticRegression() logmodel.fit(X_train,y_train) . C: Users mrsid anaconda3 lib site-packages sklearn linear_model _logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG) . LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0, warm_start=False) . predictions = logmodel.predict(X_test) . from sklearn.metrics import confusion_matrix . accuracy = confusion_matrix(y_test,predictions) . accuracy . array([[149, 14], [ 39, 65]], dtype=int64) . from sklearn.metrics import accuracy_score . accuracy = accuracy_score(y_test,predictions) accuracy . 0.8014981273408239 . predictions . array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1], dtype=int64) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/25/EDA.html",
            "relUrl": "/2021/04/25/EDA.html",
            "date": " • Apr 25, 2021"
        }
        
    
  
    
        ,"post25": {
            "title": "Exploratory Data Analysis on Iris Dataset",
            "content": "dataset link :- https://archive.ics.uci.edu/ml/datasets/Iris . Import all libraries . import pandas as pd import seaborn as sns import numpy as np import matplotlib.pyplot as plt . Creating DataFrame . df = pd.read_csv(&quot;https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv&quot;) . df.head() . sepal_length sepal_width petal_length petal_width species . 0 5.1 | 3.5 | 1.4 | 0.2 | setosa | . 1 4.9 | 3.0 | 1.4 | 0.2 | setosa | . 2 4.7 | 3.2 | 1.3 | 0.2 | setosa | . 3 4.6 | 3.1 | 1.5 | 0.2 | setosa | . 4 5.0 | 3.6 | 1.4 | 0.2 | setosa | . df.shape . (150, 5) . Univariate Analysis . df.loc[df[&#39;species&#39;]==&#39;setosa&#39;] . sepal_length sepal_width petal_length petal_width species . 0 5.1 | 3.5 | 1.4 | 0.2 | setosa | . 1 4.9 | 3.0 | 1.4 | 0.2 | setosa | . 2 4.7 | 3.2 | 1.3 | 0.2 | setosa | . 3 4.6 | 3.1 | 1.5 | 0.2 | setosa | . 4 5.0 | 3.6 | 1.4 | 0.2 | setosa | . 5 5.4 | 3.9 | 1.7 | 0.4 | setosa | . 6 4.6 | 3.4 | 1.4 | 0.3 | setosa | . 7 5.0 | 3.4 | 1.5 | 0.2 | setosa | . 8 4.4 | 2.9 | 1.4 | 0.2 | setosa | . 9 4.9 | 3.1 | 1.5 | 0.1 | setosa | . 10 5.4 | 3.7 | 1.5 | 0.2 | setosa | . 11 4.8 | 3.4 | 1.6 | 0.2 | setosa | . 12 4.8 | 3.0 | 1.4 | 0.1 | setosa | . 13 4.3 | 3.0 | 1.1 | 0.1 | setosa | . 14 5.8 | 4.0 | 1.2 | 0.2 | setosa | . 15 5.7 | 4.4 | 1.5 | 0.4 | setosa | . 16 5.4 | 3.9 | 1.3 | 0.4 | setosa | . 17 5.1 | 3.5 | 1.4 | 0.3 | setosa | . 18 5.7 | 3.8 | 1.7 | 0.3 | setosa | . 19 5.1 | 3.8 | 1.5 | 0.3 | setosa | . 20 5.4 | 3.4 | 1.7 | 0.2 | setosa | . 21 5.1 | 3.7 | 1.5 | 0.4 | setosa | . 22 4.6 | 3.6 | 1.0 | 0.2 | setosa | . 23 5.1 | 3.3 | 1.7 | 0.5 | setosa | . 24 4.8 | 3.4 | 1.9 | 0.2 | setosa | . 25 5.0 | 3.0 | 1.6 | 0.2 | setosa | . 26 5.0 | 3.4 | 1.6 | 0.4 | setosa | . 27 5.2 | 3.5 | 1.5 | 0.2 | setosa | . 28 5.2 | 3.4 | 1.4 | 0.2 | setosa | . 29 4.7 | 3.2 | 1.6 | 0.2 | setosa | . 30 4.8 | 3.1 | 1.6 | 0.2 | setosa | . 31 5.4 | 3.4 | 1.5 | 0.4 | setosa | . 32 5.2 | 4.1 | 1.5 | 0.1 | setosa | . 33 5.5 | 4.2 | 1.4 | 0.2 | setosa | . 34 4.9 | 3.1 | 1.5 | 0.1 | setosa | . 35 5.0 | 3.2 | 1.2 | 0.2 | setosa | . 36 5.5 | 3.5 | 1.3 | 0.2 | setosa | . 37 4.9 | 3.1 | 1.5 | 0.1 | setosa | . 38 4.4 | 3.0 | 1.3 | 0.2 | setosa | . 39 5.1 | 3.4 | 1.5 | 0.2 | setosa | . 40 5.0 | 3.5 | 1.3 | 0.3 | setosa | . 41 4.5 | 2.3 | 1.3 | 0.3 | setosa | . 42 4.4 | 3.2 | 1.3 | 0.2 | setosa | . 43 5.0 | 3.5 | 1.6 | 0.6 | setosa | . 44 5.1 | 3.8 | 1.9 | 0.4 | setosa | . 45 4.8 | 3.0 | 1.4 | 0.3 | setosa | . 46 5.1 | 3.8 | 1.6 | 0.2 | setosa | . 47 4.6 | 3.2 | 1.4 | 0.2 | setosa | . 48 5.3 | 3.7 | 1.5 | 0.2 | setosa | . 49 5.0 | 3.3 | 1.4 | 0.2 | setosa | . df_setosa=df.loc[df[&#39;species&#39;]==&#39;setosa&#39;] df_virginica=df.loc[df[&#39;species&#39;]==&#39;virginica&#39;] df_versicolor=df.loc[df[&#39;species&#39;]==&#39;versicolor&#39;] . plt.plot(df_setosa[&#39;sepal_length&#39;],np.zeros_like(df_setosa[&#39;sepal_length&#39;]),&#39;o&#39;) plt.plot(df_virginica[&#39;sepal_length&#39;],np.zeros_like(df_virginica[&#39;sepal_length&#39;]),&#39;o&#39;) plt.plot(df_versicolor[&#39;sepal_length&#39;],np.zeros_like(df_versicolor[&#39;sepal_length&#39;]),&#39;o&#39;) plt.xlabel(&quot;sepal_length&quot;) plt.show() . Bivariate Analysis . sns.FacetGrid(df,hue=&#39;species&#39;,size=5).map(plt.scatter,&quot;petal_length&quot;,&quot;sepal_width&quot;).add_legend(); plt.show() . Multivariate Analysis . sns.pairplot(df,hue=&#39;species&#39;,size=3) . C: Users mrsid anaconda3 lib site-packages seaborn axisgrid.py:2079: UserWarning: The `size` parameter has been renamed to `height`; please update your code. warnings.warn(msg, UserWarning) . &lt;seaborn.axisgrid.PairGrid at 0x13024488808&gt; .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/24/EDA-IRIS.html",
            "relUrl": "/2021/04/24/EDA-IRIS.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post26": {
            "title": "Seaborn || sns",
            "content": "Distribution plots . distplot, joinplot, pairplot . import seaborn as sns import numpy as np . df = sns.load_dataset(&quot;tips&quot;) . df.head() # tip is dependent feature # others are independent features . total_bill tip sex smoker day time size . 0 16.99 | 1.01 | Female | No | Sun | Dinner | 2 | . 1 10.34 | 1.66 | Male | No | Sun | Dinner | 3 | . 2 21.01 | 3.50 | Male | No | Sun | Dinner | 3 | . 3 23.68 | 3.31 | Male | No | Sun | Dinner | 2 | . 4 24.59 | 3.61 | Female | No | Sun | Dinner | 4 | . df.dtypes . total_bill float64 tip float64 sex category smoker category day category time category size int64 dtype: object . Correlation with Heatmap . df.corr() # correlarion can only be found out if values are floating point or integers # corr values range b/w -1 to +1 . total_bill tip size . total_bill 1.000000 | 0.675734 | 0.598315 | . tip 0.675734 | 1.000000 | 0.489299 | . size 0.598315 | 0.489299 | 1.000000 | . Observations :- 1) +ve corr -&gt;&gt; Total bill inc then tip will also inc . sns.heatmap(df.corr()) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d218d27108&gt; . JointPlot . Univariate analysis . sns.jointplot(x=&#39;tip&#39;,y=&#39;total_bill&#39;,data=df,kind=&#39;hex&#39;) # hex=hexagonal shape . &lt;seaborn.axisgrid.JointGrid at 0x2d219541988&gt; . sns.jointplot(x=&#39;tip&#39;,y=&#39;total_bill&#39;,data=df,kind=&#39;reg&#39;) # reg gives probablity density line(on graph) and regression line (inside plot) . &lt;seaborn.axisgrid.JointGrid at 0x2d2197b6d88&gt; . Pair plot . same data row is matched with another variable&#39;s value . sns.pairplot(df, hue=&#39;sex&#39;) . &lt;seaborn.axisgrid.PairGrid at 0x2d219f05bc8&gt; . Dist Plot . sns.distplot(df[&#39;tip&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21a51bcc8&gt; . sns.distplot(df[&#39;tip&#39;],kde =False,bins=10) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21a657dc8&gt; . Categorical Plots . Count Plot . sns.countplot(&#39;sex&#39;,data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21a6d2688&gt; . Bar Plot . sns.barplot(x=&#39;total_bill&#39;,y=&#39;sex&#39;,data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21b8f2788&gt; . Box Plot . sns.boxplot(&#39;sex&#39;, &#39;total_bill&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21b950348&gt; . sns.boxplot(x=&#39;day&#39;, y=&#39;total_bill&#39;, data=df, palette=&#39;rainbow&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21b9b9a48&gt; . sns.boxplot(data=df, orient=&#39;v&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21baf1708&gt; . sns.boxplot(x=&#39;total_bill&#39;, y=&#39;day&#39;, hue=&#39;smoker&#39;, data=df) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21bb73288&gt; . Violin Plot . sns.violinplot(x=&quot;total_bill&quot;,y=&#39;day&#39;,data=df, palette=&#39;rainbow&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x2d21bc73488&gt; .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/23/Seaborn.html",
            "relUrl": "/2021/04/23/Seaborn.html",
            "date": " • Apr 23, 2021"
        }
        
    
  
    
        ,"post27": {
            "title": "Matplotlib || plt",
            "content": "import matplotlib.pyplot as plt %matplotlib inline . import numpy as np . x = np.arange(0,10) y=np.arange(11,21) . a=np.arange(40,50) b=np.arange(50,60) . Scatter plot . plt.scatter(x,y,c=&#39;g&#39;) # c= color plt.xlabel(&#39;X axis&#39;) plt.ylabel(&#39;Y axis&#39;) plt.title(&#39;Graph in 2D&#39;) plt.savefig(&#39;g1.png&#39;) plt.show() . plt plot . plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x20b5b3bef48&gt;] . y=x*x plt.plot(x,y) . [&lt;matplotlib.lines.Line2D at 0x20b5b4228c8&gt;] . plt.plot(x,y,&#39;r&#39;) . [&lt;matplotlib.lines.Line2D at 0x20b5b447d08&gt;] . plt.plot(x,y,&#39;r--&#39;) . [&lt;matplotlib.lines.Line2D at 0x20b5b4ef748&gt;] . plt.plot(x,y,&#39;r*-&#39;) . [&lt;matplotlib.lines.Line2D at 0x20b5b562fc8&gt;] . Subplots . plt.subplot(2,2,1) # 2 rows 2 cols 1 position plt.plot(x,y,&#39;r&#39;) plt.subplot(2,2,2) plt.plot(x,y,&#39;g&#39;) plt.subplot(2,2,3) plt.plot(x,y,&#39;b&#39;) . [&lt;matplotlib.lines.Line2D at 0x20b5b61f088&gt;] . . np.pi . 3.141592653589793 . x = np.arange(0,4*np.pi,0.1) y=np.sin(x) plt.title(&quot;sine wave form&quot;) plt.plot(x,y) plt.show() . x=np.arange(0,5*np.pi,0.1) y_sin = np.sin(x) y_cos = np.cos(x) plt.subplot(2,1,1) plt.plot(x,y_sin,&#39;r--&#39;) plt.title(&quot;sine graph&quot;) plt.subplot(2,1,2) plt.plot(x,y_cos,&#39;g--&#39;) plt.title(&quot;cosine graph&quot;) plt.show() . Bar plot . x= [2,8,10] y = [11,16,18] x2 = [3,9,11] y2 = [4,7,9] plt.bar(x,y) plt.bar(x2,y2,color =&#39;g&#39;) plt.title(&#39;Bar graph&#39;) plt.ylabel( &#39;Yaxis&#39;) plt.xlabel( &#39;Xaxis&#39;) plt.show() . Histograms . a = np.array([1,2,3,4,5,5,6,67,7,8,8,9]) # y axis == bins - desity or count plt.hist(a) plt.title(&#39;histogram&#39;) plt.show() . Box plot . data = [np.random.normal(0,std,100) for std in range(1,4)] # selecting a normal distribution b/w low=0, to std, step=100 # rectangular box plot plt.boxplot(data, vert=True, patch_artist= True) . {&#39;whiskers&#39;: [&lt;matplotlib.lines.Line2D at 0x20b5bb46688&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb46f08&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb55d08&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb55e88&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb6b188&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb6ba08&gt;], &#39;caps&#39;: [&lt;matplotlib.lines.Line2D at 0x20b5bb4b8c8&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb4bf48&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb5bdc8&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb5bec8&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb6bb88&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb71a08&gt;], &#39;boxes&#39;: [&lt;matplotlib.patches.PathPatch at 0x20b5bb46048&gt;, &lt;matplotlib.patches.PathPatch at 0x20b5bb50fc8&gt;, &lt;matplotlib.patches.PathPatch at 0x20b5bb65ac8&gt;], &#39;medians&#39;: [&lt;matplotlib.lines.Line2D at 0x20b5bb4bfc8&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb5fd08&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb71b88&gt;], &#39;fliers&#39;: [&lt;matplotlib.lines.Line2D at 0x20b5bb50f08&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb5fe08&gt;, &lt;matplotlib.lines.Line2D at 0x20b5bb76a08&gt;], &#39;means&#39;: []} . data . [array([-0.7784494 , -0.30130908, 0.54002525, -0.51800759, 0.01819769, -0.83990426, -0.28781469, 0.04318482, 1.23528389, 2.1785494 , -2.0737086 , 1.0928547 , -0.0187436 , 1.26047616, -0.22879622, 0.7987299 , -1.32200805, 1.5095032 , -0.90634209, -0.88452427, 0.21450132, -0.33105648, -0.89893418, 0.2640048 , 0.18846496, -0.13365763, -0.56769452, 1.70685974, 2.50448167, -0.71739823, -2.15135456, -0.79866835, 0.01126657, 0.03509671, 0.70977944, -0.48825295, -0.51388798, 0.03850738, -0.11959896, -1.44425172, -0.48869629, 1.99891486, -0.79457436, 0.82734671, -0.21331385, -1.01447424, -1.62881497, 1.55287689, -0.76185124, -1.33031956, -0.24552639, 0.07408732, -2.05106282, 1.08293709, -0.39720809, -0.37170031, -0.78308727, 0.94345425, -1.61168896, 0.75191668, -0.19178661, 0.35292808, -0.32761845, -0.12057788, -0.90665516, 0.61673275, 0.3552815 , -0.75085115, 0.95438335, -0.4752099 , -1.22754795, 0.90739187, 0.98549253, 1.17860435, -0.47033725, -1.11863367, -2.1007785 , -1.28848407, -0.97587155, -1.50746364, 0.15689869, -1.29434923, 0.95408283, 0.38562582, 1.09328084, -0.83567472, 1.46300781, 0.21707649, 1.04889211, 0.13129867, 0.78442675, 0.21995366, 1.63712729, 1.50326651, 0.28453443, -0.2031552 , -0.28490282, 1.33678566, 2.37008989, 0.79503051]), array([ 1.23556973, -0.02072204, -1.12229404, -2.96722053, -1.30085601, -2.60421508, 1.24700109, -0.31148209, -2.52475577, -3.79873713, -0.5184776 , -1.40388223, -0.76082764, 1.21536502, -0.98142646, 0.43235375, 2.01282379, -0.21453285, 3.61200475, 1.8287454 , -2.37699005, -4.43876649, -1.5534308 , 0.19087839, 0.63776082, -3.89796591, -0.77253082, 0.15942456, 1.50682854, -2.13153439, -0.03070496, -0.87138476, -3.60486968, -3.73673651, 1.36459964, -0.57526159, 1.74855 , -1.59916748, -2.53317411, 0.34688596, -0.39179164, 3.50326963, -2.16398775, 1.6853139 , 0.93583756, -3.19704488, 2.29302575, 0.1907704 , 1.65541487, -1.30203682, 2.56856035, 0.0327959 , 4.19304044, -1.00926479, -2.24279789, -0.69572595, -1.76483291, 3.0767504 , -2.20523853, 3.85941305, 0.02224512, 0.51100795, -0.64877433, -0.97541769, -0.55332363, 0.68110681, 1.04656981, -1.66401884, -2.22326276, 2.5260883 , 1.23117647, -0.60578903, 0.08622414, 1.41381078, -2.7653705 , -0.97335699, 2.92662744, -0.83610816, 2.29915347, 0.01851729, -1.31768037, -1.48470864, 1.02320517, 0.44434635, -3.43562133, -0.4494547 , 0.08147359, 3.30459418, 1.80139721, -1.308831 , -0.99884576, -1.46526386, -0.54199541, 1.12811024, 2.97529432, 1.64583481, -0.78990555, -0.74874302, -4.4103771 , -2.48981923]), array([ 3.95391703e+00, -1.07121577e+00, -3.84668853e+00, 6.77840007e+00, -2.19381045e+00, 7.10352670e-01, 6.73618307e-01, 1.37069922e+00, -3.81843396e+00, 1.26967121e+00, -2.22084017e+00, -3.53653835e+00, 9.12261523e-01, 3.46900445e+00, 5.60861189e-01, 1.81888792e+00, 7.13406114e-01, -3.34833646e+00, 1.39887349e+00, -1.53083906e+00, 3.99241572e+00, -1.95620365e+00, -1.32736259e+00, 1.45314767e+00, 1.86896524e+00, 1.41268309e+00, -2.04054499e+00, -3.22104097e+00, -3.38356292e+00, -1.07288730e+00, -2.13342416e+00, -1.17784314e+00, -5.50678185e-01, -2.93018741e+00, 6.09593785e+00, 3.56688350e-01, -2.74400006e+00, 1.41395686e+00, -1.06679209e+00, 3.99608167e+00, -1.63810367e+00, 3.26794993e+00, -2.17703756e+00, 5.76026096e+00, -3.16019468e+00, -2.04739358e+00, -9.21248072e-01, -1.17306562e+00, -1.40941302e+00, -3.39076210e+00, 8.42848917e+00, -2.23424984e+00, 1.51486619e+00, 3.39342705e+00, -3.71272706e+00, 9.32418444e+00, -2.89173783e+00, -7.17807468e-01, 6.45628003e+00, 2.46759215e+00, -5.40677123e-01, 1.03397626e+00, -4.61687260e-01, 2.28964222e+00, -1.45379187e+00, 1.09286059e+00, 1.66547924e+00, 2.60394771e+00, 3.59662329e-02, -1.58705864e+00, -2.26368232e+00, 2.50848563e+00, -1.72671381e+00, -3.19559078e+00, -9.92987939e-01, 8.91871959e-01, 1.03963870e+00, -4.01271402e-01, 3.12010149e+00, -1.35404888e+00, 2.93841033e+00, -9.41879808e-02, 5.56786269e-01, -9.35989605e-01, 1.10483247e+00, -1.21961918e+00, -4.03470597e-01, -1.41275722e-01, 2.15839643e-01, -2.90275833e+00, 6.03367683e+00, 4.09121350e+00, 3.09437534e+00, -2.16658125e-03, 2.75046954e+00, 8.71768377e-01, -2.33004375e+00, -8.64465990e-03, 2.06668848e+00, 5.57575505e-01])] . Pi chart . labels = &#39;python&#39;,&#39;c++&#39;, &#39;ruby&#39;, &#39;java&#39; sizes = [215,130,245,210] colors = [&#39;gold&#39;, &#39;yellowgreen&#39;,&#39;lightcoral&#39;, &#39;lightskyblue&#39;] explode = (0.1,0,0,0) #explode 1st slice #plot plt.pie(sizes,explode=explode,labels=labels,colors=colors, autopct=&#39;%1.1f%%&#39;,shadow=True) plt.axis(&#39;equal&#39;) plt.show() .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/23/Matplotlib.html",
            "relUrl": "/2021/04/23/Matplotlib.html",
            "date": " • Apr 23, 2021"
        }
        
    
  
    
        ,"post28": {
            "title": "Pyforest - Import all Python Data Science Libraries",
            "content": "pip install Pyforest . Collecting Pyforest Downloading pyforest-1.0.3.tar.gz (14 kB) Building wheels for collected packages: Pyforest Building wheel for Pyforest (setup.py): started Building wheel for Pyforest (setup.py): finished with status &#39;done&#39; Created wheel for Pyforest: filename=pyforest-1.0.3-py2.py3-none-any.whl size=13720 sha256=18e08121d5ee96f79c928bf37f744f0c937b1253580c5189dc7f68057ca46f2c Stored in directory: c: users mrsid appdata local pip cache wheels 72 b6 6c b593d021f7e83f481c5208bc23df0084bcfbeb5b141352b882 Successfully built Pyforest Installing collected packages: Pyforest Successfully installed Pyforest-1.0.3 Note: you may need to restart the kernel to use updated packages. . df = pd.read_csv(&#39;http://winterolympicsmedals.com/medals.csv&#39;) . df.head() . Year City Sport Discipline NOC Event Event gender Medal . 0 1924 | Chamonix | Skating | Figure skating | AUT | individual | M | Silver | . 1 1924 | Chamonix | Skating | Figure skating | AUT | individual | W | Gold | . 2 1924 | Chamonix | Skating | Figure skating | AUT | pairs | X | Gold | . 3 1924 | Chamonix | Bobsleigh | Bobsleigh | BEL | four-man | M | Bronze | . 4 1924 | Chamonix | Ice Hockey | Ice Hockey | CAN | ice hockey | M | Gold | . active_imports() # It imports only those libraries that are in use . import pandas as pd . [&#39;import pandas as pd&#39;] . lst1 = [1,2,3,4,5] lst2 = [6,7,8,9,10] plt.plot(lst1,lst2) plt.xlabel(&quot;X-axis&quot;) plt.ylabel(&quot;Y-axis&quot;) plt.show() . np.array([1,2,3,4,5]) . array([1, 2, 3, 4, 5]) . active_imports() . import matplotlib.pyplot as plt import pandas as pd import numpy as np . [&#39;import matplotlib.pyplot as plt&#39;, &#39;import pandas as pd&#39;, &#39;import numpy as np&#39;] . df1= pd.read_csv(&quot;C: Users mrsid Desktop 30 days of ML challenge NumPy and Pandas mercedesbenz.csv&quot;) . df1.head() . ID y X0 X1 X2 X3 X4 X5 X6 X8 ... X375 X376 X377 X378 X379 X380 X382 X383 X384 X385 . 0 0 | 130.81 | k | v | at | a | d | u | j | o | ... | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 6 | 88.53 | k | t | av | e | d | y | l | o | ... | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 7 | 76.26 | az | w | n | c | d | x | j | x | ... | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | . 3 9 | 80.62 | az | t | n | f | d | x | l | e | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 13 | 78.02 | az | v | n | f | d | h | d | n | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 rows × 378 columns . sns.distplot(df1[&#39;y&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x27bb681d3c8&gt; . active_imports() . import matplotlib.pyplot as plt import seaborn as sns import pandas as pd import numpy as np . [&#39;import matplotlib.pyplot as plt&#39;, &#39;import seaborn as sns&#39;, &#39;import pandas as pd&#39;, &#39;import numpy as np&#39;] .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/22/Pyforest.html",
            "relUrl": "/2021/04/22/Pyforest.html",
            "date": " • Apr 22, 2021"
        }
        
    
  
    
        ,"post29": {
            "title": "NumPy || np",
            "content": "import numpy as np . lst1 = [1,2,3,4] arr = np.array(lst1) . type(arr) . numpy.ndarray . arr . array([1, 2, 3, 4]) . arr.shape . (4,) . list1=[1,2,3,4] list2=[6,7,8,9] list3=[3,4,5,6] arr = np.array([list1,list2,list3]) . arr . array([[1, 2, 3, 4], [6, 7, 8, 9], [3, 4, 5, 6]]) . arr.shape . (3, 4) . arr.reshape(4,3) . array([[1, 2, 3], [4, 6, 7], [8, 9, 3], [4, 5, 6]]) . arr.reshape(1,12) . array([[1, 2, 3, 4, 6, 7, 8, 9, 3, 4, 5, 6]]) . arr.shape . (3, 4) . Indexing . arr . array([[1, 2, 3, 4], [6, 7, 8, 9], [3, 4, 5, 6]]) . arr[0][1] . 2 . arr[1:,3:] . array([[9], [6]]) . arr[1:,2:] . array([[8, 9], [5, 6]]) . arr[:,2:] . array([[3, 4], [8, 9], [5, 6]]) . arr[0:2,0:2] # always remember left:right is left exact and right is one value greater than actual one . array([[1, 2], [6, 7]]) . Inbuilt functions . arr = np.arange(0,10) . arr . array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) . arr = np.arange(0,10,step=2) arr . array([0, 2, 4, 6, 8]) . # shift+tab for elaborate the function np.linspace(1,10,50) . array([ 1. , 1.18367347, 1.36734694, 1.55102041, 1.73469388, 1.91836735, 2.10204082, 2.28571429, 2.46938776, 2.65306122, 2.83673469, 3.02040816, 3.20408163, 3.3877551 , 3.57142857, 3.75510204, 3.93877551, 4.12244898, 4.30612245, 4.48979592, 4.67346939, 4.85714286, 5.04081633, 5.2244898 , 5.40816327, 5.59183673, 5.7755102 , 5.95918367, 6.14285714, 6.32653061, 6.51020408, 6.69387755, 6.87755102, 7.06122449, 7.24489796, 7.42857143, 7.6122449 , 7.79591837, 7.97959184, 8.16326531, 8.34693878, 8.53061224, 8.71428571, 8.89795918, 9.08163265, 9.26530612, 9.44897959, 9.63265306, 9.81632653, 10. ]) . print(arr) arr[3:] =100 # replace all indexes starting from 3rd to all by 100 print(arr) . [0 2 4 6 8] [ 0 2 4 100 100] . arr1=arr . arr1[3:]=500 arr1 . array([ 0, 2, 4, 500, 500]) . arr # array is actually a reference type hence change is reflected to actual array also . array([ 0, 2, 4, 500, 500]) . arr1 = arr.copy() arr1 . array([ 0, 2, 4, 500, 500]) . arr1[3:] = 800 print(arr1) print(arr) . [ 0 2 4 800 800] [ 0 2 4 500 500] . Some useful conditions for Exploratorty data analysis . arr = np.array([1,2,3,4,5]) val = 2 . arr . array([1, 2, 3, 4, 5]) . print(arr&lt;2) print(arr*2) print(arr%2) . [ True False False False False] [ 2 4 6 8 10] [1 0 1 0 1] . arr[arr&lt;2] . array([1]) . np.ones((2,5),dtype=int) . array([[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]) . np.ones(4) . array([1., 1., 1., 1.]) . np.random.rand(3,3) . array([[0.97016302, 0.13230666, 0.31222633], [0.85189366, 0.07856671, 0.57296934], [0.71915461, 0.48997742, 0.24332137]]) . arr_ex = np.random.randn(4,4) # selects from random distribution arr_ex . array([[-0.60890655, -0.67170484, -0.28552398, 1.14748824], [-1.27784825, -0.60587355, -0.87103948, -0.75084882], [ 0.1356478 , 0.67908955, -0.18930585, -1.23064491], [ 0.0557476 , 0.96733176, -0.0119645 , 0.94036578]]) . arr_ex.reshape(16,1) . array([[-0.60890655], [-0.67170484], [-0.28552398], [ 1.14748824], [-1.27784825], [-0.60587355], [-0.87103948], [-0.75084882], [ 0.1356478 ], [ 0.67908955], [-0.18930585], [-1.23064491], [ 0.0557476 ], [ 0.96733176], [-0.0119645 ], [ 0.94036578]]) . import seaborn as sns import pandas as pd . sns.distplot(pd.DataFrame(arr_ex.reshape(16,1))) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x1b903b859c8&gt; . np.random.randint(0,100,8).reshape(4,2) . array([[17, 74], [67, 13], [91, 60], [92, 75]]) . np.random.random_sample((1,5)) . array([[0.02247093, 0.32708592, 0.95730227, 0.40039247, 0.43461314]]) .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/22/NumPy.html",
            "relUrl": "/2021/04/22/NumPy.html",
            "date": " • Apr 22, 2021"
        }
        
    
  
    
        ,"post30": {
            "title": "Python-Intermediate",
            "content": "def even_odd(num): if num%2==0: print(&quot;number is even&quot;) else: print(&quot;number is odd&quot;) . even_odd(24) . number is even . def hello(name, age=29): # name is positional argument and age is keyword argument print(&quot;my name is {} and age is {}&quot;.format(name, age)) . hello(&#39;sid&#39;) . my name is sid and age is 29 . hello(&#39;sid&#39;,20) . my name is sid and age is 20 . def hello(*args, **kwargs): print(args) print(kwargs) . hello(&#39;sid&#39;,&#39;saxena&#39;,age=29,dob=2000) . (&#39;sid&#39;, &#39;saxena&#39;) {&#39;age&#39;: 29, &#39;dob&#39;: 2000} . lst=[&#39;sid&#39;,&#39;saxena&#39;] dict_args={&#39;age&#39;: 20 ,&#39;dob&#39;:2000} . hello(*lst,**dict_args) . (&#39;sid&#39;, &#39;saxena&#39;) {&#39;age&#39;: 20, &#39;dob&#39;: 2000} . lst = [1,2,3,4,5,6,7] def evenoddsum(lst): even_sum=0 odd_sum=0 for i in lst: if i%2==0: even_sum += i else: odd_sum += i return even_sum,odd_sum . evenoddsum(lst) . (12, 16) . Lambda functions . def addition(a,b): return a+b # Single expression can only be converted . addition(4,5) . 9 . addition = lambda a,b:a+b . addition(5,6) . 11 . def even(num): if num%2==0: return True . even(24) . True . even1 = lambda num:num%2==0 . even1(12) . True . def add(x,y,z): return x+y+z . add(1,2,3) . 6 . three_add = lambda x,y,z:x+y+z . three_add(1,2,3) . 6 . Map Function . def even_odd(num): if num%2==0: return True else: return False . even_odd(23) . False . lst=[1,2,3,4,5,6,7,8] # apply same function on multiple values . map(even_odd,lst) # in order to instantiate convert it into a list ## memory is not intialised yet . &lt;map at 0x2a398c7e248&gt; . list(map(even_odd,lst)) . [False, True, False, True, False, True, False, True] . list(map(lambda num:num%2==0,lst)) . [False, True, False, True, False, True, False] . Filter function . def even(num): if num%2==0: return True . lst=[1,2,3,4,5,6,7] . list(filter(even,lst)) # return elements which satisfy the condition . [2, 4, 6] . list(filter(lambda num:num%2==0,lst)) . [2, 4, 6] . List Comprehension . provide a concise way to create lists, It consists of braces containing an expression followed by for clause, then zero or more for or if clauses . lst1=[] def lst_square(lst): for i in lst: lst1.append(i*i) return lst1 . lst_square([1,2,3,4,5,6,7]) . [1, 4, 9, 16, 25, 36, 49] . lst=[1,2,3,4,5,6,7] #list comprehension [i*i for i in lst ] . [1, 4, 9, 16, 25, 36, 49] . list1=[i*i for i in lst ] print(list1) . [1, 4, 9, 16, 25, 36, 49] . [i*i for i in lst if i%2==0] . [4, 16, 36] . String Formatting . print(&quot;hello&quot;) . hello . str=&quot;hello&quot; print(str) . hello . def greetings(name): return &quot;hello {}&quot;.format(name) . greetings(&#39;sid&#39;) . &#39;hello sid&#39; . def welcome_email(firstname,lastname): return &quot;welcome {}. is your last name is {}&quot;.format(firstname,lastname) # order can not be altered . welcome_email(&#39;sid&#39;,&#39;saxena&#39;) . &#39;welcome sid. is your last name is saxena&#39; . def welcome_email(name,age): return &quot;welcome {name}. is your age is {age}&quot;.format(age=age,name=name) # now ordering can alter . welcome_email(&#39;sid&#39;,20) . &#39;welcome sid. is your age is 20&#39; . def welcome_email(name,age): return &quot;welcome {name1}. is your age is {age1}&quot;.format(age1=age,name1=name) . welcome_email(&#39;sid&#39;,20) . &#39;welcome sid. is your age is 20&#39; . List Iterables vs Iterators . lst = [1,2,3,4,5,6,7] # this whole list is getting initialised in the memory for i in lst: print(i) . 1 2 3 4 5 6 7 . list1=iter(lst) #but in case of iterators whole listdose not get stored in memory it will get accessed only via next . list1 . &lt;list_iterator at 0x2a3996beb08&gt; . next(list1) . 1 . next(list1) . 2 . for i in lst1: print(i) . 1 4 9 16 25 36 49 . .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/21/Python-Intermediate.html",
            "relUrl": "/2021/04/21/Python-Intermediate.html",
            "date": " • Apr 21, 2021"
        }
        
    
  
    
        ,"post31": {
            "title": "Python-Basics",
            "content": "bool() . False . type(True) . bool . my_str = &quot;siddy&quot; . print(my_str.isalnum()) print(my_str.isupper()) . True False . my_str=&#39;sid123&#39; my_str.isalnum() . True . Lists . type([]) . list . list = [&#39;mathematics&#39;,100,10,20,122,230] print(list) . [&#39;mathematics&#39;, 100, 10, 20, 122, 230] . list[:] # 100 to 230 list[1:] . [100, 10, 20, 122, 230] . list[1:5] # left is the same index and right is index we want+1 . [100, 10, 20, 122] . print(list) . [&#39;mathematics&#39;, 100, 10, 20, 122, 230, &#39;sid&#39;, [&#39;sid1&#39;, &#39;sid2&#39;], &#39;sid&#39;, [&#39;sid1&#39;, &#39;sid2&#39;], &#39;sid&#39;, [&#39;sid1&#39;, &#39;sid2&#39;]] . list.insert(1,&quot;saxena&quot;) print(list) . [&#39;mathematics&#39;, &#39;saxena&#39;, &#39;saxena&#39;, 100, 10, 20, 122, 230, &#39;sid&#39;, [&#39;sid1&#39;, &#39;sid2&#39;], &#39;sid&#39;, [&#39;sid1&#39;, &#39;sid2&#39;], &#39;sid&#39;, [&#39;sid1&#39;, &#39;sid2&#39;]] . list2 = [1,2,3,4,5] print(list2) . [1, 2, 3, 4, 5] . list2.extend([6,7]) list2 . [1, 2, 3, 4, 5, 6, 7] . operations on list . sum(list2) . 28 . list2.pop() . 7 . list2.count(2) . 1 . list2.index(2,1,4) . 1 . print(min(list2)) print(max(list2)) . 1 6 . list2*2 . [1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6] .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/21/Python-Basics.html",
            "relUrl": "/2021/04/21/Python-Basics.html",
            "date": " • Apr 21, 2021"
        }
        
    
  
    
        ,"post32": {
            "title": "Python-Advanced",
            "content": "correct way to initialise a Class . class Car: def __init__(self,window,door,enginetype): self.windows=window self.doors=door self.enginetype=enginetype def self_driving(self): return &quot;This is a {} car&quot;.format(self.enginetype) . car1=Car(4,5,&#39;petrol&#39;) # by default this init method is called . dir(car1) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;doors&#39;, &#39;enginetype&#39;, &#39;self_driving&#39;, &#39;windows&#39;] . car2=Car(3,4,&quot;diesel&quot;) . print(car1.windows) . 4 . print(car2.enginetype) . diesel . car1.self_driving() . &#39;This is a petrol car&#39; . print(car2.doors) . 4 . car2.enginetype=&quot;diesel&quot; . print(car2.enginetype) . diesel . Python Exception Handling . try: # code block where exception can occur a=b except: print(&quot;some problem may have occured&quot;) . some problem may have occured . try: # code block where exception can occur a=b except Exception as ex: print(ex) . name &#39;b&#39; is not defined . try: # code block where exception can occur a=b except NameError as ex1: print(&quot;the user have not defined the error&quot;) except Exception as ex: # this always needs to be written on the lst print(ex) . the user have not defined the error . try: # code block where exception can occur a=1 b=&#39;s&#39; c=a+b except NameError as ex1: print(&quot;the user have not defined the error&quot;) except Exception as ex: # this always needs to be written on the lst print(ex) . unsupported operand type(s) for +: &#39;int&#39; and &#39;str&#39; . a=1 b=&#39;s&#39; c=a+b . TypeError Traceback (most recent call last) &lt;ipython-input-15-b5351790d4cc&gt; in &lt;module&gt; 1 a=1 2 b=&#39;s&#39; -&gt; 3 c=a+b TypeError: unsupported operand type(s) for +: &#39;int&#39; and &#39;str&#39; . try: # code block where exception can occur a=1 b=&#39;s&#39; c=a+b except NameError as ex1: print(&quot;the user have not defined the error&quot;) except TypeError as ex2: print(&quot;the user has given unsupported data types for addition&quot;) print(&quot;try to make the data type similar&quot;) except Exception as ex: # this always needs to be written on the lst print(ex) . the user has given unsupported data types for addition try to make the data type similar . try: a=int(input(&quot;enter number 1 = &quot;)) b=int(input(&quot;enter number 2 = &quot;)) c=a/b d=a+b e=a*b except NameError as ex1: print(&quot;the user have not defined the error&quot;) except TypeError as ex2: print(&quot;the user has given unsupported data types for addition&quot;) print(&quot;try to make the data type similar&quot;) except Exception as ex: # this always needs to be written on the lst print(ex) . enter number 1 = 12 enter number 2 = 12 . print(c) print(d) print(e) . 1.0 24 144 . try: a=int(input(&quot;enter number 1 = &quot;)) b=int(input(&quot;enter number 2 = &quot;)) c=a/b d=a+b e=a*b except NameError as ex1: print(&quot;the user have not defined the error&quot;) except TypeError as ex2: print(&quot;the user has given unsupported data types for addition&quot;) print(&quot;try to make the data type similar&quot;) except Exception as ex: # this always needs to be written on the lst print(ex) . enter number 1 = 1 enter number 2 = 2 . 12/0 . ZeroDivisionError Traceback (most recent call last) &lt;ipython-input-28-898e9759c56e&gt; in &lt;module&gt; -&gt; 1 12/0 ZeroDivisionError: division by zero . try: a=int(input(&quot;enter number 1 = &quot;)) b=int(input(&quot;enter number 2 = &quot;)) c=a/b d=a+b e=a*b except NameError as ex1: print(&quot;the user have not defined the error&quot;) except TypeError as ex2: print(&quot;the user has given unsupported data types for addition&quot;) print(&quot;try to make the data type similar&quot;) except ZeroDivisionError as ex3: print(&quot;12/0 is not defined&quot;) except Exception as ex: # this always needs to be written on the lst print(ex) else: print(c) print(d) print(e) finally: print(&quot;The execution is complete&quot;) . enter number 1 = 12 enter number 2 = 0 12/0 is not defined The execution is complete . Custom Exception . class Error(Exception): # inheriting the exception class pass class dobException(Error): pass . year = int(input(&quot;Enter the year of birth&quot;)) age = 2021-year try: if age&lt;=30 &amp; age&gt;20: print(&quot;Valid age&quot;) else: raise dobException except dobException: print(&quot;year range is not valid&quot;) . Enter the year of birth1555 year range is not valid . Public Private and Protected Access modifiers . class Car(): def __init__(self,windows, doors, enginetypes): self.windows=windows self.doors=doors self.enginetypes=enginetypes . audi = Car(4,5,&quot;Diesel&quot;) . audi . &lt;__main__.Car at 0x1ed3a2b5ac8&gt; . audi.windows . 4 . audi.windows=5 . audi.windows . 5 . dir(audi) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;doors&#39;, &#39;enginetypes&#39;, &#39;windows&#39;] . class Car(): def __init__(self,windows, doors, enginetypes): self._windows=windows self._doors=doors self._enginetypes=enginetypes . class Truck(Car): def __init__(self,windows, doors, enginetypes, hp): super().__init__(windows,doors,enginetypes) self.hp=hp . truck=Truck(4,2,&quot;Petrol&quot;,720) . dir(truck) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;_doors&#39;, &#39;_enginetypes&#39;, &#39;_windows&#39;, &#39;hp&#39;] . truck._doors=4 . truck._doors . 4 . audi._windows . AttributeError Traceback (most recent call last) &lt;ipython-input-45-63cafd091289&gt; in &lt;module&gt; -&gt; 1 audi._windows AttributeError: &#39;Car&#39; object has no attribute &#39;_windows&#39; . dir(audi) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;doors&#39;, &#39;enginetypes&#39;, &#39;windows&#39;] . class Car(): def __init__(self,windows, doors, enginetypes): self.__windows=windows self.__doors=doors self.__enginetypes=enginetypes . audi=Car(4,2,&quot;petrol&quot;) . dir(audi) . [&#39;_Car__doors&#39;, &#39;_Car__enginetypes&#39;, &#39;_Car__windows&#39;, &#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;] . Inheritance . ## Car Blueprint class Car(): def __init__(self, windows, doors, enginetype): self.windows=windows self.doors=doors self.enginetype=enginetype def drive(self): print(&quot;the person drive a car&quot;) . car = Car(4,5,&quot;diesel&quot;) . car.windows . 4 . car.drive() . the person drive a car . class audi(Car): def __init__(self,windows,doors,enginetype,enableai): super().__init__(windows,doors,enginetype) self.enableai=enableai def selfdriving(self): print(&quot;Audi Supports Self driving&quot;) . audiQ7=audi(5,5,&#39;diesel&#39;,True) . audiQ7.enableai . True .",
            "url": "https://mr-siddy.github.io/ML-blog/2021/04/21/Python-Advanced.html",
            "relUrl": "/2021/04/21/Python-Advanced.html",
            "date": " • Apr 21, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hey 👋🏽, I’m Siddhant! . . . Hi, I’m Siddhant saxena, a Machine Learning novice and am very passionate about Artificial Intelligence 🚀 . I’m from India and am currently looking to collaborate on ML/DL projects and would love to work with like-minded individuals. . Talking about Me: . 💻 I’m currently working on ML Projects and am looking for collaborators; | 🌱 I’m currently learning Computer Vision; | 💬 Ask me about anything, I’d try my best to help; | 📫 How to reach me: mrsiddy.py@gmail.com; | . . . ⭐️ From Siddhant .",
          "url": "https://mr-siddy.github.io/ML-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://mr-siddy.github.io/ML-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}