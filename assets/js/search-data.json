{
  
    
        "post0": {
            "title": "Exploratory Data Analysis with Python and Applying Logistic Regression",
            "content": "Import Libraries . import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline . The Data . train = pd.read_csv(&#39;titanic_train.csv&#39;) . train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | C123 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | NaN | S | . Missing Data . train.isnull() # if True indicates a null value # but it is not a good way as data set can be vast . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 False | False | False | False | False | False | False | False | False | False | True | False | . 1 False | False | False | False | False | False | False | False | False | False | False | False | . 2 False | False | False | False | False | False | False | False | False | False | True | False | . 3 False | False | False | False | False | False | False | False | False | False | False | False | . 4 False | False | False | False | False | False | False | False | False | False | True | False | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 886 False | False | False | False | False | False | False | False | False | False | True | False | . 887 False | False | False | False | False | False | False | False | False | False | False | False | . 888 False | False | False | False | False | True | False | False | False | False | True | False | . 889 False | False | False | False | False | False | False | False | False | False | False | False | . 890 False | False | False | False | False | False | False | False | False | False | True | False | . 891 rows × 12 columns . sns.heatmap(train.isnull(),yticklabels = False, cbar =False, cmap=&#39;viridis&#39;) # so most of the null values are present in age and cabin . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a91cd84c8&gt; . sns.set_style(&#39;whitegrid&#39;) sns.countplot(x=&#39;Survived&#39;,data=train) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a91d397c8&gt; . sns.set_style(&#39;whitegrid&#39;) sns.countplot(x=&#39;Survived&#39;,hue=&#39;Sex&#39;,data=train, palette=&#39;RdBu_r&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92b67d88&gt; . sns.set_style(&#39;whitegrid&#39;) sns.countplot(x=&#39;Survived&#39;,hue=&#39;Pclass&#39;,data=train, palette=&#39;rainbow&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92c2ee88&gt; . sns.distplot(train[&#39;Age&#39;].dropna(), kde=False, color=&#39;darkred&#39;, bins=40) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92ca32c8&gt; . train[&#39;Age&#39;].hist(bins=30, color=&#39;blue&#39;,alpha=0.3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92daeb88&gt; . sns.countplot(x=&#39;SibSp&#39;, data=train) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92e6f2c8&gt; . train[&#39;Fare&#39;].hist(bins=30,color=&#39;green&#39;,alpha=0.4) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92ed4e48&gt; . Data Cleaning . plt.figure(figsize=(12,7)) sns.boxplot(x=&#39;Pclass&#39;,y=&#39;Age&#39;,data=train,palette=&#39;winter&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a92c2e5c8&gt; . we can see the wealthrer passengers in the higher classes tend to older, which makes sense, we&#39;ll use these average age values to impute based on pcalss for age . def impute_age(cols): Age = cols[0] Pclass = cols[1] if pd.isnull(Age): if Pclass == 1: return 37 elif Pclass == 2: return 29 else: return 24 else: return Age . train[&#39;Age&#39;] = train [[&#39;Age&#39;,&#39;Pclass&#39;]].apply(impute_age,axis=1 ) # now check heatmap again . sns.heatmap(train.isnull(),yticklabels = False, cbar =False, cmap=&#39;viridis&#39;) # so most of the null values are present in age and cabin . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a931ec508&gt; . we have to apply a lot of feature engineering to handle Cabin coz of a lot of Nan values hence we&#39;ll drop it for now . train.drop(&#39;Cabin&#39;,axis=1,inplace=True) . sns.heatmap(train.isnull(),yticklabels = False, cbar =False, cmap=&#39;viridis&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a93031ac8&gt; . train.dropna(inplace=True) . sns.heatmap(train.isnull(),yticklabels = False, cbar =False, cmap=&#39;viridis&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x19a930b6148&gt; . train.head() . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | S | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | female | 35.0 | 1 | 0 | 113803 | 53.1000 | S | . 4 5 | 0 | 3 | Allen, Mr. William Henry | male | 35.0 | 0 | 0 | 373450 | 8.0500 | S | . Converting Categorical Features . we&#39;ll need to convert categorical features to dummy variables using pandas, otherwise our machine learning algorithm wont be able to directly take in those features as inputs . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 889 entries, 0 to 890 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 889 non-null int64 1 Survived 889 non-null int64 2 Pclass 889 non-null int64 3 Name 889 non-null object 4 Sex 889 non-null object 5 Age 889 non-null float64 6 SibSp 889 non-null int64 7 Parch 889 non-null int64 8 Ticket 889 non-null object 9 Fare 889 non-null float64 10 Embarked 889 non-null object dtypes: float64(2), int64(5), object(4) memory usage: 83.3+ KB . pd.get_dummies(train[&#39;Embarked&#39;],drop_first=True).head() . Q S . 0 0 | 1 | . 1 0 | 0 | . 2 0 | 1 | . 3 0 | 1 | . 4 0 | 1 | . sex = pd.get_dummies(train[&#39;Sex&#39;],drop_first=True) embark = pd.get_dummies(train[&#39;Embarked&#39;],drop_first=True) . train.drop([&#39;Sex&#39;,&#39;Embarked&#39;,&#39;Name&#39;,&#39;Ticket&#39;],axis=1,inplace=True) . train.head() . PassengerId Survived Pclass Age SibSp Parch Fare . 0 1 | 0 | 3 | 22.0 | 1 | 0 | 7.2500 | . 1 2 | 1 | 1 | 38.0 | 1 | 0 | 71.2833 | . 2 3 | 1 | 3 | 26.0 | 0 | 0 | 7.9250 | . 3 4 | 1 | 1 | 35.0 | 1 | 0 | 53.1000 | . 4 5 | 0 | 3 | 35.0 | 0 | 0 | 8.0500 | . train = pd.concat([train,sex,embark],axis=1) . train.head() . PassengerId Survived Pclass Age SibSp Parch Fare male Q S . 0 1 | 0 | 3 | 22.0 | 1 | 0 | 7.2500 | 1 | 0 | 1 | . 1 2 | 1 | 1 | 38.0 | 1 | 0 | 71.2833 | 0 | 0 | 0 | . 2 3 | 1 | 3 | 26.0 | 0 | 0 | 7.9250 | 0 | 0 | 1 | . 3 4 | 1 | 1 | 35.0 | 1 | 0 | 53.1000 | 0 | 0 | 1 | . 4 5 | 0 | 3 | 35.0 | 0 | 0 | 8.0500 | 1 | 0 | 1 | . Building a Logistic Regression Model . Train Test Split . train.drop(&#39;Survived&#39;,axis=1).head() . PassengerId Pclass Age SibSp Parch Fare male Q S . 0 1 | 3 | 22.0 | 1 | 0 | 7.2500 | 1 | 0 | 1 | . 1 2 | 1 | 38.0 | 1 | 0 | 71.2833 | 0 | 0 | 0 | . 2 3 | 3 | 26.0 | 0 | 0 | 7.9250 | 0 | 0 | 1 | . 3 4 | 1 | 35.0 | 1 | 0 | 53.1000 | 0 | 0 | 1 | . 4 5 | 3 | 35.0 | 0 | 0 | 8.0500 | 1 | 0 | 1 | . train[&#39;Survived&#39;].head() . 0 0 1 1 2 1 3 1 4 0 Name: Survived, dtype: int64 . from sklearn.model_selection import train_test_split . X_train,X_test,y_train,y_test = train_test_split(train.drop(&#39;Survived&#39;,axis=1),train[&#39;Survived&#39;],test_size=0.30,random_state=101) . Training and Predicting . from sklearn.linear_model import LogisticRegression . logmodel = LogisticRegression() logmodel.fit(X_train,y_train) . C: Users mrsid anaconda3 lib site-packages sklearn linear_model _logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG) . LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class=&#39;auto&#39;, n_jobs=None, penalty=&#39;l2&#39;, random_state=None, solver=&#39;lbfgs&#39;, tol=0.0001, verbose=0, warm_start=False) . predictions = logmodel.predict(X_test) . from sklearn.metrics import confusion_matrix . accuracy = confusion_matrix(y_test,predictions) . accuracy . array([[149, 14], [ 39, 65]], dtype=int64) . from sklearn.metrics import accuracy_score . accuracy = accuracy_score(y_test,predictions) accuracy . 0.8014981273408239 . predictions . array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1], dtype=int64) .",
            "url": "https://mr-siddy.github.io/The-Student-Blog/2021/04/25/EDA.html",
            "relUrl": "/2021/04/25/EDA.html",
            "date": " • Apr 25, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://mr-siddy.github.io/The-Student-Blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hey 👋🏽, I’m Siddhant! . . . Hi, I’m Siddhant saxena, a Machine Learning novice and am very passionate about Artificial Intelligence 🚀 . I’m from India and am currently looking to collaborate on ML/DL projects and would love to work with like-minded individuals. . Talking about Me: . 💻 I’m currently working on ML Projects and am looking for collaborators; | 🌱 I’m currently learning Computer Vision; | 💬 Ask me about anything, I’d try my best to help; | 📫 How to reach me: mrsiddy.py@gmail.com; | . . . ⭐️ From Siddhant .",
          "url": "https://mr-siddy.github.io/The-Student-Blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://mr-siddy.github.io/The-Student-Blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}