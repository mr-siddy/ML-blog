{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c67ad3",
   "metadata": {},
   "source": [
    "# Logistic Regression on MNIST Database using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04c5f68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9eec2f",
   "metadata": {},
   "source": [
    "## Working with Image\n",
    "\n",
    "We'll use the famous [*MNIST Handwritten Digits Database*](http://yann.lecun.com/exdb/mnist/) as our training dataset. It consists of 28px by 28px grayscale images of handwritten digits (0 to 9) and labels for each image indicating which digit it represents. Here are some sample images from the dataset:\n",
    "\n",
    "![mnist-sample](https://i.imgur.com/CAYnuo1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4671b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9544d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset - pytorch will automatically converted them to a Pytorch Dataset object\n",
    "\n",
    "dataset = MNIST(root='data/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d335c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3aef054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating test_dataset using train=False\n",
    "\n",
    "test_dataset = MNIST(root='data/', train=False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d2b2751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x25EA9AE4748>, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample element\n",
    "\n",
    "dataset[0]   # it gives :- image(part of pillow), 5 (label digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505d149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  #indicates to jupyter we want to plot graphs within the notebook, without this it will show in popup\n",
    "%matplotlib inline                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61ec0fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[0]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0dc9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[10]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a695d",
   "metadata": {},
   "source": [
    "Pytorch dosen't know how to work with images, we need to convert images to tensors by specifying transform while creating our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24addba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b121aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset of tensors\n",
    "\n",
    "dataset = MNIST(root='data/',\n",
    "                train=True,\n",
    "               transform=transform.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5405b990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28]) 5\n"
     ]
    }
   ],
   "source": [
    "img_tensor, label = dataset[0]\n",
    "print(img_tensor.shape,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25521ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d4d13e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n",
      "tensor(1.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# some sample values insode the tensor\n",
    "\n",
    "print(img_tensor[:,10:15,10:15])\n",
    "print(torch.max(img_tensor),torch.min(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "668489c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x25eadd15c08>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot image by passing 28x28 matrix\n",
    "\n",
    "plt.imshow(img_tensor[0,10:15,10:15], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e917599",
   "metadata": {},
   "source": [
    "## Training and Validation Datasets\n",
    "\n",
    "1. **Training set** - used to train the model, i.e., compute the loss and adjust the model's weights using gradient descent.\n",
    "2. **Validation set** - used to evaluate the model during training, adjust hyperparameters (learning rate, etc.), and pick the best version of the model.\n",
    "3. **Test set** - used to compare different models or approaches and report the model's final accuracy.\n",
    "\n",
    "In the MNIST dataset, there are 60,000 training images and 10,000 test images. The test set is standardized so that different researchers can report their models' results against the same collection of images. \n",
    "\n",
    "Since there's no predefined validation set, we must manually split the 60,000 images into training and validation datasets. Let's set aside 10,000 randomly chosen images for validation. We can do this using the `random_spilt` method from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10effc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually split training set to 50000-10000 validation set\n",
    "\n",
    "# using random_split\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fa9b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Data_loaders to helpus load data in batches - size=128\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True) # shuffle=True for the training data loader to ensure batches generated in each epoch are different  # randomization helps generalize and speed=up the training process\n",
    "val_loader = DataLoader(val_ds, batch_size )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cfe54f",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "* A **logistic regression** model is almost identical to a linear regression model. It contains weights and bias matrices, and the output is obtained using simple matrix operations (`pred = x @ w.t() + b`). \n",
    "\n",
    "* As we did with linear regression, we can use `nn.Linear` to create the model instead of manually creating and initializing the matrices.\n",
    "\n",
    "* Since `nn.Linear` expects each training example to be a vector, each `1x28x28` image tensor is _flattened_ into a vector of size 784 `(28*28)` before being passed into the model. \n",
    "\n",
    "* The output for each image is a vector of size 10, with each element signifying the probability of a particular target label (i.e., 0 to 9). The predicted label for an image is simply the one with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09dd8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "#Logistic regression model\n",
    "\n",
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb0f6dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0097, -0.0244, -0.0155,  ..., -0.0295,  0.0300, -0.0210],\n",
       "        [ 0.0036,  0.0262, -0.0189,  ...,  0.0118,  0.0162, -0.0324],\n",
       "        [ 0.0041, -0.0117, -0.0011,  ...,  0.0128,  0.0156, -0.0292],\n",
       "        ...,\n",
       "        [-0.0163, -0.0195, -0.0283,  ..., -0.0236,  0.0138,  0.0091],\n",
       "        [ 0.0336, -0.0344,  0.0232,  ..., -0.0277, -0.0007, -0.0115],\n",
       "        [ 0.0130,  0.0136,  0.0206,  ...,  0.0128, -0.0171, -0.0017]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.weight.shape)\n",
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d09aa25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0144, -0.0100,  0.0354, -0.0225, -0.0262,  0.0286,  0.0230, -0.0162,\n",
       "        -0.0203,  0.0171], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.bias.shape)\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3019b01a",
   "metadata": {},
   "source": [
    "so total parameters = 7850 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43ff93b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 5, 4, 8, 6, 0, 0, 5, 3, 7, 9, 0, 8, 4, 5, 2, 5, 9, 3, 0, 6, 6,\n",
      "        4, 9, 2, 1, 5, 9, 3, 3, 4, 1, 0, 4, 2, 0, 0, 5, 6, 8, 9, 7, 6, 0, 4, 1,\n",
      "        2, 1, 9, 2, 6, 8, 5, 2, 8, 7, 7, 9, 7, 6, 7, 5, 9, 5, 5, 9, 1, 7, 5, 0,\n",
      "        7, 7, 2, 5, 0, 8, 1, 1, 7, 8, 7, 4, 7, 3, 1, 6, 4, 9, 9, 3, 9, 3, 5, 6,\n",
      "        6, 5, 6, 4, 2, 4, 5, 1, 8, 7, 0, 3, 9, 9, 5, 2, 7, 6, 9, 8, 5, 1, 3, 2,\n",
      "        3, 6, 4, 1, 3, 9, 7, 3])\n",
      "torch.Size([128, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-170d6f073b97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1752\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1753\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3584x28 and 784x10)"
     ]
    }
   ],
   "source": [
    "# taking 1st batch of 100 images from our bataset and pass them into our model\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    print(images.shape)\n",
    "    outputs = model(images)\n",
    "    print(outputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92f7c47",
   "metadata": {},
   "source": [
    "error occurred bcoz, input data dosen't have right shape. images are of the shape 1x28x28, but we need them to be vectors of size 784 ie we need to flatten them --> using .reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c2c015b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fb4b656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 784])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.reshape(128,784).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b20fdc",
   "metadata": {},
   "source": [
    "To include this additional function within out model, we need to define a custom model by extending the nn.Module class\n",
    "\n",
    "Inside the `__init__` constructor method, we instantiate the weights and biases using `nn.Linear`. And inside the `forward` method, which is invoked when we pass a batch of inputs to the model, we flatten the input tensor and pass it into `self.linear`.\n",
    "\n",
    "`xb.reshape(-1, 28*28)` indicates to PyTorch that we want a *view* of the `xb` tensor with two dimensions. The length along the 2nd dimension is 28\\*28 (i.e., 784). One argument to `.reshape` can be set to `-1` (in this case, the first dimension) to let PyTorch figure it out automatically based on the shape of the original tensor.\n",
    "\n",
    "Note that the model no longer has `.weight` and `.bias` attributes (as they are now inside the `.linear` attribute), but it does have a `.parameters` method that returns a list containing the weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "117fb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extending nn.Module class\n",
    "\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "model = MnistModel() #object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6934fd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=10, bias=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "980f6681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 3.4617e-02,  2.8410e-02,  2.5686e-02,  ..., -1.5863e-02,\n",
       "          -3.8656e-03,  1.5305e-02],\n",
       "         [-1.8018e-02,  1.7917e-02, -3.0232e-02,  ..., -5.3763e-03,\n",
       "          -3.2701e-02,  1.7136e-02],\n",
       "         [-3.4262e-02,  8.5667e-03, -2.0011e-02,  ..., -1.8257e-02,\n",
       "           3.4308e-02,  1.8136e-02],\n",
       "         ...,\n",
       "         [ 9.5943e-03,  1.6986e-02,  2.2343e-02,  ...,  4.5605e-03,\n",
       "           9.5017e-03, -2.5854e-04],\n",
       "         [-1.4468e-02, -2.7529e-02,  2.9830e-02,  ..., -9.3204e-03,\n",
       "           6.1549e-03, -2.5384e-02],\n",
       "         [ 3.3574e-02,  2.1621e-03, -8.8337e-03,  ..., -4.9651e-05,\n",
       "          -2.1324e-02,  2.4071e-03]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0054, -0.0311,  0.0240,  0.0014, -0.0334,  0.0090, -0.0151, -0.0068,\n",
       "          0.0042, -0.0279], requires_grad=True)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters()) # bundle all weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "745183ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.shape : torch.Size([128, 10])\n",
      "Sample outputs layer 0 : tensor([-0.1530, -0.4023,  0.0156, -0.0506,  0.0551, -0.2542,  0.0123, -0.3361,\n",
      "        -0.1795,  0.1995])\n",
      "Sample outputs layer 0 and 1 : tensor([[-0.1530, -0.4023,  0.0156, -0.0506,  0.0551, -0.2542,  0.0123, -0.3361,\n",
      "         -0.1795,  0.1995],\n",
      "        [-0.2933, -0.3964,  0.2764, -0.0050, -0.0035, -0.0671,  0.2888, -0.2759,\n",
      "         -0.1555,  0.0238]])\n"
     ]
    }
   ],
   "source": [
    "# we can use custom model in same as before \n",
    "\n",
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    break\n",
    "    \n",
    "print('output.shape :', outputs.shape)\n",
    "print('Sample outputs layer 0 :', outputs[0].data)\n",
    "print('Sample outputs layer 0 and 1 :', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c0f99",
   "metadata": {},
   "source": [
    "For each of the 100 input images, we get 10 outputs, one for each class. As discussed earlier, we'd like these outputs to represent probabilities. Each output row's elements must lie between 0 to 1 and add up to 1, which is not the case. \n",
    "\n",
    "To convert the output rows into probabilities, we use the softmax function, which has the following formula:\n",
    "\n",
    "![softmax](https://i.imgur.com/EAh9jLN.png)\n",
    "\n",
    "First, we replace each element `yi` in an output row by `e^yi`, making all the elements positive. \n",
    "\n",
    "![](https://www.montereyinstitute.org/courses/DevelopmentalMath/COURSE_TEXT2_RESOURCE/U18_L1_T1_text_final_6_files/image001.png)\n",
    "\n",
    "\n",
    "\n",
    "Then, we divide them by their sum to ensure that they add up to 1. The resulting vector can thus be interpreted as probabilities.\n",
    "\n",
    "we'll use the implementation that's provided within PyTorch because it works well with multidimensional tensors (a list of output rows in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "587c88ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c925224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1530, -0.4023,  0.0156, -0.0506,  0.0551, -0.2542,  0.0123, -0.3361,\n",
       "         -0.1795,  0.1995],\n",
       "        [-0.2933, -0.3964,  0.2764, -0.0050, -0.0035, -0.0671,  0.2888, -0.2759,\n",
       "         -0.1555,  0.0238]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bac20f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample probabilities:\n",
      " tensor([[0.0942, 0.0734, 0.1115, 0.1044, 0.1160, 0.0851, 0.1111, 0.0784, 0.0917,\n",
      "         0.1340],\n",
      "        [0.0774, 0.0698, 0.1368, 0.1032, 0.1034, 0.0970, 0.1385, 0.0787, 0.0888,\n",
      "         0.1063]])\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "probs = F.softmax(outputs, dim=1) # apply softmax for each output row # see why dim=0 dosen't workout\n",
    "\n",
    "print(\"sample probabilities:\\n\", probs[:2].data) #sample probs\n",
    "\n",
    "print(\"Sum: \", torch.sum(probs[0]).item()) # addup probs of an output row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5d7a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9, 6, 2, 9, 2, 2, 9, 5, 3, 9, 3, 8, 6, 9, 2, 9, 9, 8, 9, 9, 9, 3, 6, 3,\n",
      "        6, 3, 5, 3, 2, 2, 3, 9, 9, 8, 2, 2, 9, 6, 6, 4, 2, 0, 9, 9, 2, 2, 9, 9,\n",
      "        2, 9, 9, 9, 9, 9, 9, 9, 6, 9, 3, 3, 6, 9, 9, 3, 2, 3, 9, 8, 4, 8, 8, 4,\n",
      "        9, 2, 5, 2, 9, 2, 8, 2, 2, 6, 3, 4, 9, 9, 9, 9, 6, 6, 9, 6, 9, 3, 9, 9,\n",
      "        0, 6, 3, 2, 3, 5, 5, 3, 8, 3, 8, 2, 4, 3, 0, 9, 9, 6, 6, 3, 5, 2, 3, 9,\n",
      "        3, 2, 7, 9, 9, 2, 9, 9])\n",
      "tensor([0.1340, 0.1385, 0.1331, 0.1312, 0.1378, 0.1389, 0.1765, 0.1426, 0.1205,\n",
      "        0.1485, 0.1351, 0.1217, 0.1359, 0.1315, 0.1463, 0.1313, 0.1251, 0.1250,\n",
      "        0.1213, 0.1374, 0.1270, 0.1285, 0.1210, 0.1202, 0.1537, 0.1311, 0.1201,\n",
      "        0.1155, 0.1454, 0.1945, 0.1293, 0.1238, 0.1146, 0.1202, 0.1568, 0.1285,\n",
      "        0.1396, 0.1146, 0.1350, 0.1179, 0.1579, 0.1335, 0.1622, 0.1176, 0.1568,\n",
      "        0.1461, 0.1368, 0.1345, 0.1403, 0.1409, 0.1426, 0.1331, 0.1502, 0.1324,\n",
      "        0.1265, 0.1440, 0.1352, 0.1367, 0.1186, 0.1284, 0.1301, 0.1446, 0.1604,\n",
      "        0.1328, 0.1556, 0.1515, 0.1254, 0.1221, 0.1191, 0.1351, 0.1306, 0.1152,\n",
      "        0.1264, 0.1515, 0.1167, 0.1381, 0.1342, 0.1423, 0.1233, 0.1406, 0.1184,\n",
      "        0.1247, 0.1140, 0.1443, 0.1542, 0.1410, 0.1169, 0.1249, 0.1407, 0.1257,\n",
      "        0.1382, 0.1283, 0.1415, 0.1145, 0.1345, 0.1229, 0.1267, 0.1291, 0.1408,\n",
      "        0.1413, 0.1231, 0.1289, 0.1252, 0.1473, 0.1149, 0.1233, 0.1328, 0.1257,\n",
      "        0.1239, 0.1239, 0.1235, 0.1495, 0.1488, 0.1119, 0.1191, 0.1328, 0.1396,\n",
      "        0.1598, 0.1483, 0.1271, 0.1297, 0.1417, 0.1131, 0.1655, 0.1422, 0.1257,\n",
      "        0.1339, 0.1229], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# predicted label for each index is index of element with max probab\n",
    "\n",
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "\n",
    "print(preds)\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7e6522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 8, 5, 3, 3, 3, 2, 1, 0, 7, 2, 5, 3, 4, 8, 7, 4, 1, 9, 4, 9, 4, 4, 7,\n",
       "        0, 9, 1, 7, 0, 0, 8, 5, 1, 8, 0, 4, 7, 8, 2, 5, 2, 1, 4, 6, 0, 8, 6, 9,\n",
       "        5, 4, 9, 4, 9, 3, 4, 6, 3, 8, 1, 2, 2, 4, 9, 9, 5, 6, 9, 1, 8, 5, 8, 2,\n",
       "        9, 0, 3, 0, 9, 7, 1, 1, 7, 8, 9, 7, 9, 4, 4, 6, 6, 3, 7, 5, 9, 8, 1, 9,\n",
       "        9, 0, 2, 0, 0, 5, 1, 3, 9, 8, 1, 6, 9, 4, 6, 2, 5, 6, 8, 2, 1, 0, 2, 5,\n",
       "        7, 6, 7, 7, 0, 1, 4, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have not trained yet\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7c78e",
   "metadata": {},
   "source": [
    "## Evaluation Metric and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5854dae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1530, -0.4023,  0.0156, -0.0506,  0.0551, -0.2542,  0.0123, -0.3361,\n",
       "         -0.1795,  0.1995],\n",
       "        [-0.2933, -0.3964,  0.2764, -0.0050, -0.0035, -0.0671,  0.2888, -0.2759,\n",
       "         -0.1555,  0.0238]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f481bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False,  True, False,\n",
       "         True, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False,  True, False, False, False, False, False, False,\n",
       "         True, False, False, False, False, False, False,  True, False, False,\n",
       "         True, False,  True, False, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False,  True, False, False, False,\n",
       "         True, False,  True, False, False, False,  True, False, False, False,\n",
       "        False, False, False, False,  True, False, False, False,  True, False,\n",
       "        False, False,  True, False, False,  True, False, False, False, False,\n",
       "        False,  True, False,  True, False, False, False, False, False, False,\n",
       "        False, False, False,  True, False, False, False, False, False, False,\n",
       "        False, False,  True, False, False, False, False, False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds == labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10ab918a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(preds == labels) # this is telling how many out of 128 were get predicted correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c1ca8",
   "metadata": {},
   "source": [
    "## Accuracy of predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b57bc3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34e02721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1641)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(outputs,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bdd7f",
   "metadata": {},
   "source": [
    "The `==` operator performs an element-wise comparison of two tensors with the same shape and returns a tensor of the same shape, containing `True` for unequal elements and `False` for equal elements. Passing the result to `torch.sum` returns the number of labels that were predicted correctly. Finally, we divide by the total number of images to get the accuracy. \n",
    "\n",
    "Note that we don't need to apply softmax to the outputs since its results have the same relative order. This is because `e^x` is an increasing function, i.e., if `y1 > y2`, then `e^y1 > e^y2`. The same holds after averaging out the values to get the softmax.\n",
    "\n",
    "Let's calculate the accuracy of the current model on the first batch of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99688c42",
   "metadata": {},
   "source": [
    " Accuracy is an excellent way for us (humans) to evaluate the model. However, we can't use it as a loss function for optimizing our model using gradient descent for the following reasons:\n",
    "\n",
    "1. It's not a differentiable function. `torch.max` and `==` are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n",
    "\n",
    "2. It doesn't take into account the actual probabilities predicted by the model, so it can't provide sufficient feedback for incremental improvements. \n",
    "\n",
    "For these reasons, accuracy is often used as an **evaluation metric** for classification, but not as a loss function. A commonly used loss function for classification problems is the **cross-entropy**, which has the following formula:\n",
    "\n",
    "![cross-entropy](https://i.imgur.com/VDRDl1D.png)\n",
    "\n",
    "While it looks complicated, it's actually quite simple:\n",
    "\n",
    "* For each output row, pick the predicted probability for the correct label. E.g., if the predicted probabilities for an image are `[0.1, 0.3, 0.2, ...]` and the correct label is `1`, we pick the corresponding element `0.3` and ignore the rest.\n",
    "\n",
    "* Then, take the [logarithm](https://en.wikipedia.org/wiki/Logarithm) of the picked probability. If the probability is high, i.e., close to 1, then its logarithm is a very small negative value, close to 0. And if the probability is low (close to 0), then the logarithm is a very large negative value. We also multiply the result by -1, which results is a large postive value of the loss for poor predictions.\n",
    "\n",
    "![](https://www.intmath.com/blog/wp-content/images/2019/05/log10.png)\n",
    "\n",
    "* Finally, take the average of the cross entropy across all the output rows to get the overall loss for a batch of data.\n",
    "\n",
    "Unlike accuracy, cross-entropy is a continuous and differentiable function. It also provides useful feedback for incremental improvements in the model (a slightly higher probability for the correct label leads to a lower loss). These two factors make cross-entropy a better choice for the loss function.\n",
    "\n",
    "As you might expect, PyTorch provides an efficient and tensor-friendly implementation of cross-entropy as part of the `torch.nn.functional` package. Moreover, it also performs softmax internally, so we can directly pass in the model's outputs without converting them into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56befac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0942, 0.0734, 0.1115,  ..., 0.0784, 0.0917, 0.1340],\n",
       "        [0.0774, 0.0698, 0.1368,  ..., 0.0787, 0.0888, 0.1063],\n",
       "        [0.1088, 0.0800, 0.1331,  ..., 0.0638, 0.0798, 0.1175],\n",
       "        ...,\n",
       "        [0.1022, 0.0864, 0.1257,  ..., 0.0881, 0.1148, 0.1158],\n",
       "        [0.0974, 0.0822, 0.0975,  ..., 0.0675, 0.0971, 0.1339],\n",
       "        [0.0905, 0.1213, 0.1075,  ..., 0.0760, 0.1040, 0.1229]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5162d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1e8f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss for current batch of data\n",
    "\n",
    "loss = loss_fn(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1776914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3150, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6f22d6",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5a8a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    history = [] # for reading epoch-wise results\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #training phase\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step() # change the gradients using the learning rate\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "        #validation phase\n",
    "        \n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "090a26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader] #list comprehension \n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e4f35",
   "metadata": {},
   "source": [
    "Gaps to fill-in are : training_step, validation_step, validation_epoch_end, epoch_end used by : fit, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b502257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                         # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)        # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                          # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)         #loss\n",
    "        acc = accuracy(out, labels)                 # clac accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss  = torch.stack(batch_losses).mean()  #combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_accs = torch.stack(batch_accs).mean()     #combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_accs.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "        \n",
    "        \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d69ee81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.283280611038208, 'val_acc': 0.10749604552984238}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcba3fd",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9cfc5170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.9208, val_acc: 0.6665\n",
      "Epoch [1], val_loss: 1.6565, val_acc: 0.7396\n",
      "Epoch [2], val_loss: 1.4599, val_acc: 0.7663\n",
      "Epoch [3], val_loss: 1.3116, val_acc: 0.7836\n",
      "Epoch [4], val_loss: 1.1978, val_acc: 0.7975\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b49b30fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.1083, val_acc: 0.8057\n",
      "Epoch [1], val_loss: 1.0365, val_acc: 0.8137\n",
      "Epoch [2], val_loss: 0.9777, val_acc: 0.8194\n",
      "Epoch [3], val_loss: 0.9287, val_acc: 0.8240\n",
      "Epoch [4], val_loss: 0.8873, val_acc: 0.8287\n"
     ]
    }
   ],
   "source": [
    "history2 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aff55e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.8517, val_acc: 0.8326\n",
      "Epoch [1], val_loss: 0.8210, val_acc: 0.8360\n",
      "Epoch [2], val_loss: 0.7939, val_acc: 0.8392\n",
      "Epoch [3], val_loss: 0.7700, val_acc: 0.8419\n",
      "Epoch [4], val_loss: 0.7487, val_acc: 0.8445\n"
     ]
    }
   ],
   "source": [
    "history3 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "791b0a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.7295, val_acc: 0.8467\n",
      "Epoch [1], val_loss: 0.7123, val_acc: 0.8480\n",
      "Epoch [2], val_loss: 0.6966, val_acc: 0.8495\n",
      "Epoch [3], val_loss: 0.6822, val_acc: 0.8513\n",
      "Epoch [4], val_loss: 0.6691, val_acc: 0.8527\n"
     ]
    }
   ],
   "source": [
    "history4 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cbc2e4",
   "metadata": {},
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1c55a529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = [result0] + history1 + history2 + history3 + history4\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuarcy vs No of epochs');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d858aa5",
   "metadata": {},
   "source": [
    "## Testing on Individual Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a50579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "da169cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='data/',\n",
    "                     train = False,\n",
    "                     transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "723bc126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape torch.Size([1, 28, 28])\n",
      "label 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample image from the dataset\n",
    "\n",
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('shape', img.shape)\n",
    "print('label',label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eae6fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_image function to predict single label \n",
    "\n",
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    \n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db51b532",
   "metadata": {},
   "source": [
    "`img.unsqueeze` simply adds another dimension at the begining of the 1x28x28 tensor, making it a 1x1x28x28 tensor, which the model views as a batch containing a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ea8658a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 7 , predicted: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:',label, ', predicted:',predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "054c21c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2 , predicted: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[1]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:',label, ', predicted:',predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "844dd854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1 , predicted: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[5]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:',label, ', predicted:',predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f3657ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9 , predicted: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[193]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:',label, ', predicted:',predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6284edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 2 , predicted: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[1839]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('label:',label, ', predicted:',predict_image(img, model))         # Here Model in Breaking Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "75e6f37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.6401068568229675, 'val_acc': 0.8603515625}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall loss and accuracy of model on test set\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "result = evaluate(model, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd82de1",
   "metadata": {},
   "source": [
    "# Saving and Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d719b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist-logistic.pth') # .state_dict returns Ordered Dict containig all the weights and bias matrices mapped to right attributes of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "31c80331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0064, -0.0261,  0.0092,  ...,  0.0320,  0.0143,  0.0129],\n",
       "                      [-0.0179,  0.0100,  0.0158,  ...,  0.0125, -0.0167,  0.0209],\n",
       "                      [ 0.0081,  0.0290, -0.0355,  ...,  0.0334, -0.0284, -0.0074],\n",
       "                      ...,\n",
       "                      [-0.0097, -0.0077,  0.0133,  ...,  0.0153, -0.0036,  0.0283],\n",
       "                      [ 0.0289, -0.0290, -0.0317,  ..., -0.0190,  0.0308, -0.0353],\n",
       "                      [-0.0043,  0.0184, -0.0096,  ...,  0.0319, -0.0038, -0.0067]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0544,  0.1269,  0.0047, -0.0240,  0.0016,  0.0284, -0.0175,  0.0452,\n",
       "                      -0.0609, -0.0155]))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5fecf7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0064, -0.0261,  0.0092,  ...,  0.0320,  0.0143,  0.0129],\n",
       "                      [-0.0179,  0.0100,  0.0158,  ...,  0.0125, -0.0167,  0.0209],\n",
       "                      [ 0.0081,  0.0290, -0.0355,  ...,  0.0334, -0.0284, -0.0074],\n",
       "                      ...,\n",
       "                      [-0.0097, -0.0077,  0.0133,  ...,  0.0153, -0.0036,  0.0283],\n",
       "                      [ 0.0289, -0.0290, -0.0317,  ..., -0.0190,  0.0308, -0.0353],\n",
       "                      [-0.0043,  0.0184, -0.0096,  ...,  0.0319, -0.0038, -0.0067]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0544,  0.1269,  0.0047, -0.0240,  0.0016,  0.0284, -0.0175,  0.0452,\n",
       "                      -0.0609, -0.0155]))])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To load the model weights\n",
    "\n",
    "model_2 = MnistModel()\n",
    "model_2.load_state_dict(torch.load('mnist-logistic.pth'))\n",
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41422bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
